{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: autogluon in ./.venv/lib/python3.11/site-packages (0.8.3b20231109)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: autogluon.core==0.8.3b20231109 in ./.venv/lib/python3.11/site-packages (from autogluon.core[all]==0.8.3b20231109->autogluon) (0.8.3b20231109)\n",
      "Requirement already satisfied: autogluon.features==0.8.3b20231109 in ./.venv/lib/python3.11/site-packages (from autogluon) (0.8.3b20231109)\n",
      "Requirement already satisfied: autogluon.tabular==0.8.3b20231109 in ./.venv/lib/python3.11/site-packages (from autogluon.tabular[all]==0.8.3b20231109->autogluon) (0.8.3b20231109)\n",
      "Requirement already satisfied: autogluon.multimodal==0.8.3b20231109 in ./.venv/lib/python3.11/site-packages (from autogluon) (0.8.3b20231109)\n",
      "Requirement already satisfied: autogluon.timeseries==0.8.3b20231109 in ./.venv/lib/python3.11/site-packages (from autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.8.3b20231109)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in ./.venv/lib/python3.11/site-packages (from autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (3.2.1)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in ./.venv/lib/python3.11/site-packages (from autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (4.66.1)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (2.31.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (from autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (3.8.1)\n",
      "Requirement already satisfied: boto3<2,>=1.10 in ./.venv/lib/python3.11/site-packages (from autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (1.28.82)\n",
      "Requirement already satisfied: autogluon.common==0.8.3b20231109 in ./.venv/lib/python3.11/site-packages (from autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (0.8.3b20231109)\n",
      "Requirement already satisfied: ray<2.7,>=2.6.3 in ./.venv/lib/python3.11/site-packages (from ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (2.6.3)\n",
      "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in ./.venv/lib/python3.11/site-packages (from autogluon.core[all]==0.8.3b20231109->autogluon) (0.2.7)\n",
      "Requirement already satisfied: Pillow<9.6,>=9.3 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (9.5.0)\n",
      "Requirement already satisfied: torch<2.1,>=2.0 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (2.0.1)\n",
      "Requirement already satisfied: lightning<2.1,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (2.0.9.post0)\n",
      "Requirement already satisfied: jsonschema<4.18,>=4.14 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (4.17.3)\n",
      "Requirement already satisfied: seqeval<1.3.0,>=1.2.2 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (1.2.2)\n",
      "Requirement already satisfied: evaluate<0.5.0,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (0.4.1)\n",
      "Requirement already satisfied: accelerate<0.22.0,>=0.21.0 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (0.21.0)\n",
      "Requirement already satisfied: transformers<4.32.0,>=4.31.0 in ./.venv/lib/python3.11/site-packages (from transformers[sentencepiece]<4.32.0,>=4.31.0->autogluon.multimodal==0.8.3b20231109->autogluon) (4.31.0)\n",
      "Requirement already satisfied: timm<0.10.0,>=0.9.5 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (0.9.10)\n",
      "Requirement already satisfied: torchvision<0.16.0,>=0.14.0 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (0.15.2)\n",
      "Requirement already satisfied: scikit-image<0.21.0,>=0.19.1 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (0.20.0)\n",
      "Requirement already satisfied: text-unidecode<1.4,>=1.3 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (1.3)\n",
      "Requirement already satisfied: torchmetrics<1.2.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (1.1.2)\n",
      "Requirement already satisfied: nptyping<2.5.0,>=1.4.4 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (2.4.1)\n",
      "Requirement already satisfied: omegaconf<2.3.0,>=2.1.1 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (2.2.3)\n",
      "Requirement already satisfied: pytorch-metric-learning<2.0,>=1.3.0 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (1.7.3)\n",
      "Requirement already satisfied: nlpaug<1.2.0,>=1.1.10 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (1.1.11)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (3.8.1)\n",
      "Requirement already satisfied: openmim<0.4.0,>=0.3.7 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (0.3.9)\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (0.7.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (3.1.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.9 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (2.14.1)\n",
      "Requirement already satisfied: pytesseract<0.3.11,>=0.3.9 in ./.venv/lib/python3.11/site-packages (from autogluon.multimodal==0.8.3b20231109->autogluon) (0.3.10)\n",
      "Requirement already satisfied: fastai<2.8,>=2.3.1 in ./.venv/lib/python3.11/site-packages (from autogluon.tabular[all]==0.8.3b20231109->autogluon) (2.7.13)\n",
      "Requirement already satisfied: xgboost<1.8,>=1.6 in ./.venv/lib/python3.11/site-packages (from autogluon.tabular[all]==0.8.3b20231109->autogluon) (1.7.6)\n",
      "Requirement already satisfied: lightgbm<3.4,>=3.3 in ./.venv/lib/python3.11/site-packages (from autogluon.tabular[all]==0.8.3b20231109->autogluon) (3.3.5)\n",
      "Requirement already satisfied: pytorch-lightning<2.1,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (2.0.9.post0)\n",
      "Requirement already satisfied: statsmodels<0.15,>=0.13.0 in ./.venv/lib/python3.11/site-packages (from autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.14.0)\n",
      "Requirement already satisfied: gluonts<0.15,>=0.14.0 in ./.venv/lib/python3.11/site-packages (from autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.14.0)\n",
      "Requirement already satisfied: statsforecast<1.5,>=1.4.0 in ./.venv/lib/python3.11/site-packages (from autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (1.4.0)\n",
      "Requirement already satisfied: mlforecast<0.10.1,>=0.10.0 in ./.venv/lib/python3.11/site-packages (from autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.10.0)\n",
      "Requirement already satisfied: utilsforecast<0.0.11,>=0.0.10 in ./.venv/lib/python3.11/site-packages (from autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.0.10)\n",
      "Requirement already satisfied: ujson<6,>=5 in ./.venv/lib/python3.11/site-packages (from autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (5.8.0)\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in ./.venv/lib/python3.11/site-packages (from autogluon.common==0.8.3b20231109->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (5.9.6)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from autogluon.common==0.8.3b20231109->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (68.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==0.8.3b20231109->autogluon) (23.2)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.11/site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==0.8.3b20231109->autogluon) (6.0.1)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.82 in ./.venv/lib/python3.11/site-packages (from boto3<2,>=1.10->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (1.31.82)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in ./.venv/lib/python3.11/site-packages (from boto3<2,>=1.10->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from boto3<2,>=1.10->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (0.7.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./.venv/lib/python3.11/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==0.8.3b20231109->autogluon) (2.14.6)\n",
      "Requirement already satisfied: dill in ./.venv/lib/python3.11/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.3.7)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==0.8.3b20231109->autogluon) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.11/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==0.8.3b20231109->autogluon) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./.venv/lib/python3.11/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.19.0)\n",
      "Requirement already satisfied: responses<0.19 in ./.venv/lib/python3.11/site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.18.0)\n",
      "Requirement already satisfied: pip in ./.venv/lib/python3.11/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (23.3.1)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in ./.venv/lib/python3.11/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (0.0.7)\n",
      "Requirement already satisfied: fastcore<1.6,>=1.5.29 in ./.venv/lib/python3.11/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (1.5.29)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in ./.venv/lib/python3.11/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (1.0.3)\n",
      "Requirement already satisfied: spacy<4 in ./.venv/lib/python3.11/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (3.7.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in ./.venv/lib/python3.11/site-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (1.10.13)\n",
      "Requirement already satisfied: toolz~=0.10 in ./.venv/lib/python3.11/site-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in ./.venv/lib/python3.11/site-packages (from gluonts<0.15,>=0.14.0->autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (4.8.0)\n",
      "Requirement already satisfied: future in ./.venv/lib/python3.11/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.3b20231109->autogluon) (0.18.3)\n",
      "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.11/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.3b20231109->autogluon) (3.0.0)\n",
      "Requirement already satisfied: py4j in ./.venv/lib/python3.11/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.8.3b20231109->autogluon) (0.10.9.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==0.8.3b20231109->autogluon) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./.venv/lib/python3.11/site-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.3b20231109->autogluon) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in ./.venv/lib/python3.11/site-packages (from jsonschema<4.18,>=4.14->autogluon.multimodal==0.8.3b20231109->autogluon) (0.20.0)\n",
      "Requirement already satisfied: wheel in ./.venv/lib/python3.11/site-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.8.3b20231109->autogluon) (0.41.3)\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (1.3.0)\n",
      "Requirement already satisfied: backoff<4.0,>=2.2.1 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (4.12.2)\n",
      "Requirement already satisfied: click<10.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (8.1.7)\n",
      "Requirement already satisfied: croniter<1.5.0,>=1.3.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (1.4.1)\n",
      "Requirement already satisfied: dateutils<2.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.6.12)\n",
      "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (6.7.0)\n",
      "Requirement already satisfied: fastapi<2.0,>=0.92.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.104.1)\n",
      "Requirement already satisfied: inquirer<5.0,>=2.10.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (3.1.3)\n",
      "Requirement already satisfied: lightning-cloud>=0.5.38 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.5.52)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.9.0)\n",
      "Requirement already satisfied: python-multipart<2.0,>=0.0.5 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.0.6)\n",
      "Requirement already satisfied: rich<15.0,>=12.3.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (13.6.0)\n",
      "Requirement already satisfied: starlette in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.27.0)\n",
      "Requirement already satisfied: starsessions<2.0,>=1.2.1 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (1.3.0)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (5.13.0)\n",
      "Requirement already satisfied: urllib3<4.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (2.0.7)\n",
      "Requirement already satisfied: uvicorn<2.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.24.0.post1)\n",
      "Requirement already satisfied: websocket-client<3.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (1.6.4)\n",
      "Requirement already satisfied: websockets<13.0 in ./.venv/lib/python3.11/site-packages (from lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (12.0)\n",
      "Requirement already satisfied: numba in ./.venv/lib/python3.11/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.58.1)\n",
      "Requirement already satisfied: window-ops in ./.venv/lib/python3.11/site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.0.14)\n",
      "Requirement already satisfied: gdown>=4.0.0 in ./.venv/lib/python3.11/site-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.3b20231109->autogluon) (4.7.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.8.3b20231109->autogluon) (2023.10.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in ./.venv/lib/python3.11/site-packages (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==0.8.3b20231109->autogluon) (4.9.3)\n",
      "Requirement already satisfied: colorama in ./.venv/lib/python3.11/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.3b20231109->autogluon) (0.4.6)\n",
      "Requirement already satisfied: model-index in ./.venv/lib/python3.11/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.3b20231109->autogluon) (0.1.11)\n",
      "Requirement already satisfied: opendatalab in ./.venv/lib/python3.11/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.3b20231109->autogluon) (0.0.10)\n",
      "Requirement already satisfied: tabulate in ./.venv/lib/python3.11/site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.3b20231109->autogluon) (0.9.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (3.13.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (1.0.7)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in ./.venv/lib/python3.11/site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (4.25.0)\n",
      "Requirement already satisfied: aiosignal in ./.venv/lib/python3.11/site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (1.3.1)\n",
      "Requirement already satisfied: frozenlist in ./.venv/lib/python3.11/site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in ./.venv/lib/python3.11/site-packages (from ray<2.7,>=2.6.3->ray[default]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (1.59.2)\n",
      "Requirement already satisfied: aiohttp>=3.7 in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (3.8.6)\n",
      "Requirement already satisfied: aiohttp-cors in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (0.7.0)\n",
      "Requirement already satisfied: colorful in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (0.5.5)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (0.3.14)\n",
      "Requirement already satisfied: gpustat>=1.0.0 in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (1.1.1)\n",
      "Requirement already satisfied: opencensus in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (0.11.3)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (0.18.0)\n",
      "Requirement already satisfied: smart-open in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (6.4.0)\n",
      "Requirement already satisfied: virtualenv<20.21.1,>=20.0.24 in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (20.21.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (2.6.2.2)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in ./.venv/lib/python3.11/site-packages (from ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (13.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (2023.7.22)\n",
      "Requirement already satisfied: imageio>=2.4.1 in ./.venv/lib/python3.11/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==0.8.3b20231109->autogluon) (2.32.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in ./.venv/lib/python3.11/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==0.8.3b20231109->autogluon) (2023.9.26)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in ./.venv/lib/python3.11/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==0.8.3b20231109->autogluon) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in ./.venv/lib/python3.11/site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==0.8.3b20231109->autogluon) (0.3)\n",
      "Requirement already satisfied: plotly in ./.venv/lib/python3.11/site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (5.18.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in ./.venv/lib/python3.11/site-packages (from statsmodels<0.15,>=0.13.0->autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.5.3)\n",
      "Requirement already satisfied: absl-py>=0.4 in ./.venv/lib/python3.11/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (2.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.11/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./.venv/lib/python3.11/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.11/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.11/site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (3.0.1)\n",
      "Requirement already satisfied: safetensors in ./.venv/lib/python3.11/site-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==0.8.3b20231109->autogluon) (0.4.0)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch<2.1,>=2.0->autogluon.multimodal==0.8.3b20231109->autogluon) (1.12)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in ./.venv/lib/python3.11/site-packages (from transformers<4.32.0,>=4.31.0->transformers[sentencepiece]<4.32.0,>=4.31.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.13.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in ./.venv/lib/python3.11/site-packages (from transformers[sentencepiece]<4.32.0,>=4.31.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.1.99)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->autogluon.core==0.8.3b20231109->autogluon.core[all]==0.8.3b20231109->autogluon) (3.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.7->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.7->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp>=3.7->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (1.9.2)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in ./.venv/lib/python3.11/site-packages (from arrow<3.0,>=1.2.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (2.8.19.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.11/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (2.5)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in ./.venv/lib/python3.11/site-packages (from deepdiff<8.0,>=5.7.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (4.1.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in ./.venv/lib/python3.11/site-packages (from fastapi<2.0,>=0.92.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (3.7.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (1.3.1)\n",
      "Requirement already satisfied: nvidia-ml-py>=11.450.129 in ./.venv/lib/python3.11/site-packages (from gpustat>=1.0.0->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (12.535.133)\n",
      "Requirement already satisfied: blessed>=1.17.1 in ./.venv/lib/python3.11/site-packages (from gpustat>=1.0.0->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (1.20.0)\n",
      "Requirement already satisfied: python-editor>=1.0.4 in ./.venv/lib/python3.11/site-packages (from inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (1.0.4)\n",
      "Requirement already satisfied: readchar>=3.0.6 in ./.venv/lib/python3.11/site-packages (from inquirer<5.0,>=2.10.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (4.0.5)\n",
      "Requirement already satisfied: pyjwt in ./.venv/lib/python3.11/site-packages (from lightning-cloud>=0.5.38->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (2.8.0)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in ./.venv/lib/python3.11/site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (0.41.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.11/site-packages (from rich<15.0,>=12.3.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.11/site-packages (from rich<15.0,>=12.3.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (2.16.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (0.9.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./.venv/lib/python3.11/site-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (3.3.0)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in ./.venv/lib/python3.11/site-packages (from starsessions<2.0,>=1.2.1->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (2.1.2)\n",
      "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.11/site-packages (from uvicorn<2.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.14.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in ./.venv/lib/python3.11/site-packages (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (0.3.7)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in ./.venv/lib/python3.11/site-packages (from virtualenv<20.21.1,>=20.0.24->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (3.11.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in ./.venv/lib/python3.11/site-packages (from opencensus->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from opencensus->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (2.13.0)\n",
      "Requirement already satisfied: pycryptodome in ./.venv/lib/python3.11/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.3b20231109->autogluon) (3.19.0)\n",
      "Requirement already satisfied: openxlab in ./.venv/lib/python3.11/site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==0.8.3b20231109->autogluon) (0.0.11)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.venv/lib/python3.11/site-packages (from plotly->statsforecast<1.5,>=1.4.0->autogluon.timeseries==0.8.3b20231109->autogluon.timeseries[all]==0.8.3b20231109->autogluon) (8.2.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->torch<2.1,>=2.0->autogluon.multimodal==0.8.3b20231109->autogluon) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.11/site-packages (from anyio<4.0.0,>=3.7.1->fastapi<2.0,>=0.92.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (1.3.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in ./.venv/lib/python3.11/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (0.2.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./.venv/lib/python3.11/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.7,>=2.6.3; extra == \"all\"->autogluon.core[all]==0.8.3b20231109->autogluon) (1.61.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich<15.0,>=12.3.0->lightning<2.1,>=2.0.0->autogluon.multimodal==0.8.3b20231109->autogluon) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./.venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==0.8.3b20231109->autogluon) (3.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (0.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./.venv/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.8.3b20231109->autogluon) (0.16.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in ./.venv/lib/python3.11/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==0.8.3b20231109->autogluon) (1.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn autogluon pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constans and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [\"A\", \"B\", \"C\"]\n",
    "features_order = []\n",
    "\n",
    "LAGGED_COLUMNS_TO_KEEP = [\n",
    "    # 'direct_rad:W_lag_1h', \n",
    "    'direct_rad:W_lag_forward_1h', \n",
    "    # 'clear_sky_rad:W_lag_1h', \n",
    "    'clear_sky_rad:W_lag_forward_1h', \n",
    "    # 'diffuse_rad:W_lag_1h', \n",
    "    'diffuse_rad:W_lag_forward_1h', \n",
    "    # 'direct_rad_1h:J_lag_1h', \n",
    "    'direct_rad_1h:J_lag_forward_1h', \n",
    "    # 'is_in_shadow:idx_lag_1h', \n",
    "    'is_in_shadow:idx_lag_forward_1h', \n",
    "    # 'clear_sky_energy_1h:J_lag_1h', \n",
    "    'clear_sky_energy_1h:J_lag_forward_1h', \n",
    "    # 'effective_cloud_cover:p_lag_1h', \n",
    "    'effective_cloud_cover:p_lag_forward_1h', \n",
    "    # 'visibility:m_lag_1h', \n",
    "    'visibility:m_lag_forward_1h', \n",
    "    # 'total_cloud_cover:p_lag_1h', \n",
    "    'total_cloud_cover:p_lag_forward_1h', \n",
    "\n",
    "\n",
    "    # 'direct_rad:W_lag_2h', \n",
    "    # 'direct_rad:W_lag_forward_2h', \n",
    "    # 'clear_sky_rad:W_lag_2h', \n",
    "    # 'clear_sky_rad:W_lag_forward_2h', \n",
    "    # 'diffuse_rad:W_lag_2h', \n",
    "    # 'diffuse_rad:W_lag_forward_2h', \n",
    "    # 'direct_rad_1h:J_lag_2h', \n",
    "    # 'direct_rad_1h:J_lag_forward_2h', \n",
    "    # 'is_in_shadow:idx_lag_2h', \n",
    "    # 'is_in_shadow:idx_lag_forward_2h', \n",
    "    # 'clear_sky_energy_1h:J_lag_2h', \n",
    "    # 'clear_sky_energy_1h:J_lag_forward_2h', \n",
    "    # 'effective_cloud_cover:p_lag_2h', \n",
    "    # 'effective_cloud_cover:p_lag_forward_2h', \n",
    "    # 'visibility:m_lag_2h', \n",
    "    # 'visibility:m_lag_forward_2h', \n",
    "    # 'total_cloud_cover:p_lag_2h', \n",
    "    # 'total_cloud_cover:p_lag_forward_2h', \n",
    "\n",
    "    # 'direct_rad:W_lag_3h', \n",
    "    # 'direct_rad:W_lag_forward_3h', \n",
    "    # 'clear_sky_rad:W_lag_3h', \n",
    "    # 'clear_sky_rad:W_lag_forward_3h', \n",
    "    # 'diffuse_rad:W_lag_3h', \n",
    "    # 'diffuse_rad:W_lag_forward_3h', \n",
    "    # 'direct_rad_1h:J_lag_3h', \n",
    "    # 'direct_rad_1h:J_lag_forward_3h', \n",
    "    # 'is_in_shadow:idx_lag_3h', \n",
    "    # 'is_in_shadow:idx_lag_forward_3h', \n",
    "    # 'clear_sky_energy_1h:J_lag_3h', \n",
    "    # 'clear_sky_energy_1h:J_lag_forward_3h', \n",
    "    # 'effective_cloud_cover:p_lag_3h', \n",
    "    # 'effective_cloud_cover:p_lag_forward_3h', \n",
    "    # 'visibility:m_lag_3h', \n",
    "    # 'visibility:m_lag_forward_3h', \n",
    "    # 'total_cloud_cover:p_lag_3h', \n",
    "    # 'total_cloud_cover:p_lag_forward_3h'\n",
    "]\n",
    "\n",
    "CUSTOM_COLUMNS_TO_KEEP = [\n",
    "    \"hour_cos\",\n",
    "    \"hour_sin\",\n",
    "    \"month_sin\",\n",
    "    \"month_cos\",\n",
    "    \"day-of-year\",\n",
    "    \"hours_since_forecast\"\n",
    "]\n",
    "\n",
    "WEATHER_FEATURES = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "]\n",
    "\n",
    "\n",
    "TEST_COLUMNS_TO_KEEP = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"diffuse_rad_1h:J\",\n",
    "    \"is_day:idx\",\n",
    "    \"sun_elevation:d\",\n",
    "    \"ceiling_height_agl:m\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "    \"air_density_2m:kgm3\",\n",
    "    \"wind_speed_v_10m:ms\",\n",
    "    \"dew_point_2m:K\",\n",
    "    \"wind_speed_u_10m:ms\",\n",
    "    \"t_1000hPa:K\",\n",
    "    \"absolute_humidity_2m:gm3\",\n",
    "    \"snow_water:kgm2\",\n",
    "    \"relative_humidity_1000hPa:p\",\n",
    "    \"fresh_snow_24h:cm\",\n",
    "    \"cloud_base_agl:m\",\n",
    "    \"fresh_snow_12h:cm\",\n",
    "    \"snow_depth:cm\",\n",
    "    \"dew_or_rime:idx\",\n",
    "    \"fresh_snow_6h:cm\",\n",
    "    \"super_cooled_liquid_water:kgm2\",\n",
    "    \"fresh_snow_3h:cm\",\n",
    "    \"rain_water:kgm2\",\n",
    "    \"precip_type_5min:idx\",\n",
    "    \"precip_5min:mm\",\n",
    "    \"fresh_snow_1h:cm\",\n",
    "    \"sun_azimuth:d\",\n",
    "    \"msl_pressure:hPa\",\n",
    "    \"pressure_100m:hPa\",\n",
    "    \"pressure_50m:hPa\",\n",
    "    \"sfc_pressure:hPa\",\n",
    "    \"prob_rime:p\",\n",
    "    \"wind_speed_10m:ms\",\n",
    "    # \"elevation:m\",\n",
    "    # \"snow_density:kgm3\",\n",
    "    # \"snow_drift:idx\",\n",
    "    \"snow_melt_10min:mm\",\n",
    "    \"wind_speed_w_1000hPa:ms\",\n",
    "    \"observed_or_estimated\"\n",
    "    # \"location_A\",\n",
    "    # \"location_B\",\n",
    "    # \"location_C\",\n",
    "    # \"date_calc\",\n",
    "] + CUSTOM_COLUMNS_TO_KEEP  +  LAGGED_COLUMNS_TO_KEEP\n",
    "\n",
    "COLUMNS_TO_KEEP = TEST_COLUMNS_TO_KEEP + [\"pv_measurement\"]\n",
    "\n",
    "\n",
    "\n",
    "def create_weather_lagged_features(df, weather_features):\n",
    "    # Choose the weather features for which you want to create lagged versions\n",
    "    for feature in weather_features:\n",
    "        # Assuming hourly data, adjust the lags for your specific dataset\n",
    "        # Creating lagged features for 1 hour, 1 day, and 1 week\n",
    "        # df[f'{feature}_lag_1h'] = df[feature].shift(1)\n",
    "        # df[f'{feature}_lag_2h'] = df[feature].shift(2)\n",
    "        # df[f'{feature}_lag_3h'] = df[feature].shift(3)\n",
    "\n",
    "        df[f'{feature}_lag_forward_1h'] = df[feature].shift(-1)\n",
    "        # df[f'{feature}_lag_forward_2h'] = df[feature].shift(-2)\n",
    "        # df[f'{feature}_lag_forward_3h'] = df[feature].shift(-3)\n",
    "        # df[f'{feature}_lag_24h'] = df[feature].shift(24*4)\n",
    "        # df[f'{feature}_lag_168h'] = df[feature].shift(24 * 7 * 4 * 365)\n",
    "        # df[f'{feature}_front_lag_1h'] = df[feature].shift(-4)\n",
    "        # df[f'{feature}_front_lag_24h'] = df[feature].shift(-24*4)\n",
    "\n",
    "\n",
    "    # Handling edges by filling NaNs with appropriate values or dropping them\n",
    "    # You may choose to fill with zeroes or interpolate, based on what makes more sense for your data\n",
    "    # df.fillna(method='ffill', inplace=True)  # Forward fill  # Autogluon should handle this for us.\n",
    "    # df.fillna(method='bfill', inplace=True)  # Backward fill  # Autogluon should handle this for us.\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "B_SCALE_VALUE = 6.3\n",
    "C_SCALE_VALUE = 8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_custom_fields(df):\n",
    "     df['hour_sin'] = np.sin(2 * np.pi * df['date_forecast'].dt.hour / 24)\n",
    "     df['hour_cos'] = np.cos(2 * np.pi * df['date_forecast'].dt.hour / 24)\n",
    "\n",
    "     df['month_sin'] = np.sin(2 * np.pi * df['date_forecast'].dt.month / 12)\n",
    "     df['month_cos'] = np.cos(2 * np.pi * df['date_forecast'].dt.month / 12)\n",
    "     df['day-of-year'] = df['date_forecast'].dt.dayofyear\n",
    "     return df\n",
    "\n",
    "def add_calc_date(df_observed, df_estimated, df_test):\n",
    "    # Function to calculate the difference in hours\n",
    "    def calculate_hour_difference(row):\n",
    "        diff = row['date_calc'] - row['date_forecast']\n",
    "        return diff.total_seconds() / 3600  # Convert difference to hours\n",
    "\n",
    "    # Apply the function to calculate the hour difference for df_estimated and df_test\n",
    "    df_estimated['hours_since_forecast'] = df_estimated.apply(calculate_hour_difference, axis=1)\n",
    "    df_test['hours_since_forecast'] = df_test.apply(calculate_hour_difference, axis=1)\n",
    "\n",
    "    # Fill in zero for df_observed\n",
    "    df_observed['hours_since_forecast'] = 0\n",
    "\n",
    "    return df_observed, df_estimated, df_test\n",
    "\n",
    "\n",
    "def remove_outliers(df):\n",
    "    # Use a mask to filter out the rows where rolling std is zero but keep the rows where the value itself is zero\n",
    "    # Because some places in the data, the pv-measurements are messed up and are repeating.\n",
    "    mask = (df['pv_measurement'].rolling(2).std() == 0) & (df['pv_measurement'] != 0)\n",
    "    df[mask] = np.NaN  # Put this to NaN and hope autoGluon Handles.\n",
    "    return df\n",
    "\n",
    "def resample_add_data(df, is_test_data):\n",
    "    df = add_custom_fields(df)\n",
    "    df.set_index('date_forecast', inplace=True)\n",
    "    df = df.resample('1H').mean()\n",
    "    \n",
    "    # Remove empty dates if test data\n",
    "    if is_test_data:\n",
    "        non_nan_threshold = len(df.columns) // 2\n",
    "        df.dropna(thresh=non_nan_threshold, inplace=True)\n",
    "\n",
    "    # df.interpolate(method=\"linear\", inplace=True)  # Autogluon should handle this for us.\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_location_feature(X, location):\n",
    "      # Treat location as a categorical feature by converting it to a category type\n",
    "    X['location'] = location\n",
    "    X['location'] = X['location'].astype(str)  # Convert to string if 'location' is not an int\n",
    "    # X['dew_or_rime:idx'] = X['dew_or_rime:idx'].astype(str)\n",
    "    # X['is_day:idx'] = X['is_day:idx'].astype(str)\n",
    "    # X['is_in_shadow:idx'] = X['is_in_shadow:idx'].astype(str)\n",
    "    # categorical_columns = ['location', 'dew_or_rime:idx', 'is_day:idx', 'is_in_shadow:idx']\n",
    "\n",
    "    # # Before filling NaN values, add 'missing' as a category for each categorical column.\n",
    "    # for column in categorical_columns:\n",
    "    #     X[column] = X[column].astype('category')  # Ensure the column is of type 'category'.\n",
    "    #     if 'missing' not in X[column].cat.categories:\n",
    "    #         X[column] = X[column].cat.add_categories(['missing'])  # Add 'missing' as a new category.\n",
    "    #     X[column] = X[column].fillna('missing')\n",
    "    # X['location'] = X['location'].astype('category')\n",
    "    # X['dew_or_rime:idx'] = X['dew_or_rime:idx'].astype('category')\n",
    "    # X['is_day:idx'] = X['is_day:idx'].astype('category')\n",
    "    # X['is_in_shadow:idx'] = X['is_in_shadow:idx'].astype('category')\n",
    "    \n",
    "    return X\n",
    "\n",
    "def add_scaling(X_test, X_training, location):\n",
    "    global scalers\n",
    "    continuous_columns = X_training.select_dtypes(include=['float32', 'int32']).columns\n",
    "    if location not in scalers:\n",
    "        scalers[location] = MinMaxScaler()\n",
    "    X_training[continuous_columns] = scalers[location].fit_transform(X_training[continuous_columns])\n",
    "    \n",
    "    X_test[continuous_columns] = scalers[location].transform(X_test[continuous_columns])\n",
    "\n",
    "    return X_test, X_training\n",
    "\n",
    "# Skip this as we have hours since forecast as a feature.\n",
    "# Deprecated as the concat is moved to main function.\n",
    "def make_observed_and_estimated_category(df_observed, df_estimated, df_test):\n",
    "     # Hot encode in wether observed or estimated\n",
    "    df_observed['observed_or_estimated'] = 'observed'\n",
    "    df_estimated['observed_or_estimated'] = 'estimated'\n",
    "    df_test['observed_or_estimated'] = 'estimated'\n",
    "    # Concatenate observed and estimated\n",
    "    df_training = pd.concat([df_observed, df_estimated], axis=0).sort_values(by=\"date_forecast\")\n",
    "    df_training['observed_or_estimated'] = df_training['observed_or_estimated'].astype('category')\n",
    "    df_test['observed_or_estimated'] = df_test['observed_or_estimated'].astype('category')\n",
    "\n",
    "    return df_training, df_test\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize a dictionary to hold the scalers for each location\n",
    "\n",
    "scalers = {}\n",
    "\n",
    "\n",
    "def prepare_data(location):\n",
    "    # Load data\n",
    "    scaling = False  # Set scaling to True to enable individual scaling for each location\n",
    "    global scalers\n",
    "    global scale_target \n",
    "    scale_target = False\n",
    "\n",
    "    # Load training data\n",
    "    df_observed = pd.read_parquet(f\"data/{location}/X_train_observed.parquet\")\n",
    "    df_estimated = pd.read_parquet(f\"data/{location}/X_train_estimated.parquet\")\n",
    "    df_target = pd.read_parquet(f\"data/{location}/train_targets.parquet\")\n",
    "    # drop nan values in target data, pv measurement\n",
    "    df_target.dropna(inplace=True)\n",
    "\n",
    "   \n",
    "    # Load test data\n",
    "    df_test = pd.read_parquet(f\"data/{location}/X_test_estimated.parquet\")\n",
    "\n",
    "   \n",
    "    # Add calculated date\n",
    "    df_observed, df_estimated, df_test = add_calc_date(df_observed, df_estimated, df_test)\n",
    "    \n",
    "\n",
    "    # Resample and add custom fields\n",
    "\n",
    "    df_observed = resample_add_data(df_observed, False)\n",
    "    df_estimated = resample_add_data(df_estimated, False)\n",
    "    df_test = resample_add_data(df_test, True)\n",
    "\n",
    "    df_training, df_test = make_observed_and_estimated_category(df_observed, df_estimated, df_test)\n",
    "    \n",
    "\n",
    "    # Autogluon should scale for us.\n",
    "    if scale_target:\n",
    "        if location == \"B\":\n",
    "            df_target[\"pv_measurement\"] = df_target[\"pv_measurement\"] * B_SCALE_VALUE\n",
    "        elif location == \"C\":\n",
    "            df_target[\"pv_measurement\"] = df_target[\"pv_measurement\"] * C_SCALE_VALUE\n",
    "    \n",
    "    # Merge training with target data\n",
    "    df_training = pd.merge(df_training, df_target, left_on=\"date_forecast\", right_on=\"time\", how=\"inner\")\n",
    "    \n",
    "    # Create lagged features and remove outliers training\n",
    "    df_training = create_weather_lagged_features(df_training, WEATHER_FEATURES)\n",
    "    df_training = df_training[COLUMNS_TO_KEEP]\n",
    "    df_training = remove_outliers(df_training)\n",
    "\n",
    "    df_test = create_weather_lagged_features(df_test, WEATHER_FEATURES)\n",
    "    df_test = df_test[TEST_COLUMNS_TO_KEEP]\n",
    "\n",
    "\n",
    "    # Add categories\n",
    "    df_training = add_location_feature(df_training, location)\n",
    "    X_test = add_location_feature(df_test, location)\n",
    "    \n",
    "    # Add scaling\n",
    "    if scaling:\n",
    "        X_test, X_training = add_scaling(X_test, X_training, location)\n",
    "    df_test.reset_index(inplace=True)\n",
    "    df_test.drop(columns=[\"date_forecast\"], inplace=True)\n",
    "    # y_training = np.log1p(y_training)\n",
    "    return df_training, X_test\n",
    "\n",
    "\n",
    "\n",
    "# Use prepare_data function\n",
    "\n",
    "combined_df_train = []\n",
    "combined_df_train2 = []\n",
    "combined_df_test = []\n",
    "combined_df_validation = []\n",
    "\n",
    "for location in locations:\n",
    "    # Prepare the training data\n",
    "    X_training, X_test = prepare_data(location)\n",
    "\n",
    "    df_training, df_test = prepare_data(location)\n",
    "    # split df training into training and validation, with validation being only estimated data\n",
    "    X_training, X_validation = train_test_split(df_training[df_training[\"observed_or_estimated\"] == \"estimated\"], test_size=1440, shuffle=True)\n",
    "    X_training = pd.concat([X_training, df_training[df_training[\"observed_or_estimated\"] == \"observed\"]])\n",
    "    X_training = shuffle(X_training)\n",
    "    X_training2 = shuffle(X_training, random_state=420)\n",
    "    \n",
    "    combined_df_train.append(X_training)\n",
    "    combined_df_train2.append(X_training2)\n",
    "    combined_df_validation.append(X_validation)\n",
    "\n",
    "    combined_df_test.append(X_test)\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmXT = {'learning_rate': 0.05, 'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}\n",
    "r51 = {'layers': [200, 100, 50],\n",
    "     'emb_drop': 0.6046989241462619,\n",
    "     'ps': 0.09244767444160731,\n",
    "     'bs': 1024,\n",
    "     'lr': 0.00775309042164966,\n",
    "     'epochs': 48,\n",
    "     'early.stopping.min_delta': 0.0001,\n",
    "     'early.stopping.patience': 20,\n",
    "     'smoothing': 0.0, 'ag_args': {'name_suffix': '_r51'}}\n",
    "\n",
    "r118 = {'learning_rate': 0.021720607471727896,\n",
    "     'extra_trees': True,\n",
    "     'feature_fraction': 0.7832570544199176,\n",
    "     'min_data_in_leaf': 3,\n",
    "     'num_leaves': 21}\n",
    "\n",
    "rf_r5 = {'n_estimators': 300,\n",
    "     'max_leaf_nodes': 50000,\n",
    "     'n_jobs': -1,\n",
    "     'random_state': 0,\n",
    "     'bootstrap': True,\n",
    "     'min_samples_leaf': 5,\n",
    "     'max_features': 0.5}\n",
    "\n",
    "hyperparameters_a = {\n",
    "    'NN_TORCH': {},\n",
    "    'GBM': [lgbmXT, 'GBMLarge', r118],\n",
    "    'FASTAI': [r51]\n",
    "}\n",
    "\n",
    "hyperparameters_b = {\n",
    "    'NN_TORCH': {},\n",
    "    'GBM': [lgbmXT, r118],\n",
    "    'KNN': [{'weights': 'uniform'}],\n",
    "    'FASTAI': [r51],\n",
    "    'CAT': {}\n",
    "}\n",
    "\n",
    "hyperparameters_c = {\n",
    "    'NN_TORCH': {},\n",
    "    'GBM': [lgbmXT, r118],\n",
    "    'KNN': [{'weights': 'uniform'}],\n",
    "    'FASTAI': [r51],\n",
    "    'CAT': {},\n",
    "    'XGB': {},\n",
    "\n",
    "}\n",
    "\n",
    "level_2_hyperparameters = {\n",
    "    'XT': [{}],\n",
    "    'RF': [{}, rf_r5],\n",
    "    'GBM': ['GBMLarge'],\n",
    "    'NN_TORCH': {},\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models/test_modelA\"\n",
      "Presets specified: ['experimental_zeroshot_hpo_hybrid']\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=3\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"autogluon_models/test_modelA\"\n",
      "AutoGluon Version:  0.8.3b20231109\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Sat Jun 18 17:07:28 PDT 2022; root:xnu-8020.140.41~1/RELEASE_ARM64_T8110\n",
      "Disk Space Avail:   8.44 GB / 245.11 GB (3.4%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "Train Data Rows:    32643\n",
      "Train Data Columns: 59\n",
      "Tuning Data Rows:    1440\n",
      "Tuning Data Columns: 59\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 645.05153, 1177.24683)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:223: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2601.76 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.6 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['observed_or_estimated']\n",
      "\t\t('float', [])    : 57 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'is_in_shadow:idx', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 57 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'is_in_shadow:idx', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['observed_or_estimated']\n",
      "\t0.1s = Fit runtime\n",
      "\t58 features in original data used to generate 58 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.62 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'0': {'NN_TORCH': {}, 'GBM': [{'learning_rate': 0.05, 'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge', {'learning_rate': 0.021720607471727896, 'extra_trees': True, 'feature_fraction': 0.7832570544199176, 'min_data_in_leaf': 3, 'num_leaves': 21}], 'FASTAI': [{'layers': [200, 100, 50], 'emb_drop': 0.6046989241462619, 'ps': 0.09244767444160731, 'bs': 1024, 'lr': 0.00775309042164966, 'epochs': 48, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'ag_args': {'name_suffix': '_r51'}}]},\n",
      "\t'1': {'XT': [{}], 'RF': [{}, {'n_estimators': 300, 'max_leaf_nodes': 50000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'min_samples_leaf': 5, 'max_features': 0.5}], 'GBM': ['GBMLarge'], 'NN_TORCH': {}},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 5 L1 models ...\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 39.92s of the 59.9s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 232 due to low memory. Expected memory usage reduced from 19.37% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 232 -> 193 due to low time. Expected time usage reduced from 47.9s -> 39.9s...\n",
      "\t-96.1036\t = Validation score   (-mean_absolute_error)\n",
      "\t23.24s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L1 ... Training model for up to 15.48s of the 35.46s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 172 due to low time. Expected time usage reduced from 26.9s -> 15.5s...\n",
      "\t-98.5285\t = Validation score   (-mean_absolute_error)\n",
      "\t8.78s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L1 ... Training model for up to 6.29s of the 26.27s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 217 due to low memory. Expected memory usage reduced from 20.65% -> 15.0% of available memory...\n",
      "\t-98.1755\t = Validation score   (-mean_absolute_error)\n",
      "\t4.4s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 0.79s of the 20.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "2023-11-12 21:46:38,058\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:46:38,076\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Completed 1/3 k-fold bagging repeats ...\n",
      "2023-11-12 21:46:38,078\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6559, ip=127.0.0.1)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 204, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2023-11-12 21:46:38,079\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6558, ip=127.0.0.1)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 204, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2023-11-12 21:46:38,081\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6556, ip=127.0.0.1)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 204, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2023-11-12 21:46:38,082\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6555, ip=127.0.0.1)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 204, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2023-11-12 21:46:38,083\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6554, ip=127.0.0.1)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 204, in _fit\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.9s of the 16.05s of remaining time.\n",
      "\t-96.1036\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 5 L2 models ...\n",
      "Fitting model: RandomForest_BAG_L2 ... Training model for up to 15.96s of the 15.95s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 64 due to low time. Expected time usage reduced from 74.1s -> 16.0s...\n",
      "\t-93.7099\t = Validation score   (-mean_absolute_error)\n",
      "\t8.99s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L2 ... Training model for up to 6.66s of the 6.64s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 79 due to low time. Expected time usage reduced from 25.2s -> 6.7s...\n",
      "\t-90.8702\t = Validation score   (-mean_absolute_error)\n",
      "\t4.22s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L2 ... Training model for up to 2.24s of the 2.22s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 262 due to low memory. Expected memory usage reduced from 17.11% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 262 -> 66 due to low time. Expected time usage reduced from 8.8s -> 2.2s...\n",
      "\t-92.0559\t = Validation score   (-mean_absolute_error)\n",
      "\t1.53s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 0.43s of the 0.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L2.\n",
      "2023-11-12 21:46:57,008\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:46:57,009\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:46:57,009\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:46:57,010\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:46:57,010\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:46:57,011\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:46:57,012\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Completed 1/3 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 59.9s of the -2.88s of remaining time.\n",
      "\t-90.7699\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 62.96s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon_models/test_modelA\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models/test_modelB\"\n",
      "Presets specified: ['experimental_zeroshot_hpo_hybrid']\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=3\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"autogluon_models/test_modelB\"\n",
      "AutoGluon Version:  0.8.3b20231109\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Sat Jun 18 17:07:28 PDT 2022; root:xnu-8020.140.41~1/RELEASE_ARM64_T8110\n",
      "Disk Space Avail:   9.05 GB / 245.11 GB (3.7%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "Train Data Rows:    28151\n",
      "Train Data Columns: 59\n",
      "Tuning Data Rows:    1440\n",
      "Tuning Data Columns: 59\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 95.92698, 204.47518)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:223: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2874.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.2 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['observed_or_estimated']\n",
      "\t\t('float', [])    : 57 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'is_in_shadow:idx', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 57 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'is_in_shadow:idx', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['observed_or_estimated']\n",
      "\t0.1s = Fit runtime\n",
      "\t58 features in original data used to generate 58 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.49 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'0': {'NN_TORCH': {}, 'GBM': [{'learning_rate': 0.05, 'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {'learning_rate': 0.021720607471727896, 'extra_trees': True, 'feature_fraction': 0.7832570544199176, 'min_data_in_leaf': 3, 'num_leaves': 21}], 'KNN': [{'weights': 'uniform'}], 'FASTAI': [{'layers': [200, 100, 50], 'emb_drop': 0.6046989241462619, 'ps': 0.09244767444160731, 'bs': 1024, 'lr': 0.00775309042164966, 'epochs': 48, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'ag_args': {'name_suffix': '_r51'}}], 'CAT': {}},\n",
      "\t'1': {'XT': [{}], 'RF': [{}, {'n_estimators': 300, 'max_leaf_nodes': 50000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'min_samples_leaf': 5, 'max_features': 0.5}], 'GBM': ['GBMLarge'], 'NN_TORCH': {}},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 5 L1 models ...\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 39.92s of the 59.9s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 221 due to low time. Expected time usage reduced from 54.1s -> 39.9s...\n",
      "\t-14.7827\t = Validation score   (-mean_absolute_error)\n",
      "\t24.75s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L1 ... Training model for up to 14.41s of the 34.38s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 182 due to low time. Expected time usage reduced from 23.6s -> 14.4s...\n",
      "\t-15.5848\t = Validation score   (-mean_absolute_error)\n",
      "\t8.67s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L1 ... Training model for up to 5.39s of the 25.37s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 215 due to low time. Expected time usage reduced from 7.5s -> 5.4s...\n",
      "\t-15.0905\t = Validation score   (-mean_absolute_error)\n",
      "\t3.49s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1.19s of the 21.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "2023-11-12 21:47:39,488\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:47:39,491\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6633, ip=127.0.0.1)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 207, in _fit\n",
      "    self._train_net(\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 326, in _train_net\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2023-11-12 21:47:39,494\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:47:39,496\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Completed 1/3 k-fold bagging repeats ...\n",
      "2023-11-12 21:47:39,497\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6630, ip=127.0.0.1)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 207, in _fit\n",
      "    self._train_net(\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 326, in _train_net\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2023-11-12 21:47:39,498\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6629, ip=127.0.0.1)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 207, in _fit\n",
      "    self._train_net(\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 326, in _train_net\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "2023-11-12 21:47:39,499\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_ray_fit()\u001b[39m (pid=6628, ip=127.0.0.1)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
      "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 854, in fit\n",
      "    out = self._fit(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 207, in _fit\n",
      "    self._train_net(\n",
      "  File \"/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/models/tabular_nn/torch/tabular_nn_torch.py\", line 326, in _train_net\n",
      "    raise TimeLimitExceeded\n",
      "autogluon.core.utils.exceptions.TimeLimitExceeded\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.9s of the 17.6s of remaining time.\n",
      "\t-14.7827\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 5 L2 models ...\n",
      "Fitting model: RandomForest_BAG_L2 ... Training model for up to 17.54s of the 17.53s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 77 due to low time. Expected time usage reduced from 68.0s -> 17.5s...\n",
      "\t-14.6489\t = Validation score   (-mean_absolute_error)\n",
      "\t10.51s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L2 ... Training model for up to 6.75s of the 6.73s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 79 due to low time. Expected time usage reduced from 25.4s -> 6.7s...\n",
      "\t-14.3583\t = Validation score   (-mean_absolute_error)\n",
      "\t4.24s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L2 ... Training model for up to 2.32s of the 2.31s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 92 due to low time. Expected time usage reduced from 7.5s -> 2.3s...\n",
      "\t-14.2863\t = Validation score   (-mean_absolute_error)\n",
      "\t1.71s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 0.27s of the 0.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L2.\n",
      "2023-11-12 21:48:00,359\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:48:00,360\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:48:00,361\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:48:00,364\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:48:00,364\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Completed 1/3 k-fold bagging repeats ...\n",
      "2023-11-12 21:48:00,365\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2023-11-12 21:48:00,366\tERROR worker.py:405 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 59.9s of the -3.26s of remaining time.\n",
      "\t-14.2449\t = Validation score   (-mean_absolute_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 63.34s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon_models/test_modelB\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models/test_modelC\"\n",
      "Presets specified: ['experimental_zeroshot_hpo_hybrid']\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=3\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"autogluon_models/test_modelC\"\n",
      "AutoGluon Version:  0.8.3b20231109\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Sat Jun 18 17:07:28 PDT 2022; root:xnu-8020.140.41~1/RELEASE_ARM64_T8110\n",
      "Disk Space Avail:   9.77 GB / 245.11 GB (4.0%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "Train Data Rows:    24195\n",
      "Train Data Columns: 59\n",
      "Tuning Data Rows:    1440\n",
      "Tuning Data Columns: 59\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 78.97668, 167.94356)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:223: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1319.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.97 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['observed_or_estimated']\n",
      "\t\t('float', [])    : 57 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'is_in_shadow:idx', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 57 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'is_in_shadow:idx', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['observed_or_estimated']\n",
      "\t0.1s = Fit runtime\n",
      "\t58 features in original data used to generate 58 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.49 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'0': {'NN_TORCH': {}, 'GBM': [{'learning_rate': 0.05, 'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {'learning_rate': 0.021720607471727896, 'extra_trees': True, 'feature_fraction': 0.7832570544199176, 'min_data_in_leaf': 3, 'num_leaves': 21}], 'KNN': [{'weights': 'uniform'}], 'FASTAI': [{'layers': [200, 100, 50], 'emb_drop': 0.6046989241462619, 'ps': 0.09244767444160731, 'bs': 1024, 'lr': 0.00775309042164966, 'epochs': 48, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'ag_args': {'name_suffix': '_r51'}}], 'CAT': {}, 'XGB': {}},\n",
      "\t'1': {'XT': [{}], 'RF': [{}, {'n_estimators': 300, 'max_leaf_nodes': 50000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'min_samples_leaf': 5, 'max_features': 0.5}], 'GBM': ['GBMLarge'], 'NN_TORCH': {}},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 5 L1 models ...\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 39.91s of the 59.89s of remaining time.\n",
      "\t-14.4674\t = Validation score   (-mean_absolute_error)\n",
      "\t21.51s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L1 ... Training model for up to 17.71s of the 37.69s of remaining time.\n",
      "\t-15.0458\t = Validation score   (-mean_absolute_error)\n",
      "\t9.27s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L1 ... Training model for up to 7.95s of the 27.93s of remaining time.\n",
      "\t-13.6703\t = Validation score   (-mean_absolute_error)\n",
      "\t3.43s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 3.86s of the 23.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.01%)\n",
      "\t-12.6506\t = Validation score   (-mean_absolute_error)\n",
      "\t4.93s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Completed 1/3 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.89s of the 16.96s of remaining time.\n",
      "\t-12.3129\t = Validation score   (-mean_absolute_error)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 5 L2 models ...\n",
      "Fitting model: RandomForest_BAG_L2 ... Training model for up to 16.89s of the 16.89s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 124 due to low time. Expected time usage reduced from 40.8s -> 16.9s...\n",
      "\t-12.8393\t = Validation score   (-mean_absolute_error)\n",
      "\t10.45s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L2 ... Training model for up to 6.13s of the 6.12s of remaining time.\n",
      "\t-12.7059\t = Validation score   (-mean_absolute_error)\n",
      "\t10.51s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Completed 1/3 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 59.89s of the -4.89s of remaining time.\n",
      "\t-12.0535\t = Validation score   (-mean_absolute_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 64.97s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon_models/test_modelC\")\n"
     ]
    }
   ],
   "source": [
    "def train_model(dataset):\n",
    "    # Define the path where the AutoGluon models will be saved\n",
    "    # enumerate all the locations\n",
    "    for index, location in enumerate(locations):\n",
    "        save_path = f\"autogluon_models/test_model{location}\"\n",
    "\n",
    "        if location == \"A\":\n",
    "            hyperparameters = hyperparameters_a\n",
    "        elif location == \"B\":\n",
    "            hyperparameters = hyperparameters_b\n",
    "        else: \n",
    "            hyperparameters = hyperparameters_c\n",
    "\n",
    "        model = TabularPredictor(\n",
    "            label=\"pv_measurement\", path=save_path, eval_metric=\"mae\"\n",
    "        )\n",
    "        model.fit(\n",
    "            train_data=dataset[index].dropna(subset=[\"pv_measurement\"]),\n",
    "            tuning_data=combined_df_validation[index].dropna(subset=[\"pv_measurement\"]),\n",
    "            presets=\"experimental_zeroshot_hpo_hybrid\",\n",
    "            use_bag_holdout=True,\n",
    "            hyperparameters={0: hyperparameters, 1: level_2_hyperparameters},\n",
    "            num_bag_sets=3,\n",
    "            num_stack_levels=1,\n",
    "        )\n",
    "\n",
    "\n",
    "train_model(combined_df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models/test_modelA-2\"\n",
      "Presets specified: ['experimental_zeroshot_hpo_hybrid']\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=3\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"autogluon_models/test_modelA-2\"\n",
      "AutoGluon Version:  0.8.3b20231109\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Sat Jun 18 17:07:28 PDT 2022; root:xnu-8020.140.41~1/RELEASE_ARM64_T8110\n",
      "Disk Space Avail:   9.88 GB / 245.11 GB (4.0%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "Train Data Rows:    32643\n",
      "Train Data Columns: 59\n",
      "Tuning Data Rows:    1440\n",
      "Tuning Data Columns: 59\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 645.05153, 1177.24683)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:223: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2464.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.6 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  1 | ['observed_or_estimated']\n",
      "\t\t('float', [])    : 57 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'is_in_shadow:idx', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 57 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'is_in_shadow:idx', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['observed_or_estimated']\n",
      "\t0.1s = Fit runtime\n",
      "\t58 features in original data used to generate 58 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.62 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "use_bag_holdout=True, will use tuning_data as holdout (will not be used for early stopping).\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'0': {'NN_TORCH': {}, 'GBM': [{'learning_rate': 0.05, 'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, 'GBMLarge', {'learning_rate': 0.021720607471727896, 'extra_trees': True, 'feature_fraction': 0.7832570544199176, 'min_data_in_leaf': 3, 'num_leaves': 21}], 'FASTAI': [{'layers': [200, 100, 50], 'emb_drop': 0.6046989241462619, 'ps': 0.09244767444160731, 'bs': 1024, 'lr': 0.00775309042164966, 'epochs': 48, 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0, 'ag_args': {'name_suffix': '_r51'}}]},\n",
      "\t'1': {'XT': [{}], 'RF': [{}, {'n_estimators': 300, 'max_leaf_nodes': 50000, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'min_samples_leaf': 5, 'max_features': 0.5}], 'GBM': ['GBMLarge'], 'NN_TORCH': {}},\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 5 L1 models ...\n",
      "Fitting model: RandomForest_BAG_L1 ... Training model for up to 39.92s of the 59.89s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 227 due to low memory. Expected memory usage reduced from 19.8% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 227 -> 205 due to low time. Expected time usage reduced from 44.0s -> 39.9s...\n",
      "\t-95.6405\t = Validation score   (-mean_absolute_error)\n",
      "\t26.26s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: RandomForest_2_BAG_L1 ... Training model for up to 12.52s of the 32.5s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 142 due to low time. Expected time usage reduced from 26.3s -> 12.5s...\n",
      "\t-98.8142\t = Validation score   (-mean_absolute_error)\n",
      "\t7.74s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: ExtraTrees_BAG_L1 ... Training model for up to 4.44s of the 24.41s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 227 due to low memory. Expected memory usage reduced from 19.8% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 227 -> 134 due to low time. Expected time usage reduced from 7.5s -> 4.4s...\n"
     ]
    }
   ],
   "source": [
    "# shuffle dataset so that a slightly different model is trained\n",
    "combined_df_train = shuffle(combined_df_train, random_state=69)\n",
    "\n",
    "# Model 1\n",
    "def train_model(dataset):\n",
    "    # Define the path where the AutoGluon models will be saved\n",
    "    for index, location in enumerate(locations):\n",
    "        save_path = f\"autogluon_models/test_model{location}-2\"\n",
    "\n",
    "        if location == \"A\":\n",
    "            hyperparameters = hyperparameters_a\n",
    "        elif location == \"B\":\n",
    "            hyperparameters = hyperparameters_b\n",
    "        else: \n",
    "            hyperparameters = hyperparameters_c\n",
    "\n",
    "        # Initialize the TabularPredictor object\n",
    "        model = TabularPredictor(\n",
    "            label=\"pv_measurement\", path=save_path, eval_metric=\"mae\"\n",
    "        )\n",
    "        model.fit(\n",
    "            train_data=dataset[index].dropna(subset=[\"pv_measurement\"]),\n",
    "            tuning_data=combined_df_validation[index].dropna(subset=[\"pv_measurement\"]),\n",
    "            presets=\"experimental_zeroshot_hpo_hybrid\",\n",
    "            use_bag_holdout=True,\n",
    "            hyperparameters={0: hyperparameters, 1: level_2_hyperparameters},\n",
    "            num_bag_sets=3,\n",
    "            num_stack_levels=1,\n",
    "        )\n",
    "\n",
    "\n",
    "# Train the model using all available training data and the initial validation set for early stopping\n",
    "train_model(combined_df_train2)\n",
    "\n",
    "# Evaluate the model using the same validation set\n",
    "# evaluate_model(combined_X_val, combined_Y_val, location, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have defined WEATHER_FEATURES, TEST_COLUMNS_TO_KEEP, and other functions previously\n",
    "\n",
    "def make_predictions(df_test_pred, location):\n",
    "    eval_model1 = TabularPredictor.load(f\"autogluon_models/test_model{location}\", require_version_match=False)\n",
    "    preds1 = eval_model1.predict(df_test_pred)\n",
    "    eval_model2 = TabularPredictor.load(f\"autogluon_models/test_model{location}-2\", require_version_match=False)\n",
    "    preds2 = eval_model2.predict(df_test_pred)\n",
    "    return (preds1 + preds2) / 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    True\n",
      "1    True\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "Name: location, dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_3184/2689837874.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 5.18739223e-01  5.18772125e-01  5.54042459e-01  6.39966278e+01\n",
      "  3.15282288e+02  9.79294556e+02  2.10690430e+03  3.01765039e+03\n",
      "  2.70298633e+03  2.56971826e+03  2.98400366e+03  3.04538184e+03\n",
      "  2.26180176e+03  2.69479102e+03  2.14400391e+03  1.40218628e+03\n",
      "  1.14251514e+03  5.49433167e+02  2.18173706e+02  2.29379082e+01\n",
      "  5.26592791e-01  5.29130399e-01  5.19395709e-01  5.20543754e-01\n",
      "  5.62234104e-01  5.62010407e-01  1.21563685e+00  1.73876862e+02\n",
      "  5.77013306e+02  1.36711243e+03  2.48477710e+03  3.31022803e+03\n",
      "  3.64051562e+03  3.89455029e+03  3.74186279e+03  3.99752344e+03\n",
      "  3.92075732e+03  4.01970361e+03  3.12267383e+03  2.67892041e+03\n",
      "  1.69434937e+03  8.40627258e+02  4.10089355e+02  9.58433762e+01\n",
      "  1.42300749e+00  5.27954936e-01  5.50508559e-01  5.47413945e-01\n",
      "  6.01120174e-01  5.25662601e-01  2.95794258e+01  2.51335907e+02\n",
      "  6.83188171e+02  1.43490820e+03  2.66009521e+03  3.42447314e+03\n",
      "  4.40780713e+03  4.77009473e+03  4.58917578e+03  4.36174365e+03\n",
      "  4.20555371e+03  3.70414844e+03  2.70482471e+03  2.10591748e+03\n",
      "  1.40475635e+03  8.23594788e+02  4.12826660e+02  1.53446854e+02\n",
      "  3.46055269e+00  5.24525881e-01  5.24436235e-01  4.85473812e-01\n",
      "  5.19568503e-01  5.19281566e-01  1.79878082e+01  1.41365082e+02\n",
      "  5.59121765e+02  1.51664575e+03  2.62219507e+03  3.31267432e+03\n",
      "  3.22988062e+03  3.37954907e+03  3.28293994e+03  3.39700024e+03\n",
      "  3.00024902e+03  3.22054297e+03  3.13145508e+03  2.49704834e+03\n",
      "  1.72854126e+03  6.60592651e+02  2.94225708e+02  1.22033524e+02\n",
      "  3.29757667e+00  5.12467563e-01  5.17134905e-01  5.15401423e-01\n",
      "  5.18276453e-01  5.54409206e-01  4.78479805e+01  2.23230270e+02\n",
      "  6.31299927e+02  1.72596790e+03  2.85602100e+03  3.40910645e+03\n",
      "  4.41487256e+03  4.64644434e+03  4.70935254e+03  4.71247266e+03\n",
      "  4.57299512e+03  4.09643701e+03  3.32534399e+03  2.74425977e+03\n",
      "  2.03296216e+03  9.35360962e+02  4.49180695e+02  1.99772781e+02\n",
      "  2.09200115e+01 -5.59148908e-01 -7.91250825e-01 -1.70117712e+00\n",
      "  5.10155141e-01  7.22933888e-01  5.65067482e+01  2.43393372e+02\n",
      "  7.35936890e+02  1.82832153e+03  2.60644336e+03  3.48041431e+03\n",
      "  4.11991602e+03  3.67335327e+03  3.71293896e+03  3.26299829e+03\n",
      "  3.40229150e+03  3.17956860e+03  2.91862695e+03  2.19382056e+03\n",
      "  1.62939209e+03  8.87424805e+02  4.65336426e+02  1.97295166e+02\n",
      "  2.40435619e+01  5.18477082e-01  5.16714692e-01  5.30490577e-01\n",
      "  5.31029701e-01  7.28110075e-01  6.41104507e+01  2.49818054e+02\n",
      "  7.13564941e+02  1.84798926e+03  2.80954492e+03  3.73955640e+03\n",
      "  4.22383057e+03  4.44452441e+03  4.17836865e+03  4.10828223e+03\n",
      "  3.53037158e+03  3.28816699e+03  2.92974829e+03  2.41635620e+03\n",
      "  1.58739893e+03  8.55639404e+02  4.23308289e+02  1.84450684e+02\n",
      "  1.33073568e+01  5.32014132e-01  5.32607615e-01  5.23134828e-01\n",
      "  5.58899462e-01  4.88365471e-01  8.69080162e+00  5.53094559e+01\n",
      "  9.88314972e+01  1.80203903e+02  2.28788300e+02  3.87082642e+02\n",
      "  6.58812012e+02  7.28078674e+02  8.69444824e+02  1.45222607e+03\n",
      "  2.17427881e+03  2.07332422e+03  2.29219043e+03  1.79699219e+03\n",
      "  8.73011658e+02  4.84416412e+02  2.75909485e+02  1.71558624e+02\n",
      "  2.45037956e+01  5.32625556e-01  5.30498147e-01  4.90816474e-01\n",
      "  5.32769263e-01  5.67410827e-01  3.64360771e+01  1.56433807e+02\n",
      "  3.43432892e+02  8.18057129e+02  1.33757471e+03  2.09660400e+03\n",
      "  1.87821619e+03  2.11398999e+03  2.67339941e+03  2.44605786e+03\n",
      "  2.72881299e+03  2.83840454e+03  2.22161450e+03  1.25258984e+03\n",
      "  7.97633057e+02  3.46901733e+02  2.08822266e+02  7.42741394e+01\n",
      "  2.95649481e+00  5.12922585e-01  6.00924253e-01  5.19721925e-01\n",
      "  5.19568503e-01  6.03727281e-01  3.26104431e+01  1.06778641e+02\n",
      "  1.89476440e+02  3.61192566e+02  8.11609131e+02  1.36828455e+03\n",
      "  2.08849512e+03  1.70801941e+03  1.50841943e+03  1.33480420e+03\n",
      "  1.18974976e+03  9.97773438e+02  8.50244019e+02  6.48840332e+02\n",
      "  4.59516541e+02  3.51788452e+02  2.08687195e+02  4.88138123e+01\n",
      "  1.25363255e+01  5.27927279e-01  5.29559493e-01  5.31235337e-01\n",
      "  5.30156970e-01  5.75927854e-01  2.13355312e+01  9.79714890e+01\n",
      "  2.76154205e+02  9.46305786e+02  1.33059753e+03  1.57662671e+03\n",
      "  1.70696265e+03  1.48670984e+03  2.07128271e+03  1.98108618e+03\n",
      "  2.63204590e+03  2.83542114e+03  2.47894312e+03  1.95914404e+03\n",
      "  1.26843066e+03  7.08765442e+02  4.26923187e+02  1.92769257e+02\n",
      "  4.97891159e+01  5.68344653e-01  5.20124912e-01  4.81811315e-01\n",
      "  5.09771943e-01  8.91934097e-01  6.18321114e+01  1.46415375e+02\n",
      "  3.42012665e+02  7.03757629e+02  1.23775806e+03  1.20635278e+03\n",
      "  1.37460010e+03  1.30325232e+03  1.49512085e+03  1.33049316e+03\n",
      "  1.27928284e+03  9.26692566e+02  1.12068018e+03  7.57221191e+02\n",
      "  5.17978027e+02  3.00692108e+02  2.03943604e+02  7.42849350e+01\n",
      "  7.83505011e+00  5.03247023e-01  4.80752468e-01  4.81458783e-01\n",
      "  5.35779715e-01  4.04614925e+00  6.36246338e+01  1.57492554e+02\n",
      "  4.01798920e+02  9.06086426e+02  1.17853003e+03  1.21219946e+03\n",
      "  1.56643774e+03  2.44169043e+03  2.55033789e+03  1.71908179e+03\n",
      "  1.58277979e+03  1.58747839e+03  1.60398523e+03  1.33997034e+03\n",
      "  1.25659790e+03  6.33183716e+02  3.30920898e+02  1.83687302e+02\n",
      "  3.57319336e+01  6.03457749e-01  5.29600739e-01  5.01022935e-01\n",
      "  5.17558336e-01  2.02753353e+00  5.74122047e+01  1.87448776e+02\n",
      "  4.19187073e+02  8.00428833e+02  1.19364160e+03  1.87060767e+03\n",
      "  2.62795410e+03  3.26777832e+03  2.47394653e+03  2.60402832e+03\n",
      "  1.92198547e+03  1.55118164e+03  1.16956348e+03  8.50902100e+02\n",
      "  6.99594360e+02  3.64097534e+02  1.67410980e+02  6.16070251e+01\n",
      "  8.25521851e+00  5.35739124e-01  5.28844714e-01  5.30691803e-01\n",
      "  5.25723934e-01  1.18079758e+00  1.56754723e+01  7.58215485e+01\n",
      "  2.32223755e+02  4.43774902e+02  6.58754272e+02  8.35171936e+02\n",
      "  1.10950439e+03  1.24451318e+03  1.12020374e+03  1.23204077e+03\n",
      "  1.22127295e+03  1.06443506e+03  9.32505981e+02  8.31470947e+02\n",
      "  6.17261169e+02  3.74854309e+02  2.13009857e+02  1.21232193e+02\n",
      "  2.43222084e+01  5.55821776e-01  5.25835991e-01  5.20433724e-01\n",
      "  5.19976139e-01  2.21768570e+00  4.88745346e+01  1.73757980e+02\n",
      "  2.88216888e+02  5.49736633e+02  7.91049011e+02  8.70786621e+02\n",
      "  1.43183813e+03  1.44823267e+03  1.48288159e+03  2.00461841e+03\n",
      "  1.89178052e+03  1.28779736e+03  8.69484680e+02  8.28921387e+02\n",
      "  7.98741455e+02  5.02835205e+02  2.32005722e+02  8.19365692e+01\n",
      "  7.75904369e+00  5.44930339e-01  5.28048933e-01  5.27724564e-01\n",
      "  5.22085369e-01  4.43585682e+00  5.09239960e+01  1.22705353e+02\n",
      "  2.67203979e+02  4.08053467e+02  5.12163269e+02  6.94755249e+02\n",
      "  8.75447876e+02  1.15404492e+03  1.23650024e+03  1.33874658e+03\n",
      "  1.33784937e+03  1.21434070e+03  1.10566321e+03  8.51084717e+02\n",
      "  9.89323853e+02  8.91537109e+02  4.54068604e+02  2.08928528e+02\n",
      "  7.63941803e+01  2.45190191e+00  5.31064332e-01  5.30010521e-01\n",
      "  6.59984827e-01  1.80920677e+01  1.26621201e+02  3.60018616e+02\n",
      "  8.77075867e+02  1.95968872e+03  3.14599463e+03  4.06297266e+03\n",
      "  4.70737109e+03  5.07069434e+03  5.09992773e+03  4.94365918e+03\n",
      "  4.66339111e+03  4.20700244e+03  3.46044702e+03  2.80976123e+03\n",
      "  2.13306299e+03  1.25528625e+03  6.35354004e+02  3.34985565e+02\n",
      "  1.40764404e+02  3.75847578e+00  5.20246863e-01  4.73981738e-01\n",
      "  5.65674126e-01  1.79322262e+01  1.24815620e+02  3.11184937e+02\n",
      "  7.32637695e+02  1.34819116e+03  2.12617090e+03  3.26381030e+03\n",
      "  4.18241699e+03  4.56081055e+03  3.57156494e+03  2.13098608e+03\n",
      "  1.32792273e+03  8.76209961e+02  9.99421753e+02  1.05807788e+03\n",
      "  9.86452576e+02  5.42770142e+02  2.85501160e+02  1.71171204e+02\n",
      "  5.92470703e+01  3.50766969e+00  5.27465641e-01  5.26453733e-01\n",
      "  5.07895350e-01  8.57409286e+00  4.53848114e+01  1.62516159e+02\n",
      "  3.75660217e+02  1.01651483e+03  2.24682812e+03  3.13127295e+03\n",
      "  3.68034180e+03  4.44237695e+03  4.28712695e+03  4.47953320e+03\n",
      "  4.41448193e+03  4.04001172e+03  3.39875928e+03  2.77727100e+03\n",
      "  2.04578540e+03  1.24920337e+03  6.28466003e+02  3.24836609e+02\n",
      "  1.36586746e+02  5.94772863e+00  5.47396183e-01  5.39650679e-01\n",
      "  5.64055741e-01  2.08329048e+01  1.18807922e+02  3.20850769e+02\n",
      "  8.28097473e+02  1.78979565e+03  2.67150098e+03  3.52432129e+03\n",
      "  4.47347998e+03  4.95111377e+03  5.04723486e+03  4.99755518e+03\n",
      "  4.61810156e+03  4.21228857e+03  3.41464551e+03  2.81752808e+03\n",
      "  2.03843066e+03  1.27030981e+03  6.48331421e+02  3.43298981e+02\n",
      "  1.47233124e+02  6.43581295e+00  5.21519542e-01  4.85878021e-01\n",
      "  5.25858641e-01  1.54293242e+01  1.23200211e+02  3.32023621e+02\n",
      "  8.11519897e+02  1.56754175e+03  2.30209424e+03  3.64758276e+03\n",
      "  4.33768213e+03  4.61156055e+03  4.46194629e+03  3.80170996e+03\n",
      "  3.36128223e+03  3.12798291e+03  2.59173218e+03  2.27337354e+03\n",
      "  1.51935132e+03  8.03267334e+02  3.86599396e+02  2.23381409e+02\n",
      "  6.94528351e+01  2.86604428e+00  3.02734315e-01  2.21249953e-01\n",
      "  4.94651020e-01  6.43775368e+00  4.68600311e+01  1.04062050e+02\n",
      "  2.76030457e+02  5.43707458e+02  6.49848022e+02  9.70747314e+02\n",
      "  9.07359192e+02  1.00392499e+03  2.18824023e+03  3.62944824e+03\n",
      "  3.63804639e+03  3.57786206e+03  3.03891064e+03  2.47501733e+03\n",
      "  1.67408325e+03  1.06563013e+03  5.50689514e+02  2.84720459e+02\n",
      "  1.05491013e+02  5.30744171e+00  2.02965468e-01  2.40827739e-01\n",
      "  1.39322007e+00  6.31565952e+00  2.63292160e+01  8.13395233e+01\n",
      "  8.05767365e+01  1.81696350e+02  3.83434753e+02  6.78380859e+02\n",
      "  1.19770728e+03  1.32746130e+03  1.22412134e+03  1.15649438e+03\n",
      "  1.40417041e+03  2.25286206e+03  2.40940942e+03  2.04506995e+03\n",
      "  1.37113098e+03  7.82606750e+02  4.00798706e+02  1.60743073e+02\n",
      "  5.26881256e+01  2.25687313e+00  5.05459964e-01  5.41461468e-01\n",
      "  6.64196968e-01  2.31536331e+01  1.26871231e+02  3.20854431e+02\n",
      "  7.94421021e+02  1.78515564e+03  2.84326807e+03  3.74355591e+03\n",
      "  4.26058105e+03  4.39909766e+03  4.49467773e+03  4.45648584e+03\n",
      "  3.78021924e+03  3.14063477e+03  2.85841895e+03  1.94007849e+03\n",
      "  1.38128857e+03  8.54758057e+02  4.11333557e+02  2.31639221e+02\n",
      "  1.12860451e+02  6.59330177e+00  7.48428702e-01  6.02566361e-01\n",
      "  5.06600738e-01  1.44643841e+01  1.08131737e+02  2.90504944e+02\n",
      "  7.17885742e+02  1.57584058e+03  2.56096411e+03  3.42991064e+03\n",
      "  4.21913135e+03  4.42677734e+03  4.79178320e+03  4.77256250e+03\n",
      "  4.45599365e+03  3.77050635e+03  2.81775684e+03  2.05606616e+03\n",
      "  1.33604773e+03  9.78187683e+02  5.12790283e+02  2.90354675e+02\n",
      "  1.03332367e+02  4.39812851e+00  5.35892427e-01  5.58661342e-01\n",
      "  5.52125990e-01  8.37393188e+00  9.69078369e+01  2.56104492e+02\n",
      "  3.41676117e+02  5.37734558e+02  7.55500366e+02  8.55764282e+02\n",
      "  9.89274902e+02  1.35933740e+03  1.23940186e+03  1.03840125e+03\n",
      "  1.43989990e+03  1.01354718e+03  8.67192688e+02  7.66890625e+02\n",
      "  5.44744629e+02  2.78120667e+02  1.52394180e+02  7.00602417e+01\n",
      "  1.42627583e+01  1.04265118e+00  6.76184535e-01  7.16108441e-01\n",
      "  5.59655547e-01  2.49309921e+00  1.90500488e+01  7.06222839e+01\n",
      "  9.84713440e+01  1.64702026e+02  2.60716064e+02  5.10460632e+02\n",
      "  5.23531799e+02  5.71032471e+02  5.45640381e+02  6.30316223e+02\n",
      "  7.63312744e+02  8.13366638e+02  7.24661499e+02  6.47179077e+02\n",
      "  6.25096069e+02  4.13208893e+02  2.43390747e+02  1.36079559e+02\n",
      "  3.75844879e+01  1.91990566e+00  5.58089674e-01  7.56738245e-01\n",
      "  5.25367200e-01  1.39707880e+01  1.06599289e+02  2.42107330e+02\n",
      "  5.51208069e+02  1.14985034e+03  1.98364941e+03  2.52556152e+03\n",
      "  3.65211475e+03  4.17895508e+03  4.22911475e+03  4.14234082e+03\n",
      "  3.57577295e+03  3.10905518e+03  1.87045581e+03  1.37393848e+03\n",
      "  7.32310120e+02  5.27853516e+02  3.15172821e+02  1.93392227e+02\n",
      "  7.79517670e+01  4.42780876e+00  2.21969068e-01  3.38051319e-01\n",
      "  1.20129019e-01  5.86685181e+00  5.36296234e+01  1.68766327e+02\n",
      "  2.44720184e+02  2.54662979e+02  3.26082703e+02  4.97819580e+02\n",
      "  1.49187427e+03  2.15836670e+03  2.59457886e+03  3.07405176e+03\n",
      "  2.18178491e+03  1.62798047e+03  1.10261353e+03  8.54924255e+02\n",
      "  6.96738586e+02  4.91839783e+02  2.90584656e+02  1.67528763e+02\n",
      "  6.45944366e+01  3.29004622e+00  5.54493189e-01  3.47945118e+00]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_submission.loc[mask, \"prediction\"] = preds.to_numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: location, dtype: bool\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: location, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df_submission = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "for index, location in enumerate(locations): \n",
    "    preds = make_predictions(combined_df_test[index], location)\n",
    "\n",
    "    # Assign the predictions to df_submission for the current location\n",
    "    mask = df_submission[\"location\"] == location\n",
    "    print(mask.head())\n",
    "    # Add a check to make sure the lengths match\n",
    "    if len(preds) != mask.sum():\n",
    "        print(f\"Length of predictions: {len(preds)}\")\n",
    "        print(f\"Length of submission entries: {mask.sum()}\")\n",
    "        raise ValueError(f\"Mismatch in length of predictions and submission entries for location {location}.\")\n",
    "\n",
    "    df_submission.loc[mask, \"prediction\"] = preds.to_numpy()\n",
    "\n",
    "df_submission['prediction'] = df_submission['prediction'].apply(lambda x: max(x, 0))\n",
    "\n",
    "df_submission['prediction'] = df_submission['prediction'].apply(lambda x: 0 if x < 1.5 else x)\n",
    "\n",
    "\n",
    "# Set predictions to zero where up to three non-zero predictions are surrounded by zeros\n",
    "for i in range(1, len(df_submission) - 1):\n",
    "    # Check single non-zero prediction surrounded by zeros\n",
    "    if df_submission.loc[i - 1, 'prediction'] == 0 and df_submission.loc[i + 1, 'prediction'] == 0:\n",
    "        df_submission.loc[i, 'prediction'] = 0\n",
    "    # Check two consecutive non-zero predictions surrounded by zeros\n",
    "    if i < len(df_submission) - 2 and df_submission.loc[i - 1, 'prediction'] == 0 and df_submission.loc[i + 2, 'prediction'] == 0:\n",
    "        df_submission.loc[i, 'prediction'] = 0\n",
    "        df_submission.loc[i + 1, 'prediction'] = 0\n",
    "    # Check three consecutive non-zero predictions surrounded by zeros\n",
    "\n",
    "\n",
    "# Save the results to a new submission file\n",
    "df_submission[[\"id\", \"prediction\"]].to_csv(\"predictions/short-storybook.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
