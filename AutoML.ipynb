{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries to run AutoML\n",
    "import sys, os, os.path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initalize functions and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [\"A\", \"B\", \"C\"]\n",
    "scaler = None\n",
    "features_order = []\n",
    "\n",
    "LAGGED_COLUMNS_TO_KEEP = [\n",
    "    'direct_rad:W_lag_1h', \n",
    "    'direct_rad:W_lag_forward_1h', \n",
    "    'clear_sky_rad:W_lag_1h', \n",
    "    'clear_sky_rad:W_lag_forward_1h', \n",
    "    'diffuse_rad:W_lag_1h', \n",
    "    'diffuse_rad:W_lag_forward_1h', \n",
    "    'direct_rad_1h:J_lag_1h', \n",
    "    'direct_rad_1h:J_lag_forward_1h', \n",
    "    'is_in_shadow:idx_lag_1h', \n",
    "    'is_in_shadow:idx_lag_forward_1h', \n",
    "    'clear_sky_energy_1h:J_lag_1h', \n",
    "    'clear_sky_energy_1h:J_lag_forward_1h', \n",
    "    'effective_cloud_cover:p_lag_1h', \n",
    "    'effective_cloud_cover:p_lag_forward_1h', \n",
    "    'visibility:m_lag_1h', \n",
    "    'visibility:m_lag_forward_1h', \n",
    "    'total_cloud_cover:p_lag_1h', \n",
    "    'total_cloud_cover:p_lag_forward_1h', \n",
    "\n",
    "    'direct_rad:W_lag_3h', \n",
    "    'direct_rad:W_lag_forward_3h', \n",
    "    'clear_sky_rad:W_lag_3h', \n",
    "    'clear_sky_rad:W_lag_forward_3h', \n",
    "    'diffuse_rad:W_lag_3h', \n",
    "    'diffuse_rad:W_lag_forward_3h', \n",
    "    'direct_rad_1h:J_lag_3h', \n",
    "    'direct_rad_1h:J_lag_forward_3h', \n",
    "    'is_in_shadow:idx_lag_3h', \n",
    "    'is_in_shadow:idx_lag_forward_3h', \n",
    "    'clear_sky_energy_1h:J_lag_3h', \n",
    "    'clear_sky_energy_1h:J_lag_forward_3h', \n",
    "    'effective_cloud_cover:p_lag_3h', \n",
    "    'effective_cloud_cover:p_lag_forward_3h', \n",
    "    'visibility:m_lag_3h', \n",
    "    'visibility:m_lag_forward_3h', \n",
    "    'total_cloud_cover:p_lag_3h', \n",
    "    'total_cloud_cover:p_lag_forward_3h'\n",
    "]\n",
    "\n",
    "CUSTOM_COLUMNS_TO_KEEP = [\n",
    "    \"hour_cos\",\n",
    "    \"hour_sin\",\n",
    "    \"month_sin\",\n",
    "    \"month_cos\",\n",
    "    \"day-of-year\",\n",
    "]\n",
    "\n",
    "WEATHER_FEATURES = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "]\n",
    "\n",
    "\n",
    "COLUMNS_TO_KEEP = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"diffuse_rad_1h:J\",\n",
    "    \"is_day:idx\",\n",
    "    \"sun_elevation:d\",\n",
    "    # \"ceiling_height_agl:m\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "    \"air_density_2m:kgm3\",\n",
    "    \"wind_speed_v_10m:ms\",\n",
    "    \"dew_point_2m:K\",\n",
    "    \"wind_speed_u_10m:ms\",\n",
    "    \"t_1000hPa:K\",\n",
    "    \"absolute_humidity_2m:gm3\",\n",
    "     \"snow_water:kgm2\",\n",
    "    \"relative_humidity_1000hPa:p\",\n",
    "    \"fresh_snow_24h:cm\",\n",
    "    \"cloud_base_agl:m\",\n",
    "    \"fresh_snow_12h:cm\",\n",
    "    \"snow_depth:cm\",\n",
    "    \"dew_or_rime:idx\",\n",
    "    \"fresh_snow_6h:cm\",\n",
    "    \"super_cooled_liquid_water:kgm2\",\n",
    "    \"fresh_snow_3h:cm\",\n",
    "    \"rain_water:kgm2\",\n",
    "    \"precip_type_5min:idx\",\n",
    "    \"precip_5min:mm\",\n",
    "    \"fresh_snow_1h:cm\",\n",
    "    \"sun_azimuth:d\",\n",
    "    \"msl_pressure:hPa\",\n",
    "    \"pressure_100m:hPa\",\n",
    "    \"pressure_50m:hPa\",\n",
    "    \"sfc_pressure:hPa\",\n",
    "    \"prob_rime:p\",\n",
    "    \"wind_speed_10m:ms\",\n",
    "    \"elevation:m\",\n",
    "    # \"snow_density:kgm3\",\n",
    "    \"snow_drift:idx\",\n",
    "    \"snow_melt_10min:mm\",\n",
    "    \"wind_speed_w_1000hPa:ms\",\n",
    "    # \"date_calc\",\n",
    "    \"pv_measurement\",\n",
    "] + CUSTOM_COLUMNS_TO_KEEP + LAGGED_COLUMNS_TO_KEEP\n",
    "\n",
    "TEST_COLUMNS_TO_KEEP = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"diffuse_rad_1h:J\",\n",
    "    \"is_day:idx\",\n",
    "    \"sun_elevation:d\",\n",
    "    # \"ceiling_height_agl:m\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "    \"air_density_2m:kgm3\",\n",
    "    \"wind_speed_v_10m:ms\",\n",
    "    \"dew_point_2m:K\",\n",
    "    \"wind_speed_u_10m:ms\",\n",
    "    \"t_1000hPa:K\",\n",
    "    \"absolute_humidity_2m:gm3\",\n",
    "    \"snow_water:kgm2\",\n",
    "    \"relative_humidity_1000hPa:p\",\n",
    "    \"fresh_snow_24h:cm\",\n",
    "    \"cloud_base_agl:m\",\n",
    "    \"fresh_snow_12h:cm\",\n",
    "    \"snow_depth:cm\",\n",
    "    \"dew_or_rime:idx\",\n",
    "    \"fresh_snow_6h:cm\",\n",
    "    \"super_cooled_liquid_water:kgm2\",\n",
    "    \"fresh_snow_3h:cm\",\n",
    "    \"rain_water:kgm2\",\n",
    "    \"precip_type_5min:idx\",\n",
    "    \"precip_5min:mm\",\n",
    "    \"fresh_snow_1h:cm\",\n",
    "    \"sun_azimuth:d\",\n",
    "    \"msl_pressure:hPa\",\n",
    "    \"pressure_100m:hPa\",\n",
    "    \"pressure_50m:hPa\",\n",
    "    \"sfc_pressure:hPa\",\n",
    "    \"prob_rime:p\",\n",
    "    \"wind_speed_10m:ms\",\n",
    "    \"elevation:m\",\n",
    "    # \"snow_density:kgm3\",\n",
    "    \"snow_drift:idx\",\n",
    "    \"snow_melt_10min:mm\",\n",
    "    \"wind_speed_w_1000hPa:ms\",\n",
    "    # \"date_calc\",\n",
    "    # \"pv_measurement\",\n",
    "] + CUSTOM_COLUMNS_TO_KEEP + LAGGED_COLUMNS_TO_KEEP\n",
    "\n",
    "\n",
    "\n",
    "def create_weather_lagged_features(df, weather_features):\n",
    "    # Choose the weather features for which you want to create lagged versions\n",
    "    for feature in weather_features:\n",
    "        # Assuming hourly data, adjust the lags for your specific dataset\n",
    "        # Creating lagged features for 1 hour, 1 day, and 1 week\n",
    "        df[f'{feature}_lag_1h'] = df[feature].shift(1)\n",
    "        df[f'{feature}_lag_3h'] = df[feature].shift(2)\n",
    "        df[f'{feature}_lag_forward_1h'] = df[feature].shift(-1)\n",
    "        df[f'{feature}_lag_forward_3h'] = df[feature].shift(-2)\n",
    "        # df[f'{feature}_lag_24h'] = df[feature].shift(24*4)\n",
    "        # df[f'{feature}_lag_168h'] = df[feature].shift(24 * 7 * 4 * 365)\n",
    "        # df[f'{feature}_front_lag_1h'] = df[feature].shift(-4)\n",
    "        # df[f'{feature}_front_lag_24h'] = df[feature].shift(-24*4)\n",
    "\n",
    "\n",
    "    # Handling edges by filling NaNs with appropriate values or dropping them\n",
    "    # You may choose to fill with zeroes or interpolate, based on what makes more sense for your data\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "    df.fillna(method='bfill', inplace=True)  # Backward fill\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_lagged_features(df, column_name='pv_measurement'):\n",
    "    # Assuming 'date_forecast' is the datetime column used for sorting\n",
    "\n",
    "    df[f'{column_name}_prev_month'] = df[column_name].shift(24*7) # previous week\n",
    "\n",
    "    # For yearly lag, you would need to calculate the number of observations per year\n",
    "    # If the data is not consistent (leap years, etc.), you may need a more complex method\n",
    "    # Here's a simple version assuming 365 days a year:\n",
    "    df[f'{column_name}_prev_year'] = df[column_name].shift(24*365) # previous year\n",
    "    df[f'{column_name}_2years_ago'] = df[column_name].shift(24*365*2) # next year\n",
    "\n",
    "    # Handling edges by filling NaNs with appropriate values or dropping them\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "    df.fillna(method='bfill', inplace=True)  # Backward fill\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_custom_fields(df):\n",
    "     df['hour_sin'] = np.sin(2 * np.pi * df['date_forecast'].dt.hour / 24)\n",
    "     df['hour_cos'] = np.cos(2 * np.pi * df['date_forecast'].dt.hour / 24)\n",
    "\n",
    "     df['month_sin'] = np.sin(2 * np.pi * df['date_forecast'].dt.month / 12)\n",
    "     df['month_cos'] = np.cos(2 * np.pi * df['date_forecast'].dt.month / 12)\n",
    "     df['day-of-year'] = df['date_forecast'].dt.dayofyear\n",
    "     return df\n",
    "\n",
    "def remove_outliers(df):\n",
    "    # Use a mask to filter out the rows where rolling std is zero but keep the rows where the value itself is zero\n",
    "    mask = (df['pv_measurement'].rolling(5).std() == 0) & (df['pv_measurement'] != 0)\n",
    "    df = df[~mask]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a dictionary to hold the scalers for each location\n",
    "scalers = {}\n",
    "\n",
    "def prepare_data(location):\n",
    "    # Load data\n",
    "    scaling = False  # Set scaling to True to enable individual scaling for each location\n",
    "    global features_order\n",
    "    global scalers  # Use the global dictionary to store scalers\n",
    "\n",
    "    df_observed = pd.read_parquet(f\"data/{location}/X_train_observed.parquet\")\n",
    "    df_estimated = pd.read_parquet(f\"data/{location}/X_train_estimated.parquet\")\n",
    "    df_target = pd.read_parquet(f\"data/{location}/train_targets.parquet\")\n",
    "\n",
    "    # Combine observed and estimated datasets\n",
    "    df_combined = pd.concat([df_observed, df_estimated], axis=0).sort_values(by=\"date_forecast\")\n",
    "\n",
    "    df_combined = add_custom_fields(df_combined)\n",
    "    df_combined.set_index('date_forecast', inplace=True)\n",
    "    df_merged = df_combined.resample('1H').mean()\n",
    "\n",
    "    # Merge with target data\n",
    "    df_merged = pd.merge(df_merged, df_target, left_on=\"date_forecast\", right_on=\"time\", how=\"inner\")\n",
    "    \n",
    "    # One-hot encoding for location\n",
    "    df_merged['location'] = location\n",
    "    df_merged['location_A'] = (df_merged['location'] == 'A').astype(int)\n",
    "    df_merged['location_B'] = (df_merged['location'] == 'B').astype(int)\n",
    "    df_merged['location_C'] = (df_merged['location'] == 'C').astype(int)\n",
    "    df_merged.drop('location', axis=1, inplace=True)\n",
    "\n",
    "    df_merged = create_weather_lagged_features(df_merged, WEATHER_FEATURES)\n",
    "    df_merged = df_merged[COLUMNS_TO_KEEP]\n",
    "    df_merged = remove_outliers(df_merged)\n",
    "\n",
    "    y = df_merged[\"pv_measurement\"]\n",
    "    X = df_merged.drop(\"pv_measurement\", axis=1)\n",
    "    features_order = list(X.columns)\n",
    "    df_merged.fillna(0, inplace=True)  # Fill NaN values\n",
    "\n",
    "    # Apply Min-Max normalization to the features\n",
    "    if scaling: \n",
    "        # Check if a scaler for this location already exists\n",
    "        if location not in scalers:\n",
    "            scalers[location] = MinMaxScaler()\n",
    "            X_normalized = scalers[location].fit_transform(X)\n",
    "        else:\n",
    "            X_normalized = scalers[location].transform(X)\n",
    "\n",
    "        return pd.DataFrame(X_normalized, columns=X.columns), y\n",
    "    else: \n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Initialize H2O cluster\n",
    "h2o.init(\n",
    "    nthreads=-1,     # number of threads when launching a new H2O server\n",
    "    max_mem_size=8  # in gigabytes\n",
    ")\n",
    "X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Columns to train on\n",
    "\n",
    "cols = ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3',\n",
    "       'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W',\n",
    "       'cloud_base_agl:m', 'dew_point_2m:K', 'diffuse_rad:W',\n",
    "       'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J',\n",
    "       'effective_cloud_cover:p',\n",
    "       'is_day:idx', 'is_in_shadow:idx', 'msl_pressure:hPa', 'precip_5min:mm',\n",
    "       'precip_type_5min:idx', 'pressure_100m:hPa', 'pressure_50m:hPa',\n",
    "       'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p',\n",
    "       'sfc_pressure:hPa', \n",
    "       'sun_azimuth:d', 'sun_elevation:d',\n",
    "       't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m',\n",
    "       'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms',\n",
    "       'wind_speed_w_1000hPa:ms', 'location', 'direct_rad:W_ls',\n",
    "       'effective_cloud_cover:p_ls', 'clear_sky_rad:W_ls',\n",
    "       'sun_elevation:d_ls', 'diffuse_rad:W_ls', 'dew:idx', 'rime:idx',\n",
    "       'hour_diff', 'pv_measurement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Convert data into H2OFrame\n",
    "train = h2o.H2OFrame(pd.concat([X_train, y_train], axis=1))\n",
    "test = h2o.H2OFrame(pd.concat([X_test, y_test], axis=1))\n",
    "\n",
    "x = cols\n",
    "y = \"pv_measurement\"\n",
    "x.remove(y)\n",
    "\n",
    "# Set up max runtime and seed for AutoML\n",
    "aml = H2OAutoML(max_runtime_secs=3600, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Train AutoML model\n",
    "aml.train(x=x, y=y, training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# List of columns used during training\n",
    "columns_used_in_training = train.columns\n",
    "columns_used_in_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "model_ids = list(lb['model_id'].as_data_frame().iloc[:,0])\n",
    "lb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = aml.get_best_model()\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Save the three best models\n",
    "leaderboard = aml.leaderboard\n",
    "\n",
    "top5_model_ids = h2o.as_list(leaderboard['model_id'])['model_id'][:5]\n",
    "\n",
    "for idx, model_id in enumerate(top5_model_ids, 1):\n",
    "    model = h2o.get_model(model_id)\n",
    "    h2o.save_model(model=model, path=f\"../data_folder/models/model_ls_{idx}\", force=True)\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Inspect the model's performance on the test data\n",
    "perf = best_model.model_performance(test)\n",
    "print(perf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Show the model's actual predictions and the true values in the same dataframe\n",
    "pred = best_model.predict(test)\n",
    "pred_df = pred.as_data_frame()\n",
    "test_df = test.as_data_frame()\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "pred_df.reset_index(drop=True, inplace=True)\n",
    "merged_df = pd.concat([test_df, pred_df], axis=1)\n",
    "merged_df.rename(columns={'predict': 'prediction'}, inplace=True)\n",
    "merged_df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "explain_model = aml.explain(frame = train, figsize = (8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/Users/emmichewigand/.pyenv/versions/3.9.18/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
