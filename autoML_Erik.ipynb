{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from tpot import TPOTRegressor\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constans and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [\"A\", \"B\", \"C\"]\n",
    "features_order = []\n",
    "\n",
    "LAGGED_COLUMNS_TO_KEEP = [\n",
    "    'direct_rad:W_lag_1h', \n",
    "    'direct_rad:W_lag_forward_1h', \n",
    "    'clear_sky_rad:W_lag_1h', \n",
    "    'clear_sky_rad:W_lag_forward_1h', \n",
    "    'diffuse_rad:W_lag_1h', \n",
    "    'diffuse_rad:W_lag_forward_1h', \n",
    "    'direct_rad_1h:J_lag_1h', \n",
    "    'direct_rad_1h:J_lag_forward_1h', \n",
    "    'is_in_shadow:idx_lag_1h', \n",
    "    'is_in_shadow:idx_lag_forward_1h', \n",
    "    'clear_sky_energy_1h:J_lag_1h', \n",
    "    'clear_sky_energy_1h:J_lag_forward_1h', \n",
    "    'effective_cloud_cover:p_lag_1h', \n",
    "    'effective_cloud_cover:p_lag_forward_1h', \n",
    "    'visibility:m_lag_1h', \n",
    "    'visibility:m_lag_forward_1h', \n",
    "    'total_cloud_cover:p_lag_1h', \n",
    "    'total_cloud_cover:p_lag_forward_1h', \n",
    "\n",
    "\n",
    "    # 'direct_rad:W_lag_2h', \n",
    "    # 'direct_rad:W_lag_forward_2h', \n",
    "    # 'clear_sky_rad:W_lag_2h', \n",
    "    # 'clear_sky_rad:W_lag_forward_2h', \n",
    "    # 'diffuse_rad:W_lag_2h', \n",
    "    # 'diffuse_rad:W_lag_forward_2h', \n",
    "    # 'direct_rad_1h:J_lag_2h', \n",
    "    # 'direct_rad_1h:J_lag_forward_2h', \n",
    "    # 'is_in_shadow:idx_lag_2h', \n",
    "    # 'is_in_shadow:idx_lag_forward_2h', \n",
    "    # 'clear_sky_energy_1h:J_lag_2h', \n",
    "    # 'clear_sky_energy_1h:J_lag_forward_2h', \n",
    "    # 'effective_cloud_cover:p_lag_2h', \n",
    "    # 'effective_cloud_cover:p_lag_forward_2h', \n",
    "    # 'visibility:m_lag_2h', \n",
    "    # 'visibility:m_lag_forward_2h', \n",
    "    # 'total_cloud_cover:p_lag_2h', \n",
    "    # 'total_cloud_cover:p_lag_forward_2h', \n",
    "\n",
    "    # 'direct_rad:W_lag_3h', \n",
    "    # 'direct_rad:W_lag_forward_3h', \n",
    "    # 'clear_sky_rad:W_lag_3h', \n",
    "    # 'clear_sky_rad:W_lag_forward_3h', \n",
    "    # 'diffuse_rad:W_lag_3h', \n",
    "    # 'diffuse_rad:W_lag_forward_3h', \n",
    "    # 'direct_rad_1h:J_lag_3h', \n",
    "    # 'direct_rad_1h:J_lag_forward_3h', \n",
    "    # 'is_in_shadow:idx_lag_3h', \n",
    "    # 'is_in_shadow:idx_lag_forward_3h', \n",
    "    # 'clear_sky_energy_1h:J_lag_3h', \n",
    "    # 'clear_sky_energy_1h:J_lag_forward_3h', \n",
    "    # 'effective_cloud_cover:p_lag_3h', \n",
    "    # 'effective_cloud_cover:p_lag_forward_3h', \n",
    "    # 'visibility:m_lag_3h', \n",
    "    # 'visibility:m_lag_forward_3h', \n",
    "    # 'total_cloud_cover:p_lag_3h', \n",
    "    # 'total_cloud_cover:p_lag_forward_3h'\n",
    "]\n",
    "\n",
    "CUSTOM_COLUMNS_TO_KEEP = [\n",
    "    \"hour_cos\",\n",
    "    \"hour_sin\",\n",
    "    \"month_sin\",\n",
    "    \"month_cos\",\n",
    "    \"day-of-year\",\n",
    "]\n",
    "\n",
    "WEATHER_FEATURES = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "]\n",
    "\n",
    "\n",
    "COLUMNS_TO_KEEP = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"diffuse_rad_1h:J\",\n",
    "    \"is_day:idx\",\n",
    "    \"sun_elevation:d\",\n",
    "    # \"ceiling_height_agl:m\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "    \"air_density_2m:kgm3\",\n",
    "    \"wind_speed_v_10m:ms\",\n",
    "    \"dew_point_2m:K\",\n",
    "    \"wind_speed_u_10m:ms\",\n",
    "    \"t_1000hPa:K\",\n",
    "    \"absolute_humidity_2m:gm3\",\n",
    "     \"snow_water:kgm2\",\n",
    "    \"relative_humidity_1000hPa:p\",\n",
    "    \"fresh_snow_24h:cm\",\n",
    "    \"cloud_base_agl:m\",\n",
    "    \"fresh_snow_12h:cm\",\n",
    "    \"snow_depth:cm\",\n",
    "    \"dew_or_rime:idx\",\n",
    "    \"fresh_snow_6h:cm\",\n",
    "    \"super_cooled_liquid_water:kgm2\",\n",
    "    \"fresh_snow_3h:cm\",\n",
    "    \"rain_water:kgm2\",\n",
    "    \"precip_type_5min:idx\",\n",
    "    \"precip_5min:mm\",\n",
    "    \"fresh_snow_1h:cm\",\n",
    "    \"sun_azimuth:d\",\n",
    "    \"msl_pressure:hPa\",\n",
    "    \"pressure_100m:hPa\",\n",
    "    \"pressure_50m:hPa\",\n",
    "    \"sfc_pressure:hPa\",\n",
    "    \"prob_rime:p\",\n",
    "    \"wind_speed_10m:ms\",\n",
    "    \"elevation:m\",\n",
    "    # \"snow_density:kgm3\",\n",
    "    \"snow_drift:idx\",\n",
    "    \"snow_melt_10min:mm\",\n",
    "    \"wind_speed_w_1000hPa:ms\",\n",
    "    # \"location_A\",\n",
    "    # \"location_B\",\n",
    "    # \"location_C\",\n",
    "    # \"date_calc\",\n",
    "    \"pv_measurement\",\n",
    "] + CUSTOM_COLUMNS_TO_KEEP  +  LAGGED_COLUMNS_TO_KEEP\n",
    "\n",
    "TEST_COLUMNS_TO_KEEP = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"diffuse_rad_1h:J\",\n",
    "    \"is_day:idx\",\n",
    "    \"sun_elevation:d\",\n",
    "    # \"ceiling_height_agl:m\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "    \"air_density_2m:kgm3\",\n",
    "    \"wind_speed_v_10m:ms\",\n",
    "    \"dew_point_2m:K\",\n",
    "    \"wind_speed_u_10m:ms\",\n",
    "    \"t_1000hPa:K\",\n",
    "    \"absolute_humidity_2m:gm3\",\n",
    "    \"snow_water:kgm2\",\n",
    "    \"relative_humidity_1000hPa:p\",\n",
    "    \"fresh_snow_24h:cm\",\n",
    "    \"cloud_base_agl:m\",\n",
    "    \"fresh_snow_12h:cm\",\n",
    "    \"snow_depth:cm\",\n",
    "    \"dew_or_rime:idx\",\n",
    "    \"fresh_snow_6h:cm\",\n",
    "    \"super_cooled_liquid_water:kgm2\",\n",
    "    \"fresh_snow_3h:cm\",\n",
    "    \"rain_water:kgm2\",\n",
    "    \"precip_type_5min:idx\",\n",
    "    \"precip_5min:mm\",\n",
    "    \"fresh_snow_1h:cm\",\n",
    "    \"sun_azimuth:d\",\n",
    "    \"msl_pressure:hPa\",\n",
    "    \"pressure_100m:hPa\",\n",
    "    \"pressure_50m:hPa\",\n",
    "    \"sfc_pressure:hPa\",\n",
    "    \"prob_rime:p\",\n",
    "    \"wind_speed_10m:ms\",\n",
    "    \"elevation:m\",\n",
    "    # \"snow_density:kgm3\",\n",
    "    \"snow_drift:idx\",\n",
    "    \"snow_melt_10min:mm\",\n",
    "    \"wind_speed_w_1000hPa:ms\",\n",
    "    # \"date_calc\",\n",
    "    # \"pv_measurement\",\n",
    "] + CUSTOM_COLUMNS_TO_KEEP + LAGGED_COLUMNS_TO_KEEP\n",
    "\n",
    "\n",
    "def create_weather_lagged_features(df, weather_features):\n",
    "    # Choose the weather features for which you want to create lagged versions\n",
    "    for feature in weather_features:\n",
    "        # Assuming hourly data, adjust the lags for your specific dataset\n",
    "        # Creating lagged features for 1 hour, 1 day, and 1 week\n",
    "        df[f'{feature}_lag_1h'] = df[feature].shift(1)\n",
    "        # df[f'{feature}_lag_2h'] = df[feature].shift(2)\n",
    "        # df[f'{feature}_lag_3h'] = df[feature].shift(3)\n",
    "\n",
    "        df[f'{feature}_lag_forward_1h'] = df[feature].shift(-1)\n",
    "        # df[f'{feature}_lag_forward_2h'] = df[feature].shift(-2)\n",
    "        # df[f'{feature}_lag_forward_3h'] = df[feature].shift(-3)\n",
    "        # df[f'{feature}_lag_24h'] = df[feature].shift(24*4)\n",
    "        # df[f'{feature}_lag_168h'] = df[feature].shift(24 * 7 * 4 * 365)\n",
    "        # df[f'{feature}_front_lag_1h'] = df[feature].shift(-4)\n",
    "        # df[f'{feature}_front_lag_24h'] = df[feature].shift(-24*4)\n",
    "\n",
    "\n",
    "    # Handling edges by filling NaNs with appropriate values or dropping them\n",
    "    # You may choose to fill with zeroes or interpolate, based on what makes more sense for your data\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "    df.fillna(method='bfill', inplace=True)  # Backward fill\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_lagged_features(df, column_name='pv_measurement'):\n",
    "    # Assuming 'date_forecast' is the datetime column used for sorting\n",
    "\n",
    "    df[f'{column_name}_prev_month'] = df[column_name].shift(24*7) # previous week\n",
    "\n",
    "    # For yearly lag, you would need to calculate the number of observations per year\n",
    "    # If the data is not consistent (leap years, etc.), you may need a more complex method\n",
    "    # Here's a simple version assuming 365 days a year:\n",
    "    df[f'{column_name}_prev_year'] = df[column_name].shift(24*365) # previous year\n",
    "    df[f'{column_name}_2years_ago'] = df[column_name].shift(24*365*2) # next year\n",
    "\n",
    "    # Handling edges by filling NaNs with appropriate values or dropping them\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "    df.fillna(method='bfill', inplace=True)  # Backward fill\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_custom_fields(df):\n",
    "     df['hour_sin'] = np.sin(2 * np.pi * df['date_forecast'].dt.hour / 24)\n",
    "     df['hour_cos'] = np.cos(2 * np.pi * df['date_forecast'].dt.hour / 24)\n",
    "\n",
    "     df['month_sin'] = np.sin(2 * np.pi * df['date_forecast'].dt.month / 12)\n",
    "     df['month_cos'] = np.cos(2 * np.pi * df['date_forecast'].dt.month / 12)\n",
    "     df['day-of-year'] = df['date_forecast'].dt.dayofyear\n",
    "     return df\n",
    "\n",
    "def remove_outliers(df):\n",
    "    # Use a mask to filter out the rows where rolling std is zero but keep the rows where the value itself is zero\n",
    "    mask = (df['pv_measurement'].rolling(5).std() == 0) & (df['pv_measurement'] != 0)\n",
    "    df = df[~mask]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a dictionary to hold the scalers for each location\n",
    "scalers = {}\n",
    "\n",
    "def prepare_data(location):\n",
    "    # Load data\n",
    "    scaling = True  # Set scaling to True to enable individual scaling for each location\n",
    "    global features_order\n",
    "\n",
    "    df_observed = pd.read_parquet(f\"data/{location}/X_train_observed.parquet\")\n",
    "    df_estimated = pd.read_parquet(f\"data/{location}/X_train_estimated.parquet\")\n",
    "    df_target = pd.read_parquet(f\"data/{location}/train_targets.parquet\")\n",
    "\n",
    "    # Combine observed and estimated datasets\n",
    "    df_combined = pd.concat([df_observed, df_estimated], axis=0).sort_values(by=\"date_forecast\")\n",
    "\n",
    "    df_combined = add_custom_fields(df_combined)\n",
    "    df_combined.set_index('date_forecast', inplace=True)\n",
    "    df_merged = df_combined.resample('1H').mean().interpolate(method=\"linear\")\n",
    "\n",
    "    # Merge with target data\n",
    "    df_merged = pd.merge(df_merged, df_target, left_on=\"date_forecast\", right_on=\"time\", how=\"inner\")\n",
    "    \n",
    "    # One-hot encoding for location\n",
    "    df_merged = create_weather_lagged_features(df_merged, WEATHER_FEATURES)\n",
    "    df_merged = df_merged[COLUMNS_TO_KEEP]\n",
    "    df_merged = remove_outliers(df_merged)\n",
    "    \n",
    "    y = df_merged[\"pv_measurement\"]\n",
    "    X = df_merged.drop(\"pv_measurement\", axis=1)\n",
    "    features_order = list(X.columns)\n",
    "    \n",
    "    # Treat location as a categorical feature by converting it to a category type\n",
    "    X['location'] = location\n",
    "    X['location'] = X['location'].astype(str)  # Convert to string if 'location' is not an int\n",
    "    \n",
    "\n",
    "    if scaling:\n",
    "        continuous_columns = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "        scalers[location] = MinMaxScaler()\n",
    "        X[continuous_columns] = scalers[location].fit_transform(X[continuous_columns])\n",
    "        \n",
    "\n",
    "    y = np.log1p(y)  # Log transformation\n",
    "    X = one_hot_encode_location(X)\n",
    "    return X, y\n",
    "    \n",
    "def one_hot_encode_location(X):\n",
    "    X[\"location_A\"] = (X[\"location\"]== \"A\").astype(int)\n",
    "    X[\"location_B\"] = (X[\"location\"]== \"B\").astype(int)\n",
    "    X[\"location_C\"] = (X[\"location\"]== \"C\").astype(int)\n",
    "    X.drop(columns=\"location\", axis=1, inplace=True)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location A:\n",
      "date_calc                            0\n",
      "date_forecast                        0\n",
      "absolute_humidity_2m:gm3             0\n",
      "air_density_2m:kgm3                  0\n",
      "ceiling_height_agl:m                 0\n",
      "clear_sky_energy_1h:J              474\n",
      "clear_sky_rad:W                    595\n",
      "cloud_base_agl:m                     0\n",
      "dew_or_rime:idx                   2780\n",
      "dew_point_2m:K                       0\n",
      "diffuse_rad:W                      596\n",
      "diffuse_rad_1h:J                   474\n",
      "direct_rad:W                       845\n",
      "direct_rad_1h:J                    650\n",
      "effective_cloud_cover:p            137\n",
      "elevation:m                          0\n",
      "fresh_snow_12h:cm                 2878\n",
      "fresh_snow_1h:cm                  2879\n",
      "fresh_snow_24h:cm                 2878\n",
      "fresh_snow_3h:cm                  2878\n",
      "fresh_snow_6h:cm                  2878\n",
      "is_day:idx                         594\n",
      "is_in_shadow:idx                  2231\n",
      "msl_pressure:hPa                     0\n",
      "precip_5min:mm                    2696\n",
      "precip_type_5min:idx              2696\n",
      "pressure_100m:hPa                    0\n",
      "pressure_50m:hPa                     0\n",
      "prob_rime:p                       2880\n",
      "rain_water:kgm2                   2636\n",
      "relative_humidity_1000hPa:p          0\n",
      "sfc_pressure:hPa                     0\n",
      "snow_density:kgm3                    0\n",
      "snow_depth:cm                     2880\n",
      "snow_drift:idx                    2880\n",
      "snow_melt_10min:mm                2880\n",
      "snow_water:kgm2                   2271\n",
      "sun_azimuth:d                        0\n",
      "sun_elevation:d                      0\n",
      "super_cooled_liquid_water:kgm2    1915\n",
      "t_1000hPa:K                          0\n",
      "total_cloud_cover:p                137\n",
      "visibility:m                         0\n",
      "wind_speed_10m:ms                    2\n",
      "wind_speed_u_10m:ms                 46\n",
      "wind_speed_v_10m:ms                 69\n",
      "wind_speed_w_1000hPa:ms           2880\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Location B:\n",
      "date_calc                            0\n",
      "date_forecast                        0\n",
      "absolute_humidity_2m:gm3             0\n",
      "air_density_2m:kgm3                  0\n",
      "ceiling_height_agl:m                 0\n",
      "clear_sky_energy_1h:J              474\n",
      "clear_sky_rad:W                    595\n",
      "cloud_base_agl:m                     0\n",
      "dew_or_rime:idx                   2800\n",
      "dew_point_2m:K                       0\n",
      "diffuse_rad:W                      596\n",
      "diffuse_rad_1h:J                   474\n",
      "direct_rad:W                       848\n",
      "direct_rad_1h:J                    661\n",
      "effective_cloud_cover:p            137\n",
      "elevation:m                          0\n",
      "fresh_snow_12h:cm                 2880\n",
      "fresh_snow_1h:cm                  2880\n",
      "fresh_snow_24h:cm                 2880\n",
      "fresh_snow_3h:cm                  2880\n",
      "fresh_snow_6h:cm                  2880\n",
      "is_day:idx                         594\n",
      "is_in_shadow:idx                  2230\n",
      "msl_pressure:hPa                     0\n",
      "precip_5min:mm                    2696\n",
      "precip_type_5min:idx              2696\n",
      "pressure_100m:hPa                    0\n",
      "pressure_50m:hPa                     0\n",
      "prob_rime:p                       2880\n",
      "rain_water:kgm2                   2636\n",
      "relative_humidity_1000hPa:p          0\n",
      "sfc_pressure:hPa                     0\n",
      "snow_density:kgm3                    0\n",
      "snow_depth:cm                     2880\n",
      "snow_drift:idx                    2880\n",
      "snow_melt_10min:mm                2880\n",
      "snow_water:kgm2                   2271\n",
      "sun_azimuth:d                        0\n",
      "sun_elevation:d                      0\n",
      "super_cooled_liquid_water:kgm2    1915\n",
      "t_1000hPa:K                          0\n",
      "total_cloud_cover:p                137\n",
      "visibility:m                         0\n",
      "wind_speed_10m:ms                    2\n",
      "wind_speed_u_10m:ms                 44\n",
      "wind_speed_v_10m:ms                 68\n",
      "wind_speed_w_1000hPa:ms           2880\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Location C:\n",
      "date_calc                            0\n",
      "date_forecast                        0\n",
      "absolute_humidity_2m:gm3             0\n",
      "air_density_2m:kgm3                  0\n",
      "ceiling_height_agl:m                 0\n",
      "clear_sky_energy_1h:J              476\n",
      "clear_sky_rad:W                    596\n",
      "cloud_base_agl:m                     0\n",
      "dew_or_rime:idx                   2728\n",
      "dew_point_2m:K                       0\n",
      "diffuse_rad:W                      599\n",
      "diffuse_rad_1h:J                   478\n",
      "direct_rad:W                       963\n",
      "direct_rad_1h:J                    777\n",
      "effective_cloud_cover:p            170\n",
      "elevation:m                          0\n",
      "fresh_snow_12h:cm                 2873\n",
      "fresh_snow_1h:cm                  2873\n",
      "fresh_snow_24h:cm                 2873\n",
      "fresh_snow_3h:cm                  2873\n",
      "fresh_snow_6h:cm                  2873\n",
      "is_day:idx                         596\n",
      "is_in_shadow:idx                  2095\n",
      "msl_pressure:hPa                     0\n",
      "precip_5min:mm                    2681\n",
      "precip_type_5min:idx              2681\n",
      "pressure_100m:hPa                    0\n",
      "pressure_50m:hPa                     0\n",
      "prob_rime:p                       2870\n",
      "rain_water:kgm2                   2650\n",
      "relative_humidity_1000hPa:p          0\n",
      "sfc_pressure:hPa                     0\n",
      "snow_density:kgm3                    0\n",
      "snow_depth:cm                     2880\n",
      "snow_drift:idx                    2880\n",
      "snow_melt_10min:mm                2880\n",
      "snow_water:kgm2                   2279\n",
      "sun_azimuth:d                        0\n",
      "sun_elevation:d                      0\n",
      "super_cooled_liquid_water:kgm2    1898\n",
      "t_1000hPa:K                          0\n",
      "total_cloud_cover:p                170\n",
      "visibility:m                         0\n",
      "wind_speed_10m:ms                    0\n",
      "wind_speed_u_10m:ms                 60\n",
      "wind_speed_v_10m:ms                 51\n",
      "wind_speed_w_1000hPa:ms           2849\n",
      "dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_zeros_in_test_set(locations, data_folder=\"data\"):\n",
    "    # Dictionary to hold the count of zeros for each location\n",
    "    zeros_count = {}\n",
    "\n",
    "    # Iterate through each location\n",
    "    for location in locations:\n",
    "        # Load the test set data\n",
    "        df_test = pd.read_parquet(f\"{data_folder}/{location}/X_test_estimated.parquet\")\n",
    "\n",
    "        # Check for zeros in each column\n",
    "        zeros_in_columns = (df_test == 0).sum()\n",
    "\n",
    "        # Store the result in the dictionary\n",
    "        zeros_count[location] = zeros_in_columns\n",
    "\n",
    "    return zeros_count\n",
    "\n",
    "# Assuming 'locations' is a list of location identifiers\n",
    "locations = [\"A\", \"B\", \"C\"]\n",
    "zero_values_summary = check_zeros_in_test_set(locations)\n",
    "\n",
    "# Now, let's print the summary for each location\n",
    "for location, zeros in zero_values_summary.items():\n",
    "    print(f\"Location {location}:\")\n",
    "    print(zeros)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10344\\3251292879.py:209: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10344\\3251292879.py:210: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10344\\3251292879.py:209: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10344\\3251292879.py:210: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10344\\3251292879.py:209: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10344\\3251292879.py:210: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                              \n",
      "Generation 1 - Current best internal CV score: -0.511333811478393\n",
      "                                                                            \n",
      "Generation 2 - Current best internal CV score: -0.4919317434306934\n",
      "                                                          \n",
      "Best pipeline: RandomForestRegressor(input_matrix, bootstrap=False, max_features=0.05, min_samples_leaf=9, min_samples_split=13, n_estimators=100)\n",
      "Mean Absolute Error on Test Data: 0.3372247381355866\n",
      "Location C, Mean Absolute Error: 106.75371912828125\n"
     ]
    }
   ],
   "source": [
    "def train_model(X_train, y_train, X_val, y_val, location):\n",
    "    model = TPOTRegressor(generations=2, population_size=5, verbosity=2, random_state=42)  # This setting is just for debug. Population 50, generations 5 was base setting.\n",
    "\n",
    "    model.fit(X_train, y_train.to_numpy().squeeze())\n",
    "    model.export('tpot_pipeline.py')  # Save the best model\n",
    "    print(f\"Mean Absolute Error on Test Data: {mean_absolute_error(y_val, model.predict(X_val))}\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(X_val, y_val, location, model = None):\n",
    "    if model is None:\n",
    "        model = TPOTRegressor()\n",
    "        \n",
    "        model.load_model(f\"catboost_model_merged.cbm\")\n",
    "    \n",
    "    y_pred = model.predict(X_val)\n",
    "    y_val = np.expm1(y_val)\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    print(f'Location {location}, Mean Absolute Error: {mae}')\n",
    "\n",
    "combined_X_train = pd.DataFrame()\n",
    "combined_X_val = pd.DataFrame()\n",
    "combined_Y_train = pd.DataFrame()\n",
    "combined_Y_val = pd.DataFrame()\n",
    "\n",
    "for location in locations:\n",
    "    # Prepare the training data\n",
    "    X, y = prepare_data(location)\n",
    "    \n",
    "    # Ensure consistent feature ordering\n",
    "    features_order = list(X.columns)  # Save the feature order after preparation\n",
    "    # print column with name \"location_A\"\n",
    "    \n",
    "    # Split the data once\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    combined_X_train = pd.concat([combined_X_train, X_train])\n",
    "    combined_X_val = pd.concat([combined_X_val, X_val])\n",
    "    combined_Y_train = pd.concat([combined_Y_train, y_train])\n",
    "    combined_Y_val = pd.concat([combined_Y_val, y_val])\n",
    "\n",
    "\n",
    "combined_X_train, combined_Y_train = shuffle(combined_X_train, combined_Y_train, random_state=42)\n",
    "combined_X_val, combined_Y_val = shuffle(combined_X_val, combined_Y_val, random_state=42)\n",
    "\n",
    "# Train the model using all available training data and the initial validation set for early stopping\n",
    "model = train_model(combined_X_train, combined_Y_train, combined_X_val, combined_Y_val, location)\n",
    "# Evaluate the model using the same validation set\n",
    "evaluate_model(combined_X_val, combined_Y_val, location, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming you have defined WEATHER_FEATURES, TEST_COLUMNS_TO_KEEP, and other functions previously\n",
    "\n",
    "def make_predictions(df_test, location, target, model = None):\n",
    "    global scalers\n",
    "    scaling = True\n",
    "    if model is None: \n",
    "        model = CatBoostRegressor()\n",
    "        model.load_model(f\"catboost_model_merged.cbm\")  # Load the model specific to the location\n",
    "        \n",
    "    df_test = add_custom_fields(df_test)\n",
    "    df_test.set_index('date_forecast', inplace=True)\n",
    "    df_test = df_test.resample(rule=\"1H\").mean().interpolate(method=\"linear\")\n",
    "    \n",
    "    # One-hot encode the location\n",
    "    df_test = create_weather_lagged_features(df_test, WEATHER_FEATURES)\n",
    "    df_test = df_test[TEST_COLUMNS_TO_KEEP]\n",
    "    \n",
    "    df_test['location'] = location\n",
    "    df_test['location'] = df_test['location'].astype(str)\n",
    "    df_test['dew_or_rime:idx'] = df_test['dew_or_rime:idx'].astype(str)\n",
    "    df_test['is_day:idx'] = df_test['is_day:idx'].astype(str)\n",
    "    df_test['is_in_shadow:idx'] = df_test['is_in_shadow:idx'].astype(str)\n",
    "\n",
    "    # Apply the same Min-Max normalization to the test data\n",
    "    if scaling:\n",
    "        scaler = scalers[location]\n",
    "        continuous_columns = df_test.select_dtypes(include=['float64', 'int64']).columns\n",
    "        df_test[continuous_columns] = scaler.transform(df_test[continuous_columns])\n",
    "\n",
    "    preds = model.predict(df_test)\n",
    "    preds = np.expm1(preds)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   direct_rad:W  clear_sky_rad:W  diffuse_rad:W  direct_rad_1h:J  \\\n",
      "0           0.0              0.0            0.0              0.0   \n",
      "1           0.0              0.0            0.0              0.0   \n",
      "2           0.0              0.0            0.0              0.0   \n",
      "3           0.0              0.0            0.0              0.0   \n",
      "4           0.0              0.0            0.0              0.0   \n",
      "\n",
      "  is_in_shadow:idx  clear_sky_energy_1h:J  diffuse_rad_1h:J is_day:idx  \\\n",
      "0              1.0                    0.0               0.0        0.0   \n",
      "1              1.0                    0.0               0.0        0.0   \n",
      "2              1.0                    0.0               0.0        0.0   \n",
      "3              1.0                    0.0               0.0        0.0   \n",
      "4              1.0                    0.0               0.0        0.0   \n",
      "\n",
      "   sun_elevation:d  effective_cloud_cover:p  ...  \\\n",
      "0       -39.065250                    100.0  ...   \n",
      "1       -39.382252                    100.0  ...   \n",
      "2       -38.040501                    100.0  ...   \n",
      "3       -34.390499                    100.0  ...   \n",
      "4       -29.268749                    100.0  ...   \n",
      "\n",
      "   is_in_shadow:idx_lag_forward_1h  clear_sky_energy_1h:J_lag_1h  \\\n",
      "0                              1.0                           0.0   \n",
      "1                              1.0                           0.0   \n",
      "2                              1.0                           0.0   \n",
      "3                              1.0                           0.0   \n",
      "4                              1.0                           0.0   \n",
      "\n",
      "   clear_sky_energy_1h:J_lag_forward_1h  effective_cloud_cover:p_lag_1h  \\\n",
      "0                                   0.0                           100.0   \n",
      "1                                   0.0                           100.0   \n",
      "2                                   0.0                           100.0   \n",
      "3                                   0.0                           100.0   \n",
      "4                                   0.0                           100.0   \n",
      "\n",
      "   effective_cloud_cover:p_lag_forward_1h  visibility:m_lag_1h  \\\n",
      "0                                   100.0         20712.525391   \n",
      "1                                   100.0         20712.525391   \n",
      "2                                   100.0          5624.174805   \n",
      "3                                   100.0          3240.425049   \n",
      "4                                   100.0          3243.500000   \n",
      "\n",
      "   visibility:m_lag_forward_1h  total_cloud_cover:p_lag_1h  \\\n",
      "0                  5624.174805                       100.0   \n",
      "1                  3240.425049                       100.0   \n",
      "2                  3243.500000                       100.0   \n",
      "3                  2528.449951                       100.0   \n",
      "4                  2222.024902                       100.0   \n",
      "\n",
      "   total_cloud_cover:p_lag_forward_1h  location  \n",
      "0                               100.0         A  \n",
      "1                               100.0         A  \n",
      "2                               100.0         A  \n",
      "3                               100.0         A  \n",
      "4                               100.0         A  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Invalid type for cat_feature category for [feature_idx=4]=0.0 : cat_features must be integer or string, real number values and NaN values should be converted to string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m_catboost.pyx:2684\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame_categorical_column\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:1892\u001b[0m, in \u001b[0;36m_catboost.get_id_object_bytes_string_representation\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: bad object for id: 0.0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb Cell 16\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mfor\u001b[39;00m loc \u001b[39min\u001b[39;00m locations:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     evaluate_model_locally(loc, scalers)\n",
      "\u001b[1;32m/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m resampled_dates \u001b[39m=\u001b[39m dates_df\u001b[39m.\u001b[39mresample(\u001b[39m'\u001b[39m\u001b[39m1H\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39masfreq()\u001b[39m.\u001b[39mindex\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m preds \u001b[39m=\u001b[39m make_predictions(data, location, target)[\u001b[39m-\u001b[39m\u001b[39m720\u001b[39m:]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# if location in scalers:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m#     # You need to reshape preds because inverse_transform expects a 2D array\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39m#     preds = preds.reshape(-1, 1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39m# mae = mean_absolute_error(target, preds)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# print(f\"Mean average Error: {mae}\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mtail(\u001b[39m720\u001b[39m)[\u001b[39m\"\u001b[39m\u001b[39mpv_measurement\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto_numpy()\n",
      "\u001b[1;32m/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     df_test[continuous_columns] \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(df_test[continuous_columns])  \u001b[39m# Use transform, not fit_transform\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mprint\u001b[39m(df_test\u001b[39m.\u001b[39mhead())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(df_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m# preds = np.expm1(preds)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/project/TDT4173-project/catboost_model_merged_vol3.ipynb#X21sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(df_test)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/catboost/core.py:5748\u001b[0m, in \u001b[0;36mCatBoostRegressor.predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5746\u001b[0m \u001b[39mif\u001b[39;00m prediction_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5747\u001b[0m     prediction_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_default_prediction_type()\n\u001b[0;32m-> 5748\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, \u001b[39m'\u001b[39;49m\u001b[39mpredict\u001b[39;49m\u001b[39m'\u001b[39;49m, task_type)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/catboost/core.py:2505\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2503\u001b[0m \u001b[39mif\u001b[39;00m verbose \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2504\u001b[0m     verbose \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 2505\u001b[0m data, data_is_single_object \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_predict_input_data(data, parent_method_name, thread_count)\n\u001b[1;32m   2506\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m   2508\u001b[0m predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/catboost/core.py:2485\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2483\u001b[0m is_single_object \u001b[39m=\u001b[39m _is_data_single_object(data)\n\u001b[1;32m   2484\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Pool):\n\u001b[0;32m-> 2485\u001b[0m     data \u001b[39m=\u001b[39m Pool(\n\u001b[1;32m   2486\u001b[0m         data\u001b[39m=\u001b[39;49m[data] \u001b[39mif\u001b[39;49;00m is_single_object \u001b[39melse\u001b[39;49;00m data,\n\u001b[1;32m   2487\u001b[0m         label\u001b[39m=\u001b[39;49mlabel,\n\u001b[1;32m   2488\u001b[0m         cat_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_cat_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2489\u001b[0m         text_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_text_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2490\u001b[0m         embedding_features\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_embedding_feature_indices() \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data, FeaturesData) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2491\u001b[0m         thread_count\u001b[39m=\u001b[39;49mthread_count\n\u001b[1;32m   2492\u001b[0m     )\n\u001b[1;32m   2493\u001b[0m \u001b[39mreturn\u001b[39;00m data, is_single_object\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/catboost/core.py:793\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    787\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[1;32m    788\u001b[0m             \u001b[39mraise\u001b[39;00m CatBoostError(\n\u001b[1;32m    789\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    790\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mpython objects.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m             )\n\u001b[0;32m--> 793\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[1;32m    794\u001b[0m                    group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    795\u001b[0m \u001b[39msuper\u001b[39m(Pool, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/catboost/core.py:1425\u001b[0m, in \u001b[0;36mPool._init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[39mif\u001b[39;00m feature_tags \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1424\u001b[0m     feature_tags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_transform_tags(feature_tags, feature_names)\n\u001b[0;32m-> 1425\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[1;32m   1426\u001b[0m                 group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n",
      "File \u001b[0;32m_catboost.pyx:3976\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4026\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:3842\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2769\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2686\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame_categorical_column\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Invalid type for cat_feature category for [feature_idx=4]=0.0 : cat_features must be integer or string, real number values and NaN values should be converted to string."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def check_zeros_in_test_set(locations, data_folder=\"data\"):\n",
    "    # Dictionary to hold the count of zeros for each location\n",
    "    zeros_count = {}\n",
    "\n",
    "    # Iterate through each location\n",
    "    for location in locations:\n",
    "        # Load the test set data\n",
    "        df_test = pd.read_parquet(f\"{data_folder}/{location}/X_test_estimated.parquet\")\n",
    "\n",
    "        # Check for zeros in each column\n",
    "        zeros_in_columns = (df_test == 0).sum()\n",
    "\n",
    "        # Store the result in the dictionary\n",
    "        zeros_count[location] = zeros_in_columns\n",
    "\n",
    "    return zeros_count\n",
    "\n",
    "# Assuming 'locations' is a list of location identifiers\n",
    "locations = [\"A\", \"B\", \"C\"]\n",
    "zero_values_summary = check_zeros_in_test_set(locations)\n",
    "\n",
    "\n",
    "def evaluate_model_locally(location, scalers):\n",
    "    # Load the test data\n",
    "    target = pd.read_parquet(f\"data/{location}/train_targets.parquet\")\n",
    "    data = pd.read_parquet(f\"data/{location}/X_train_estimated.parquet\")\n",
    "\n",
    "    # Scale the data using the scaler for the current location\n",
    "    \n",
    "    # Make a copy of the date_forecast column\n",
    "    dates = data[\"date_forecast\"].copy()\n",
    "    # Create a new DataFrame with dates as the index\n",
    "    dates_df = pd.DataFrame(index=dates).tail(720*4)\n",
    "\n",
    "    # Resample to 1-hour intervals\n",
    "    resampled_dates = dates_df.resample('1H').asfreq().index\n",
    "\n",
    "    # Make predictions\n",
    "    preds = make_predictions(data, location, target, model = model)[-720:]\n",
    "    # if location in scalers:\n",
    "    #     # You need to reshape preds because inverse_transform expects a 2D array\n",
    "    #     preds = preds.reshape(-1, 1)\n",
    "    #     preds_original_scale = scalers[location].inverse_transform(preds)\n",
    "\n",
    "    #     # Reshape preds back to its original shape if necessary\n",
    "    #     preds_original_scale = preds_original_scale.flatten()\n",
    "    # mae = mean_absolute_error(target, preds)\n",
    "    # print(f\"Mean average Error: {mae}\")\n",
    "    target = target.tail(720)[\"pv_measurement\"].to_numpy()\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(60,6))\n",
    "    plt.plot(resampled_dates, target, label=\"Target\")\n",
    "    plt.plot(resampled_dates, preds, label=\"Predictions\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Target vs Predictions')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "    plt.show()\n",
    "\n",
    "for loc in locations:\n",
    "    evaluate_model_locally(loc, scalers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to csv 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2880\n",
      "2160\n",
      "2880\n",
      "2160\n",
      "2880\n",
      "2160\n"
     ]
    }
   ],
   "source": [
    "df_submission = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "for location in locations: \n",
    "    df_test= pd.read_parquet(f\"data/{location}/X_test_estimated.parquet\")\n",
    "    df_target = pd.read_parquet(f\"data/{location}/train_targets.parquet\")\n",
    "    print(len(df_test))\n",
    "    \n",
    "    preds = make_predictions(df_test, location, df_target, model = model)\n",
    "    \n",
    "    # Assign the predictions to df_submission for the current location\n",
    "    mask = df_submission[\"location\"] == location\n",
    "    print(len(mask))\n",
    "    # Before this line in your main function\n",
    "\n",
    "    # Add a check to make sure the lengths match\n",
    "    if len(preds) != mask.sum():\n",
    "        print(f\"Length of predictions: {len(preds)}\")\n",
    "        print(f\"Length of submission entries: {mask.sum()}\")\n",
    "        raise ValueError(f\"Mismatch in length of predictions and submission entries for location {location}.\")\n",
    "\n",
    "    df_submission.loc[mask, \"prediction\"] = preds\n",
    "    \n",
    "\n",
    "# Save the results to a new submission file\n",
    "df_submission[[\"id\", \"prediction\"]].to_csv(\"kaggle_submission_catboost_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date_calc       date_forecast  absolute_humidity_2m:gm3  \\\n",
      "0 2023-04-30 07:00:04 2023-05-01 00:00:00                       4.4   \n",
      "1 2023-04-30 07:00:04 2023-05-01 00:15:00                       4.3   \n",
      "2 2023-04-30 07:00:04 2023-05-01 00:30:00                       4.3   \n",
      "3 2023-04-30 07:00:04 2023-05-01 00:45:00                       4.3   \n",
      "4 2023-04-30 07:00:04 2023-05-01 01:00:00                       4.3   \n",
      "\n",
      "   air_density_2m:kgm3  ceiling_height_agl:m  clear_sky_energy_1h:J  \\\n",
      "0                1.286            912.700012                    0.0   \n",
      "1                1.287            912.700012                    0.0   \n",
      "2                1.287            912.700012                    0.0   \n",
      "3                1.287            912.700012                    0.0   \n",
      "4                1.287                   NaN                    0.0   \n",
      "\n",
      "   clear_sky_rad:W  cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  \\\n",
      "0              0.0       1041.199951              0.0      271.700012   \n",
      "1              0.0       1054.800049              0.0      271.700012   \n",
      "2              0.0       1068.300049              0.0      271.600006   \n",
      "3              0.0       1081.900024              0.0      271.600006   \n",
      "4              0.0       1095.400024              0.0      271.600006   \n",
      "\n",
      "   diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  \\\n",
      "0            0.0               0.0           0.0              0.0   \n",
      "1            0.0               0.0           0.0              0.0   \n",
      "2            0.0               0.0           0.0              0.0   \n",
      "3            0.0               0.0           0.0              0.0   \n",
      "4            0.0               0.0           0.0              0.0   \n",
      "\n",
      "   effective_cloud_cover:p  elevation:m  fresh_snow_12h:cm  fresh_snow_1h:cm  \\\n",
      "0                80.699997          6.0                0.0               0.0   \n",
      "1                77.000000          6.0                0.0               0.0   \n",
      "2                73.099998          6.0                0.0               0.0   \n",
      "3                69.000000          6.0                0.0               0.0   \n",
      "4                64.500000          6.0                0.0               0.0   \n",
      "\n",
      "   fresh_snow_24h:cm  fresh_snow_3h:cm  fresh_snow_6h:cm  is_day:idx  \\\n",
      "0                0.0               0.0               0.0         0.0   \n",
      "1                0.0               0.0               0.0         0.0   \n",
      "2                0.0               0.0               0.0         0.0   \n",
      "3                0.0               0.0               0.0         0.0   \n",
      "4                0.0               0.0               0.0         0.0   \n",
      "\n",
      "   is_in_shadow:idx  msl_pressure:hPa  precip_5min:mm  precip_type_5min:idx  \\\n",
      "0               1.0       1013.900024             0.0                   0.0   \n",
      "1               1.0       1013.700012             0.0                   0.0   \n",
      "2               1.0       1013.599976             0.0                   0.0   \n",
      "3               1.0       1013.500000             0.0                   0.0   \n",
      "4               1.0       1013.299988             0.0                   0.0   \n",
      "\n",
      "   pressure_100m:hPa  pressure_50m:hPa  prob_rime:p  rain_water:kgm2  \\\n",
      "0        1000.700012       1007.000000          0.0              0.0   \n",
      "1        1000.599976       1006.900024          0.0              0.0   \n",
      "2        1000.500000       1006.700012          0.0              0.0   \n",
      "3        1000.400024       1006.599976          0.0              0.0   \n",
      "4        1000.200012       1006.500000          0.0              0.0   \n",
      "\n",
      "   relative_humidity_1000hPa:p  sfc_pressure:hPa  snow_density:kgm3  \\\n",
      "0                    80.300003       1013.299988                NaN   \n",
      "1                    80.300003       1013.200012                NaN   \n",
      "2                    80.300003       1013.000000                NaN   \n",
      "3                    80.199997       1012.900024                NaN   \n",
      "4                    80.199997       1012.799988                NaN   \n",
      "\n",
      "   snow_depth:cm  snow_drift:idx  snow_melt_10min:mm  snow_water:kgm2  \\\n",
      "0            0.0             0.0                 0.0              0.0   \n",
      "1            0.0             0.0                 0.0              0.0   \n",
      "2            0.0             0.0                 0.0              0.0   \n",
      "3            0.0             0.0                 0.0              0.0   \n",
      "4            0.0             0.0                 0.0              0.0   \n",
      "\n",
      "   sun_azimuth:d  sun_elevation:d  super_cooled_liquid_water:kgm2  \\\n",
      "0      10.520000          -11.185                             0.0   \n",
      "1      14.203000          -10.825                             0.0   \n",
      "2      17.868999          -10.360                             0.0   \n",
      "3      21.514000           -9.794                             0.0   \n",
      "4      25.135000           -9.128                             0.0   \n",
      "\n",
      "   t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
      "0   273.799988            80.699997  30210.699219                4.0   \n",
      "1   273.799988            77.000000  30003.599609                4.0   \n",
      "2   273.799988            73.099998  29797.099609                3.9   \n",
      "3   273.799988            69.000000  29618.599609                3.9   \n",
      "4   273.799988            64.500000  29507.500000                3.9   \n",
      "\n",
      "   wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \\\n",
      "0                  2.2                  3.4                     -0.0   \n",
      "1                  2.1                  3.4                     -0.0   \n",
      "2                  2.1                  3.3                     -0.0   \n",
      "3                  2.0                  3.3                     -0.0   \n",
      "4                  2.0                  3.3                     -0.0   \n",
      "\n",
      "   hour_sin  hour_cos  month_sin  month_cos  day-of-year  \n",
      "0  0.000000  1.000000        0.5  -0.866025          121  \n",
      "1  0.000000  1.000000        0.5  -0.866025          121  \n",
      "2  0.000000  1.000000        0.5  -0.866025          121  \n",
      "3  0.000000  1.000000        0.5  -0.866025          121  \n",
      "4  0.258819  0.965926        0.5  -0.866025          121  \n",
      "                              date_calc  absolute_humidity_2m:gm3  \\\n",
      "date_forecast                                                       \n",
      "2023-05-01 00:00:00 2023-04-30 07:00:04                       4.4   \n",
      "2023-05-01 00:15:00 2023-04-30 07:00:04                       4.3   \n",
      "2023-05-01 00:30:00 2023-04-30 07:00:04                       4.3   \n",
      "2023-05-01 00:45:00 2023-04-30 07:00:04                       4.3   \n",
      "2023-05-01 01:00:00 2023-04-30 07:00:04                       4.3   \n",
      "\n",
      "                     air_density_2m:kgm3  ceiling_height_agl:m  \\\n",
      "date_forecast                                                    \n",
      "2023-05-01 00:00:00                1.286            912.700012   \n",
      "2023-05-01 00:15:00                1.287            912.700012   \n",
      "2023-05-01 00:30:00                1.287            912.700012   \n",
      "2023-05-01 00:45:00                1.287            912.700012   \n",
      "2023-05-01 01:00:00                1.287                   NaN   \n",
      "\n",
      "                     clear_sky_energy_1h:J  clear_sky_rad:W  cloud_base_agl:m  \\\n",
      "date_forecast                                                                   \n",
      "2023-05-01 00:00:00                    0.0              0.0       1041.199951   \n",
      "2023-05-01 00:15:00                    0.0              0.0       1054.800049   \n",
      "2023-05-01 00:30:00                    0.0              0.0       1068.300049   \n",
      "2023-05-01 00:45:00                    0.0              0.0       1081.900024   \n",
      "2023-05-01 01:00:00                    0.0              0.0       1095.400024   \n",
      "\n",
      "                     dew_or_rime:idx  dew_point_2m:K  diffuse_rad:W  \\\n",
      "date_forecast                                                         \n",
      "2023-05-01 00:00:00              0.0      271.700012            0.0   \n",
      "2023-05-01 00:15:00              0.0      271.700012            0.0   \n",
      "2023-05-01 00:30:00              0.0      271.600006            0.0   \n",
      "2023-05-01 00:45:00              0.0      271.600006            0.0   \n",
      "2023-05-01 01:00:00              0.0      271.600006            0.0   \n",
      "\n",
      "                     diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  \\\n",
      "date_forecast                                                          \n",
      "2023-05-01 00:00:00               0.0           0.0              0.0   \n",
      "2023-05-01 00:15:00               0.0           0.0              0.0   \n",
      "2023-05-01 00:30:00               0.0           0.0              0.0   \n",
      "2023-05-01 00:45:00               0.0           0.0              0.0   \n",
      "2023-05-01 01:00:00               0.0           0.0              0.0   \n",
      "\n",
      "                     effective_cloud_cover:p  elevation:m  fresh_snow_12h:cm  \\\n",
      "date_forecast                                                                  \n",
      "2023-05-01 00:00:00                80.699997          6.0                0.0   \n",
      "2023-05-01 00:15:00                77.000000          6.0                0.0   \n",
      "2023-05-01 00:30:00                73.099998          6.0                0.0   \n",
      "2023-05-01 00:45:00                69.000000          6.0                0.0   \n",
      "2023-05-01 01:00:00                64.500000          6.0                0.0   \n",
      "\n",
      "                     fresh_snow_1h:cm  fresh_snow_24h:cm  fresh_snow_3h:cm  \\\n",
      "date_forecast                                                                \n",
      "2023-05-01 00:00:00               0.0                0.0               0.0   \n",
      "2023-05-01 00:15:00               0.0                0.0               0.0   \n",
      "2023-05-01 00:30:00               0.0                0.0               0.0   \n",
      "2023-05-01 00:45:00               0.0                0.0               0.0   \n",
      "2023-05-01 01:00:00               0.0                0.0               0.0   \n",
      "\n",
      "                     fresh_snow_6h:cm  is_day:idx  is_in_shadow:idx  \\\n",
      "date_forecast                                                         \n",
      "2023-05-01 00:00:00               0.0         0.0               1.0   \n",
      "2023-05-01 00:15:00               0.0         0.0               1.0   \n",
      "2023-05-01 00:30:00               0.0         0.0               1.0   \n",
      "2023-05-01 00:45:00               0.0         0.0               1.0   \n",
      "2023-05-01 01:00:00               0.0         0.0               1.0   \n",
      "\n",
      "                     msl_pressure:hPa  precip_5min:mm  precip_type_5min:idx  \\\n",
      "date_forecast                                                                 \n",
      "2023-05-01 00:00:00       1013.900024             0.0                   0.0   \n",
      "2023-05-01 00:15:00       1013.700012             0.0                   0.0   \n",
      "2023-05-01 00:30:00       1013.599976             0.0                   0.0   \n",
      "2023-05-01 00:45:00       1013.500000             0.0                   0.0   \n",
      "2023-05-01 01:00:00       1013.299988             0.0                   0.0   \n",
      "\n",
      "                     pressure_100m:hPa  pressure_50m:hPa  prob_rime:p  \\\n",
      "date_forecast                                                           \n",
      "2023-05-01 00:00:00        1000.700012       1007.000000          0.0   \n",
      "2023-05-01 00:15:00        1000.599976       1006.900024          0.0   \n",
      "2023-05-01 00:30:00        1000.500000       1006.700012          0.0   \n",
      "2023-05-01 00:45:00        1000.400024       1006.599976          0.0   \n",
      "2023-05-01 01:00:00        1000.200012       1006.500000          0.0   \n",
      "\n",
      "                     rain_water:kgm2  relative_humidity_1000hPa:p  \\\n",
      "date_forecast                                                       \n",
      "2023-05-01 00:00:00              0.0                    80.300003   \n",
      "2023-05-01 00:15:00              0.0                    80.300003   \n",
      "2023-05-01 00:30:00              0.0                    80.300003   \n",
      "2023-05-01 00:45:00              0.0                    80.199997   \n",
      "2023-05-01 01:00:00              0.0                    80.199997   \n",
      "\n",
      "                     sfc_pressure:hPa  snow_density:kgm3  snow_depth:cm  \\\n",
      "date_forecast                                                             \n",
      "2023-05-01 00:00:00       1013.299988                NaN            0.0   \n",
      "2023-05-01 00:15:00       1013.200012                NaN            0.0   \n",
      "2023-05-01 00:30:00       1013.000000                NaN            0.0   \n",
      "2023-05-01 00:45:00       1012.900024                NaN            0.0   \n",
      "2023-05-01 01:00:00       1012.799988                NaN            0.0   \n",
      "\n",
      "                     snow_drift:idx  snow_melt_10min:mm  snow_water:kgm2  \\\n",
      "date_forecast                                                              \n",
      "2023-05-01 00:00:00             0.0                 0.0              0.0   \n",
      "2023-05-01 00:15:00             0.0                 0.0              0.0   \n",
      "2023-05-01 00:30:00             0.0                 0.0              0.0   \n",
      "2023-05-01 00:45:00             0.0                 0.0              0.0   \n",
      "2023-05-01 01:00:00             0.0                 0.0              0.0   \n",
      "\n",
      "                     sun_azimuth:d  sun_elevation:d  \\\n",
      "date_forecast                                         \n",
      "2023-05-01 00:00:00      10.520000          -11.185   \n",
      "2023-05-01 00:15:00      14.203000          -10.825   \n",
      "2023-05-01 00:30:00      17.868999          -10.360   \n",
      "2023-05-01 00:45:00      21.514000           -9.794   \n",
      "2023-05-01 01:00:00      25.135000           -9.128   \n",
      "\n",
      "                     super_cooled_liquid_water:kgm2  t_1000hPa:K  \\\n",
      "date_forecast                                                      \n",
      "2023-05-01 00:00:00                             0.0   273.799988   \n",
      "2023-05-01 00:15:00                             0.0   273.799988   \n",
      "2023-05-01 00:30:00                             0.0   273.799988   \n",
      "2023-05-01 00:45:00                             0.0   273.799988   \n",
      "2023-05-01 01:00:00                             0.0   273.799988   \n",
      "\n",
      "                     total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
      "date_forecast                                                               \n",
      "2023-05-01 00:00:00            80.699997  30210.699219                4.0   \n",
      "2023-05-01 00:15:00            77.000000  30003.599609                4.0   \n",
      "2023-05-01 00:30:00            73.099998  29797.099609                3.9   \n",
      "2023-05-01 00:45:00            69.000000  29618.599609                3.9   \n",
      "2023-05-01 01:00:00            64.500000  29507.500000                3.9   \n",
      "\n",
      "                     wind_speed_u_10m:ms  wind_speed_v_10m:ms  \\\n",
      "date_forecast                                                   \n",
      "2023-05-01 00:00:00                  2.2                  3.4   \n",
      "2023-05-01 00:15:00                  2.1                  3.4   \n",
      "2023-05-01 00:30:00                  2.1                  3.3   \n",
      "2023-05-01 00:45:00                  2.0                  3.3   \n",
      "2023-05-01 01:00:00                  2.0                  3.3   \n",
      "\n",
      "                     wind_speed_w_1000hPa:ms  hour_sin  hour_cos  month_sin  \\\n",
      "date_forecast                                                                 \n",
      "2023-05-01 00:00:00                     -0.0  0.000000  1.000000        0.5   \n",
      "2023-05-01 00:15:00                     -0.0  0.000000  1.000000        0.5   \n",
      "2023-05-01 00:30:00                     -0.0  0.000000  1.000000        0.5   \n",
      "2023-05-01 00:45:00                     -0.0  0.000000  1.000000        0.5   \n",
      "2023-05-01 01:00:00                     -0.0  0.258819  0.965926        0.5   \n",
      "\n",
      "                     month_cos  day-of-year  \n",
      "date_forecast                                \n",
      "2023-05-01 00:00:00  -0.866025          121  \n",
      "2023-05-01 00:15:00  -0.866025          121  \n",
      "2023-05-01 00:30:00  -0.866025          121  \n",
      "2023-05-01 00:45:00  -0.866025          121  \n",
      "2023-05-01 01:00:00  -0.866025          121  \n",
      "1536\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (1536) does not match length of index (2160)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/simenseeberg/Documents/ntnu/h23/tdt4173/main_project/TDT4173-project/catboost_model_merged_2.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/main_project/TDT4173-project/catboost_model_merged_2.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# print(df_test_merged.head())\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/main_project/TDT4173-project/catboost_model_merged_2.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m preds \u001b[39m=\u001b[39m make_predictions(df_test_merged, location, df_target)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/main_project/TDT4173-project/catboost_model_merged_2.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m df_submission[\u001b[39m\"\u001b[39;49m\u001b[39mprediction\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m=\u001b[39m preds\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/main_project/TDT4173-project/catboost_model_merged_2.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Save the results to a new submission file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/simenseeberg/Documents/ntnu/h23/tdt4173/main_project/TDT4173-project/catboost_model_merged_2.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m df_submission[[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprediction\u001b[39m\u001b[39m\"\u001b[39m]]\u001b[39m.\u001b[39mto_csv(\u001b[39m\"\u001b[39m\u001b[39mkaggle_submission_catboost_2.csv\u001b[39m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (1536) does not match length of index (2160)"
     ]
    }
   ],
   "source": [
    "df_submission = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "df_test_merged = pd.DataFrame()\n",
    "for location in locations: \n",
    "    df_test= pd.read_parquet(f\"data/{location}/X_test_estimated.parquet\")\n",
    "    # df_estimated = pd.read_parquet(f\"data/{location}/X_train_estimated.parquet\")\n",
    "    # df_observed = pd.read_parquet(f\"data/{location}/X_train_observed.parquet\")\n",
    "    df_target = pd.read_parquet(f\"data/{location}/train_targets.parquet\")\n",
    "    # df_test = pd.concat([df_observed, df_estimated, df_test_estimated], axis=0).sort_values(\n",
    "    #     by=\"date_forecast\"\n",
    "    # )\n",
    "    df_test_merged = pd.concat([df_test_merged, df_test])\n",
    "    \n",
    "\n",
    "# print(df_test_merged.head())\n",
    "preds = make_predictions(df_test_merged, location, df_target, model = model)\n",
    "df_submission[\"prediction\"] = preds\n",
    "# Save the results to a new submission file\n",
    "df_submission[[\"id\", \"prediction\"]].to_csv(\"kaggle_submission_catboost_2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
