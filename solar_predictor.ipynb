{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_KEEP = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"diffuse_rad_1h:J\",\n",
    "    \"is_day:idx\",\n",
    "    \"sun_elevation:d\",\n",
    "    \"ceiling_height_agl:m\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    'total_cloud_cover:p',\n",
    "    'air_density_2m:kgm3',\n",
    "    'wind_speed_v_10m:ms',\n",
    "    'dew_point_2m:K',\n",
    "    'wind_speed_u_10m:ms',\n",
    "    't_1000hPa:K',\n",
    "    'absolute_humidity_2m:gm3',\n",
    "    # 'snow_water:kgm2',\n",
    "    # 'relative_humidity_1000hPa:p',\n",
    "    # 'fresh_snow_24h:cm',\n",
    "    # 'cloud_base_agl:m',\n",
    "    # 'fresh_snow_12h:cm',\n",
    "    # 'snow_depth:cm',\n",
    "    # 'dew_or_rime:idx',\n",
    "    # 'fresh_snow_6h:cm',\n",
    "    # 'super_cooled_liquid_water:kgm2',\n",
    "    # 'fresh_snow_3h:cm',\n",
    "    # 'rain_water:kgm2',\n",
    "    # 'precip_type_5min:idx',\n",
    "    # 'precip_5min:mm',\n",
    "    # 'fresh_snow_1h:cm',\n",
    "    # 'sun_azimuth:d',\n",
    "    # 'msl_pressure:hPa',\n",
    "    # 'pressure_100m:hPa',\n",
    "    # 'pressure_50m:hPa',\n",
    "    # 'sfc_pressure:hPa',\n",
    "    # 'prob_rime:p',\n",
    "    # 'wind_speed_10m:ms',\n",
    "    # 'elevation:m',\n",
    "    # 'snow_density:kgm3',\n",
    "    # 'snow_drift:idx',\n",
    "    # 'snow_melt_10min:mm',\n",
    "    # 'wind_speed_w_1000hPa:ms',\n",
    "    # \"date_calc\", something wrong with this column\n",
    "    \"pv_measurement\",\n",
    "]\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "NUM_FEATURES = len(COLUMNS_TO_KEEP) - 1  # -1 because pv_measurement is the target\n",
    "FEATURE_SIZE = 4  # 7 days of hourly data\n",
    "WEIGHT_DECAY = 0.01\n",
    "SEQUENCE_LENGTH = 14*24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Converts time series data into overlapping sequences/windows.\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    target_length = 1\n",
    "    for i in range(len(data) - sequence_length + 1):\n",
    "        seq = data[i : i + sequence_length]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences)\n",
    "\n",
    "\n",
    "class SolarPredictionNet(nn.Module):\n",
    "    def __init__(self, sequence_length, num_channels):\n",
    "        super(SolarPredictionNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_channels, 32, kernel_size=sequence_length, stride=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=1, stride=1)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Parquet files\n",
    "location = \"A\"\n",
    "df_data = pd.read_parquet(f\"data/{location}/X_train_observed.parquet\")\n",
    "df_target = pd.read_parquet(f\"data/{location}/train_targets.parquet\")\n",
    "\n",
    "# Merge the datasets\n",
    "df_merged = pd.merge(\n",
    "    df_data, df_target, left_on=\"date_forecast\", right_on=\"time\", how=\"inner\"\n",
    ")\n",
    "\n",
    "# Downsampling the dataframe to hourly intervals\n",
    "df_merged = df_merged.resample('H', on=\"date_forecast\").mean()\n",
    "\n",
    "df_merged = df_merged[COLUMNS_TO_KEEP]\n",
    "\n",
    "# Set all NaN values to 0\n",
    "df_merged.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "y = df_merged[\"pv_measurement\"]\n",
    "X = df_merged.drop(\"pv_measurement\", axis=1)\n",
    "\n",
    "# Convert dataframes to sequences\n",
    "X_sequences = create_sequences(X.values, SEQUENCE_LENGTH)\n",
    "# Adjust the sequence creation for y\n",
    "y_sequences = y.values[SEQUENCE_LENGTH-1:-1]  # Aligned with the end of each sequence and remove the last element\n",
    "\n",
    "# Sequential Split\n",
    "train_size = int(0.8 * len(X_sequences))\n",
    "X_train, X_val = X_sequences[:train_size], X_sequences[train_size:]\n",
    "y_train, y_val = y_sequences[:train_size], y_sequences[train_size:]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val.shape)\n",
    "\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).transpose(1, 2)  # Adjust shape to [batch, channels, sequence]\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).transpose(1, 2)  # Adjust shape to [batch, channels, sequence]\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "\n",
    "# Create a custom dataset\n",
    "class SolarDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "# Create datasets for training and validation\n",
    "train_dataset = SolarDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = SolarDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ... [Neural Network and Training code from previous messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader):\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Average validation loss\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Training Loss: {loss.item()}, Validation Loss: {val_loss}\"\n",
    "        )\n",
    "\n",
    "    print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training Loss: 55.33476638793945, Validation Loss: 539.0869116368501\n",
      "Epoch 2/100, Training Loss: 55.27851104736328, Validation Loss: 460.4678049709486\n",
      "Epoch 3/100, Training Loss: 54.00733184814453, Validation Loss: 407.93031908118206\n",
      "Epoch 4/100, Training Loss: 49.87413787841797, Validation Loss: 381.74931996801627\n",
      "Epoch 5/100, Training Loss: 47.6141471862793, Validation Loss: 397.1271235217219\n",
      "Epoch 6/100, Training Loss: 50.995140075683594, Validation Loss: 404.59054478355074\n",
      "Epoch 7/100, Training Loss: 51.22968673706055, Validation Loss: 343.0647103682808\n",
      "Epoch 8/100, Training Loss: 43.4141731262207, Validation Loss: 346.3092661111251\n",
      "Epoch 9/100, Training Loss: 47.997318267822266, Validation Loss: 372.28183947438777\n",
      "Epoch 10/100, Training Loss: 52.2094612121582, Validation Loss: 397.02923783012056\n",
      "Epoch 11/100, Training Loss: 52.25319290161133, Validation Loss: 414.0091923423435\n",
      "Epoch 12/100, Training Loss: 52.016868591308594, Validation Loss: 370.5730604088825\n",
      "Epoch 13/100, Training Loss: 46.50218963623047, Validation Loss: 337.8588017795397\n",
      "Epoch 14/100, Training Loss: 48.758975982666016, Validation Loss: 370.98349302747977\n",
      "Epoch 15/100, Training Loss: 50.80824279785156, Validation Loss: 454.80540970097417\n",
      "Epoch 16/100, Training Loss: 47.444114685058594, Validation Loss: 434.25930752961534\n",
      "Epoch 17/100, Training Loss: 41.97150421142578, Validation Loss: 390.3781424087027\n",
      "Epoch 18/100, Training Loss: 50.945640563964844, Validation Loss: 430.99222469329834\n",
      "Epoch 19/100, Training Loss: 55.28605270385742, Validation Loss: 480.20038214973783\n",
      "Epoch 20/100, Training Loss: 52.1694221496582, Validation Loss: 396.19134426116943\n",
      "Epoch 21/100, Training Loss: 49.96830749511719, Validation Loss: 369.15311970918077\n",
      "Epoch 22/100, Training Loss: 50.92654800415039, Validation Loss: 463.50719302633536\n",
      "Epoch 23/100, Training Loss: 51.421485900878906, Validation Loss: 433.3202590009441\n",
      "Epoch 24/100, Training Loss: 44.99169158935547, Validation Loss: 440.64319278882897\n",
      "Epoch 25/100, Training Loss: 37.89003372192383, Validation Loss: 435.1674042162688\n",
      "Epoch 26/100, Training Loss: 51.23381805419922, Validation Loss: 449.5955595970154\n",
      "Epoch 27/100, Training Loss: 45.10977554321289, Validation Loss: 479.6402899493342\n",
      "Epoch 28/100, Training Loss: 47.33049774169922, Validation Loss: 399.7825059061465\n",
      "Epoch 29/100, Training Loss: 42.754920959472656, Validation Loss: 367.91337375018907\n",
      "Epoch 30/100, Training Loss: 50.53099822998047, Validation Loss: 352.78559131207675\n",
      "Epoch 31/100, Training Loss: 50.00750732421875, Validation Loss: 365.677129600359\n",
      "Epoch 32/100, Training Loss: 51.71818161010742, Validation Loss: 363.70598224971604\n",
      "Epoch 33/100, Training Loss: 53.35994338989258, Validation Loss: 377.1151947767838\n",
      "Epoch 34/100, Training Loss: 48.767311096191406, Validation Loss: 355.21308361965674\n",
      "Epoch 35/100, Training Loss: 47.90542984008789, Validation Loss: 387.1039270421733\n",
      "Epoch 36/100, Training Loss: 51.22991943359375, Validation Loss: 376.0324853192205\n",
      "Epoch 37/100, Training Loss: 46.21096420288086, Validation Loss: 423.0038126344266\n",
      "Epoch 38/100, Training Loss: 49.183677673339844, Validation Loss: 389.3307322315548\n",
      "Epoch 39/100, Training Loss: 36.862396240234375, Validation Loss: 375.0384969503983\n",
      "Epoch 40/100, Training Loss: 41.63267135620117, Validation Loss: 394.2295314229053\n",
      "Epoch 41/100, Training Loss: 42.73033905029297, Validation Loss: 385.51090738047725\n",
      "Epoch 42/100, Training Loss: 33.04821014404297, Validation Loss: 401.69974467028743\n",
      "Epoch 43/100, Training Loss: 46.790611267089844, Validation Loss: 401.05601472439974\n",
      "Epoch 44/100, Training Loss: 33.157875061035156, Validation Loss: 374.45689597337145\n",
      "Epoch 45/100, Training Loss: 33.22888946533203, Validation Loss: 405.39810520669687\n",
      "Epoch 46/100, Training Loss: 27.6163330078125, Validation Loss: 386.89659068895423\n",
      "Epoch 47/100, Training Loss: 33.24864196777344, Validation Loss: 370.4131808902906\n",
      "Epoch 48/100, Training Loss: 32.974342346191406, Validation Loss: 375.4940424380095\n",
      "Epoch 49/100, Training Loss: 31.262842178344727, Validation Loss: 365.95486726968187\n",
      "Epoch 50/100, Training Loss: 38.098533630371094, Validation Loss: 369.15821060927016\n",
      "Epoch 51/100, Training Loss: 36.350852966308594, Validation Loss: 358.71178533719933\n",
      "Epoch 52/100, Training Loss: 26.01839256286621, Validation Loss: 400.986837003542\n",
      "Epoch 53/100, Training Loss: 26.065027236938477, Validation Loss: 398.642985706744\n",
      "Epoch 54/100, Training Loss: 26.759014129638672, Validation Loss: 359.7764543243076\n",
      "Epoch 55/100, Training Loss: 27.802648544311523, Validation Loss: 356.1693938193114\n",
      "Epoch 56/100, Training Loss: 35.079837799072266, Validation Loss: 379.0146066416865\n",
      "Epoch 57/100, Training Loss: 27.962467193603516, Validation Loss: 365.7416419568269\n",
      "Epoch 58/100, Training Loss: 30.555871963500977, Validation Loss: 350.5973444710607\n",
      "Epoch 59/100, Training Loss: 35.31740188598633, Validation Loss: 378.73968760863596\n",
      "Epoch 60/100, Training Loss: 40.27531051635742, Validation Loss: 371.2459984862286\n",
      "Epoch 61/100, Training Loss: 37.3925666809082, Validation Loss: 370.48078879066134\n",
      "Epoch 62/100, Training Loss: 34.64131164550781, Validation Loss: 367.68102620995563\n",
      "Epoch 63/100, Training Loss: 37.95516586303711, Validation Loss: 372.3552173324253\n",
      "Epoch 64/100, Training Loss: 35.5972900390625, Validation Loss: 371.0632026091866\n",
      "Epoch 65/100, Training Loss: 31.198537826538086, Validation Loss: 369.0342263242473\n",
      "Epoch 66/100, Training Loss: 26.590770721435547, Validation Loss: 381.4188423571379\n",
      "Epoch 67/100, Training Loss: 34.8904914855957, Validation Loss: 377.4179999517358\n",
      "Epoch 68/100, Training Loss: 37.79488754272461, Validation Loss: 363.2082767693893\n",
      "Epoch 69/100, Training Loss: 38.19257736206055, Validation Loss: 357.75762622252756\n",
      "Epoch 70/100, Training Loss: 28.079559326171875, Validation Loss: 374.3250688677249\n",
      "Epoch 71/100, Training Loss: 36.861114501953125, Validation Loss: 375.37676659874296\n",
      "Epoch 72/100, Training Loss: 29.436315536499023, Validation Loss: 384.25143002427143\n",
      "Epoch 73/100, Training Loss: 39.718414306640625, Validation Loss: 357.5900892382083\n",
      "Epoch 74/100, Training Loss: 38.27574920654297, Validation Loss: 389.08860844114554\n",
      "Epoch 75/100, Training Loss: 42.57697296142578, Validation Loss: 392.89565420150757\n",
      "Epoch 76/100, Training Loss: 33.52573776245117, Validation Loss: 372.9761569396309\n",
      "Epoch 77/100, Training Loss: 34.600067138671875, Validation Loss: 381.59611395130986\n",
      "Epoch 78/100, Training Loss: 20.690723419189453, Validation Loss: 358.2528454946435\n",
      "Epoch 79/100, Training Loss: 16.99752426147461, Validation Loss: 367.14273558492243\n",
      "Epoch 80/100, Training Loss: 47.585960388183594, Validation Loss: 384.9475211682527\n",
      "Epoch 81/100, Training Loss: 30.580739974975586, Validation Loss: 367.45224887391794\n",
      "Epoch 82/100, Training Loss: 36.342552185058594, Validation Loss: 377.69950999384344\n",
      "Epoch 83/100, Training Loss: 34.61696243286133, Validation Loss: 374.13325512927514\n",
      "Epoch 84/100, Training Loss: 36.30854797363281, Validation Loss: 375.70695024987924\n",
      "Epoch 85/100, Training Loss: 27.871591567993164, Validation Loss: 432.17601406055945\n",
      "Epoch 86/100, Training Loss: 31.5378360748291, Validation Loss: 370.269550188728\n",
      "Epoch 87/100, Training Loss: 34.607421875, Validation Loss: 365.8262349211651\n",
      "Epoch 88/100, Training Loss: 35.1654167175293, Validation Loss: 407.65109317199045\n",
      "Epoch 89/100, Training Loss: 30.561084747314453, Validation Loss: 390.83890319907147\n",
      "Epoch 90/100, Training Loss: 38.242591857910156, Validation Loss: 382.69283081137615\n",
      "Epoch 91/100, Training Loss: 33.73656463623047, Validation Loss: 379.2121666618015\n",
      "Epoch 92/100, Training Loss: 40.227413177490234, Validation Loss: 375.66585928460825\n",
      "Epoch 93/100, Training Loss: 41.89704132080078, Validation Loss: 386.60987698513526\n",
      "Epoch 94/100, Training Loss: 40.80217361450195, Validation Loss: 386.9262762588003\n",
      "Epoch 95/100, Training Loss: 41.42710494995117, Validation Loss: 398.7391125637552\n",
      "Epoch 96/100, Training Loss: 40.122032165527344, Validation Loss: 383.15978819391\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, location):\n",
    "    filename = f\"model_location_{location}.pt\"\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    print(f\"Model saved as {filename}\")\n",
    "\n",
    "# ... [Training Loop]\n",
    "\n",
    "model = SolarPredictionNet(SEQUENCE_LENGTH, NUM_FEATURES)\n",
    "train_model(model, train_loader, val_loader)\n",
    "save_model(model, location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720\n",
      "720\n",
      "720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fm/6k4602pj3xx1rcp_y10195140000gn/T/ipykernel_43337/4024925674.py:58: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[4.70938539e-05 4.70938539e-05 4.70938539e-05 4.70938539e-05\n",
      " 4.70938539e-05 4.70938539e-05 8.96509628e+01 1.18579124e+02\n",
      " 4.70938539e-05 4.70938539e-05 4.70938539e-05 4.70938539e-05\n",
      " 4.70938539e-05 4.70938539e-05 4.70938539e-05 4.70938539e-05\n",
      " 4.70938539e-05 2.47067795e+02 3.58291809e+02 3.51595879e+01\n",
      " 4.70938539e-05 4.70938539e-05 4.70938539e-05 4.70938539e-05\n",
      " 4.85184097e+01 1.07977710e+03 6.94756445e+03 1.57140391e+04\n",
      " 2.28185000e+04 2.62857422e+04 2.82635742e+04 2.80444336e+04\n",
      " 2.64991172e+04 2.58787734e+04 2.63951211e+04 2.99757109e+04\n",
      " 3.31621641e+04 3.54950234e+04 3.81794766e+04 4.19416562e+04\n",
      " 4.55622578e+04 4.79380469e+04 4.85898594e+04 4.84867656e+04\n",
      " 4.69825859e+04 4.56112891e+04 4.50171094e+04 4.53095586e+04\n",
      " 4.55900039e+04 4.68641719e+04 4.74837109e+04 4.80447500e+04\n",
      " 4.86153359e+04 4.85461484e+04 4.87137227e+04 4.75472539e+04\n",
      " 4.64724688e+04 4.64345195e+04 4.72064219e+04 4.90382656e+04\n",
      " 5.17813398e+04 5.51350469e+04 5.79365117e+04 6.01832383e+04\n",
      " 6.14127109e+04 6.05527578e+04 5.87507617e+04 5.69662852e+04\n",
      " 5.43252344e+04 5.16036758e+04 5.00763008e+04 4.88673203e+04\n",
      " 4.91494453e+04 4.88489766e+04 4.99937656e+04 4.95218633e+04\n",
      " 4.86573047e+04 4.76016719e+04 4.65865547e+04 4.57981328e+04\n",
      " 4.46530547e+04 4.35857344e+04 4.34389023e+04 4.63646406e+04\n",
      " 5.22375664e+04 5.88317148e+04 6.37199570e+04 6.85161328e+04\n",
      " 7.13532812e+04 7.31062031e+04 7.35061719e+04 7.28893828e+04\n",
      " 7.06005469e+04 6.63841562e+04 6.17358594e+04 5.85317266e+04\n",
      " 5.56097656e+04 5.49844492e+04 5.75885781e+04 5.95969180e+04\n",
      " 6.07336523e+04 6.16545703e+04 6.20091641e+04 6.12682070e+04\n",
      " 5.96035391e+04 5.81668008e+04 5.52070312e+04 5.46186562e+04\n",
      " 5.48740000e+04 5.53161797e+04 5.54200781e+04 5.70222070e+04\n",
      " 5.86338438e+04 5.99940234e+04 6.17804453e+04 6.18072578e+04\n",
      " 5.99460117e+04 5.61435625e+04 5.12402031e+04 4.83707500e+04\n",
      " 4.65397812e+04 4.37681445e+04 4.02876719e+04 3.73190547e+04\n",
      " 3.42975508e+04 2.98319805e+04 2.71008887e+04 2.41841191e+04\n",
      " 2.13094805e+04 1.98518086e+04 1.81684141e+04 1.65902188e+04\n",
      " 1.78417988e+04 1.87667148e+04 2.05656797e+04 2.23390000e+04\n",
      " 2.28052598e+04 2.25833359e+04 2.37111406e+04 2.36204141e+04\n",
      " 2.26238555e+04 2.32130293e+04 2.49739062e+04 2.73301836e+04\n",
      " 3.09906113e+04 3.35131719e+04 3.39725078e+04 3.14804688e+04\n",
      " 2.76446172e+04 2.34652148e+04 2.05525469e+04 1.81993262e+04\n",
      " 1.71013379e+04 1.60343711e+04 1.72073203e+04 1.85648242e+04\n",
      " 2.07761641e+04 2.32576191e+04 2.61266895e+04 2.84689375e+04\n",
      " 3.38052227e+04 3.89404688e+04 4.44020664e+04 4.79234766e+04\n",
      " 4.76344570e+04 4.87930000e+04 4.89345547e+04 4.84029609e+04\n",
      " 4.81059453e+04 4.55935742e+04 4.19759531e+04 3.81568438e+04\n",
      " 3.33730039e+04 2.81330137e+04 2.17008301e+04 1.87383516e+04\n",
      " 1.85576230e+04 1.97983203e+04 2.18748008e+04 2.44530430e+04\n",
      " 2.88355645e+04 3.50408945e+04 4.13947266e+04 4.73530703e+04\n",
      " 5.19427617e+04 5.48020742e+04 5.70256875e+04 5.83016406e+04\n",
      " 5.68353516e+04 5.40524180e+04 5.16428516e+04 4.95835000e+04\n",
      " 4.73297852e+04 4.52204453e+04 4.21068047e+04 3.88850195e+04\n",
      " 3.45546328e+04 2.85277539e+04 2.10480156e+04 1.32154531e+04\n",
      " 8.63931055e+03 6.92777539e+03 6.07433643e+03 6.09039551e+03\n",
      " 7.04317480e+03 7.86786426e+03 8.42777148e+03 7.89139355e+03\n",
      " 7.11031738e+03 7.44092090e+03 7.37142920e+03 8.42799023e+03\n",
      " 8.32625488e+03 7.94941699e+03 7.68896582e+03 7.81357520e+03\n",
      " 9.12639844e+03 1.01730293e+04 1.04282344e+04 9.73259473e+03\n",
      " 9.21855859e+03 7.99083105e+03 7.14609521e+03 5.62841406e+03\n",
      " 4.44167529e+03 3.80148950e+03 3.22025293e+03 2.66482715e+03\n",
      " 2.37657397e+03 2.86253076e+03 3.86821143e+03 5.21515088e+03\n",
      " 6.43403711e+03 8.36016602e+03 1.07550713e+04 1.20091562e+04\n",
      " 1.25807461e+04 1.15844814e+04 1.01278164e+04 9.69267188e+03\n",
      " 9.46762012e+03 9.62556445e+03 8.99485059e+03 8.11712207e+03\n",
      " 7.36381055e+03 6.54681445e+03 5.82260547e+03 5.16309863e+03\n",
      " 4.69282568e+03 4.26493262e+03 4.41128955e+03 4.98898730e+03\n",
      " 6.19312109e+03 8.52682031e+03 1.12115957e+04 1.37076299e+04\n",
      " 1.56683330e+04 1.67052930e+04 1.50214531e+04 1.26851113e+04\n",
      " 9.28297363e+03 8.10965820e+03 6.87855957e+03 5.80488965e+03\n",
      " 4.37583301e+03 3.15177637e+03 1.79668896e+03 9.67364624e+02\n",
      " 2.50101852e+02 4.70938539e-05 4.70938539e-05 4.70938539e-05\n",
      " 4.70938539e-05 4.70938539e-05 4.70938539e-05 4.70938539e-05\n",
      " 4.70938539e-05 4.70938539e-05 4.70938539e-05 4.70938539e-05\n",
      " 1.86797760e+02 7.97257935e+02 1.47373218e+03 2.06431543e+03\n",
      " 2.68033105e+03 3.21560913e+03 3.74806348e+03 4.71866943e+03\n",
      " 5.67568359e+03 6.67565625e+03 6.56536865e+03 5.51361377e+03\n",
      " 4.43189551e+03 3.21206177e+03 1.74199683e+03 1.01221472e+03\n",
      " 4.94521881e+02 1.11120132e+02 4.70938539e-05 4.70938539e-05\n",
      " 4.70938539e-05 2.31176849e+02 5.56047424e+02 1.32898145e+03\n",
      " 2.62333154e+03 4.25696631e+03 5.95106934e+03 7.29672314e+03\n",
      " 8.26167969e+03 9.23829688e+03 1.04995371e+04 1.32519824e+04\n",
      " 1.63478008e+04 1.77855605e+04 1.70539102e+04 1.59283652e+04\n",
      " 1.44256221e+04 1.21645605e+04 9.14609277e+03 6.43702539e+03\n",
      " 4.98575977e+03 3.88013843e+03 2.68309424e+03 2.24357837e+03\n",
      " 2.50538403e+03 2.85062793e+03 3.67783643e+03 4.80024072e+03\n",
      " 6.84584180e+03 1.08080840e+04 1.50535938e+04 1.86073496e+04\n",
      " 2.23859297e+04 2.46266816e+04 2.60475820e+04 2.69626426e+04\n",
      " 2.69744219e+04 2.68525742e+04 2.57958516e+04 2.29963965e+04\n",
      " 1.83656484e+04 1.22813223e+04 7.11714258e+03 4.58728320e+03\n",
      " 3.22916504e+03 2.28372852e+03 1.80541846e+03 1.85128052e+03\n",
      " 2.38946021e+03 3.32823145e+03 4.58212158e+03 6.53658887e+03\n",
      " 1.07534346e+04 1.67527012e+04 2.18603789e+04 2.51654102e+04\n",
      " 2.67350430e+04 2.71485273e+04 2.71395781e+04 2.71341133e+04\n",
      " 2.71462930e+04 2.69212012e+04 2.57206211e+04 2.27968320e+04\n",
      " 1.80519531e+04 1.19084648e+04 6.95217676e+03 4.54313232e+03\n",
      " 3.24813940e+03 2.35111646e+03 1.92303198e+03 1.98364355e+03\n",
      " 2.51178906e+03 3.44311475e+03 4.67836475e+03 6.61611084e+03\n",
      " 1.08261934e+04 1.68332305e+04 2.20046191e+04 2.54106211e+04\n",
      " 2.70636426e+04 2.74850898e+04 2.74255918e+04 2.73502148e+04\n",
      " 2.73551719e+04 2.70460508e+04 2.57127344e+04 2.27050352e+04\n",
      " 1.79634023e+04 1.18773184e+04 6.93042969e+03 4.52112549e+03\n",
      " 3.22185132e+03 2.31024927e+03 1.85727954e+03 1.88739551e+03\n",
      " 2.37549268e+03 3.26375439e+03 4.46950000e+03 6.21582471e+03\n",
      " 9.93065820e+03 1.54261973e+04 2.05712383e+04 2.40336719e+04\n",
      " 2.57751094e+04 2.62832656e+04 2.62942812e+04 2.62851367e+04\n",
      " 2.62892266e+04 2.59177812e+04 2.45313008e+04 2.15838008e+04\n",
      " 1.69970977e+04 1.10841641e+04 6.57938232e+03 4.41465820e+03\n",
      " 3.19061426e+03 2.31204688e+03 1.90336255e+03 1.96962671e+03\n",
      " 2.45527344e+03 3.33220605e+03 4.52007422e+03 6.29044531e+03\n",
      " 1.00883047e+04 1.58056260e+04 2.11545684e+04 2.48028086e+04\n",
      " 2.67255625e+04 2.74974961e+04 2.78019668e+04 2.79744219e+04\n",
      " 2.80951309e+04 2.76713066e+04 2.60750820e+04 2.28772344e+04\n",
      " 1.80339336e+04 1.17704160e+04 6.76345117e+03 4.41471338e+03\n",
      " 3.14848584e+03 2.26127832e+03 1.83185791e+03 1.87386865e+03\n",
      " 2.37005298e+03 3.26674829e+03 4.48026367e+03 6.28469043e+03\n",
      " 1.01046592e+04 1.58001719e+04 2.11799941e+04 2.48705957e+04\n",
      " 2.68284648e+04 2.76144062e+04 2.79342461e+04 2.80944199e+04\n",
      " 2.79911797e+04 2.74199102e+04 2.57668398e+04 2.24703145e+04\n",
      " 1.74229160e+04 1.10379102e+04 6.29594824e+03 4.17783008e+03\n",
      " 2.90182593e+03 2.00750146e+03 1.55821045e+03 1.56821899e+03\n",
      " 2.02698108e+03 2.87932568e+03 4.03306226e+03 5.50638086e+03\n",
      " 8.48071484e+03 1.34520508e+04 1.89623516e+04 2.29617109e+04\n",
      " 2.53189473e+04 2.63207539e+04 2.66659844e+04 2.68114141e+04\n",
      " 2.66886211e+04 2.61131484e+04 2.44691172e+04 2.12318477e+04\n",
      " 1.62837656e+04 1.02775977e+04 6.03000098e+03 4.07377734e+03\n",
      " 2.83860181e+03 1.97658325e+03 1.55380078e+03 1.59664722e+03\n",
      " 2.09140796e+03 2.96380957e+03 4.12110938e+03 5.63734375e+03\n",
      " 8.77568359e+03 1.39216016e+04 1.93298457e+04 2.31731426e+04\n",
      " 2.53769141e+04 2.63134844e+04 2.65364727e+04 2.65806270e+04\n",
      " 2.66483281e+04 2.60812891e+04 2.42687305e+04 2.08365820e+04\n",
      " 1.57245078e+04 9.75186328e+03 5.70932617e+03 3.89246045e+03\n",
      " 2.65736279e+03 1.78179907e+03 1.37093457e+03 1.39139160e+03\n",
      " 1.82068738e+03 2.66053101e+03 3.81256250e+03 5.24433301e+03\n",
      " 7.94555469e+03 1.27326475e+04 1.82649570e+04 2.22957305e+04\n",
      " 2.46333672e+04 2.57618164e+04 2.62057910e+04 2.64009805e+04\n",
      " 2.63416309e+04 2.56758477e+04 2.38266719e+04 2.03964219e+04\n",
      " 1.53272568e+04 9.54374023e+03 5.68239990e+03 3.93686646e+03\n",
      " 2.76267480e+03 1.94137463e+03 1.55446436e+03 1.62198804e+03\n",
      " 2.11181763e+03 2.97025244e+03 4.12579004e+03 5.62295654e+03\n",
      " 8.69584375e+03 1.37556621e+04 1.92387812e+04 2.32596504e+04\n",
      " 2.56980488e+04 2.68878418e+04 2.74764629e+04 2.76689180e+04\n",
      " 2.74807070e+04 2.67472188e+04 2.49115156e+04 2.15180977e+04\n",
      " 1.64245371e+04 1.03011729e+04 6.03448535e+03 4.10040527e+03\n",
      " 2.89219971e+03 2.06060645e+03 1.64647998e+03 1.66699146e+03\n",
      " 2.10943530e+03 2.90495044e+03 3.97959033e+03 5.35752490e+03\n",
      " 8.07139697e+03 1.28886719e+04 1.83026602e+04 2.24153984e+04\n",
      " 2.49359023e+04 2.62475020e+04 2.67699727e+04 2.69533984e+04\n",
      " 2.68578184e+04 2.62198828e+04 2.43145605e+04 2.08793965e+04\n",
      " 1.59334189e+04 1.00854180e+04 5.98056641e+03 4.06641357e+03\n",
      " 2.85955664e+03 2.02481360e+03 1.60319702e+03 1.60348291e+03\n",
      " 2.02198499e+03 2.82751611e+03 3.94194946e+03 5.37745068e+03\n",
      " 8.19155176e+03 1.31986875e+04 1.88246641e+04 2.30293945e+04\n",
      " 2.55922500e+04 2.69057246e+04 2.75745605e+04 2.79619141e+04\n",
      " 2.79857324e+04 2.72961738e+04 2.52482402e+04 2.17220742e+04\n",
      " 1.67591738e+04 1.07581494e+04 6.37290674e+03 4.30366406e+03\n",
      " 3.08208643e+03 2.23831982e+03 1.82033618e+03 1.82266199e+03\n",
      " 2.24247754e+03 3.04136816e+03 4.13416260e+03 5.59450195e+03\n",
      " 8.59431250e+03 1.36221514e+04 1.89808477e+04 2.28779355e+04\n",
      " 2.52260273e+04 2.63538105e+04 2.68710703e+04 2.70545586e+04\n",
      " 2.69644766e+04 2.62897520e+04 2.43990352e+04 2.10126465e+04\n",
      " 1.60710000e+04 1.02873066e+04 6.14014600e+03 4.18207617e+03\n",
      " 2.96324121e+03 2.14637012e+03 1.77499536e+03 1.83224170e+03\n",
      " 2.29101147e+03 3.10992188e+03 4.22643115e+03 5.78604102e+03\n",
      " 9.28738379e+03 1.49393506e+04 2.06788652e+04 2.49076016e+04\n",
      " 2.74733320e+04 2.87336602e+04 2.92473281e+04 2.94046289e+04\n",
      " 2.92444434e+04 2.84410137e+04 2.63886523e+04 2.27919453e+04\n",
      " 1.77061211e+04 1.14405723e+04 6.65095703e+03 4.38683398e+03\n",
      " 3.10951758e+03 2.25622461e+03 1.82981592e+03 1.84198608e+03\n",
      " 2.26300806e+03 3.05053052e+03 4.13559229e+03 5.60429395e+03\n",
      " 8.68851758e+03 1.38470781e+04 1.94569336e+04 2.36586328e+04\n",
      " 2.62393906e+04 2.74417578e+04 2.78560898e+04 2.79554004e+04\n",
      " 2.77710430e+04 2.69320234e+04 2.50007480e+04 2.16071680e+04\n",
      " 1.67155508e+04 1.08286963e+04 6.44837354e+03 4.33410303e+03\n",
      " 3.08858618e+03 2.22976660e+03 1.78422876e+03 1.79110144e+03\n",
      " 2.22308643e+03 3.01257788e+03 4.09060815e+03 5.53055273e+03\n",
      " 8.52101367e+03 1.36860938e+04 1.94304277e+04 2.37848027e+04\n",
      " 2.64714961e+04 2.76496758e+04 2.79684102e+04 2.80008828e+04\n",
      " 2.78688164e+04 2.71229512e+04 2.52106973e+04 2.17745820e+04\n",
      " 1.67771270e+04 1.07090586e+04 6.31270996e+03 4.22682910e+03\n",
      " 2.97451782e+03 2.10168921e+03 1.62886169e+03 1.59041260e+03\n",
      " 1.98755518e+03 2.75950146e+03 3.82568140e+03 5.20965625e+03\n",
      " 7.95262793e+03 1.29772168e+04 1.87600898e+04 2.31199590e+04\n",
      " 2.58122500e+04 2.71220391e+04 2.76236621e+04 2.77982793e+04]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_submission.loc[mask, \"prediction\"] = preds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_model(location):\n",
    "    model = SolarPredictionNet(SEQUENCE_LENGTH, NUM_FEATURES)\n",
    "    model.load_state_dict(torch.load(f\"model_location_{location}.pt\"))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def pad_data(data, sequence_length):\n",
    "    \"\"\"\n",
    "    Pads the data with zeros at the beginning to ensure \n",
    "    the final number of sequences matches the original number of data points.\n",
    "    \"\"\"\n",
    "    padding = np.zeros((sequence_length - 1, data.shape[1]))\n",
    "    return np.vstack((padding, data))\n",
    "\n",
    "\n",
    "def make_predictions(location, df_test):\n",
    "    # Load model\n",
    "    model = load_model(location)\n",
    "    \n",
    "    # Ensure the index is a datetime\n",
    "    df_test['date_forecast'] = pd.to_datetime(df_test['date_forecast'])\n",
    "    # Set the date_calc column as the index for resampling\n",
    "    df_test.set_index('date_forecast', inplace=True)\n",
    "    # Resample to 1-hour intervals\n",
    "\n",
    "    df_test = df_test.resample('1H').mean()\n",
    "    df_test = df_test.dropna(how='all').reset_index(drop=True)\n",
    "    \n",
    "    # Drop columns that are not required\n",
    "    df_test = df_test.drop(['date_forecast', 'date_calc'], axis=1, errors='ignore')\n",
    "    # Fill NaNs (if any after resampling)\n",
    "    df_test.fillna(0, inplace=True)\n",
    "    # Create sequences and normalize\n",
    "    padded_data = pad_data(df_test.values, SEQUENCE_LENGTH)\n",
    "    test_sequences = create_sequences(padded_data, SEQUENCE_LENGTH)\n",
    "    print(len(test_sequences))\n",
    "    test_sequences = scaler.transform(test_sequences.reshape(-1, test_sequences.shape[-1])).reshape(test_sequences.shape)\n",
    "    test_tensor = torch.tensor(test_sequences, dtype=torch.float32).transpose(1, 2)\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        predictions = model(test_tensor)\n",
    "        predictions = predictions.numpy().flatten()\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Read the Kaggle test.csv to get the location and ids\n",
    "df_submission = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "locations = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "# Iterate over the locations and fill in the predictions\n",
    "for loc in locations:\n",
    "    # Load forecasted weather data for testing for the current location\n",
    "    df_loc = pd.read_parquet(f\"data/{loc}/X_test_estimated.parquet\")\n",
    "    preds = make_predictions(loc, df_loc)\n",
    "    # Assign the predictions to df_submission for the current location\n",
    "    mask = df_submission[\"location\"] == loc\n",
    "    df_submission.loc[mask, \"prediction\"] = preds\n",
    "\n",
    "# Save the results to a new submission file\n",
    "df_submission[[\"id\", \"prediction\"]].to_csv(\"sample_kaggle_submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
