{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from autogluon.tabular import TabularPredictor\n",
    "import autogluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constans and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = [\"A\", \"B\", \"C\"]\n",
    "features_order = []\n",
    "\n",
    "LAGGED_COLUMNS_TO_KEEP = [\n",
    "    'direct_rad:W_lag_1h', \n",
    "    'direct_rad:W_lag_forward_1h', \n",
    "    'clear_sky_rad:W_lag_1h', \n",
    "    'clear_sky_rad:W_lag_forward_1h', \n",
    "    'diffuse_rad:W_lag_1h', \n",
    "    'diffuse_rad:W_lag_forward_1h', \n",
    "    'direct_rad_1h:J_lag_1h', \n",
    "    'direct_rad_1h:J_lag_forward_1h', \n",
    "    'is_in_shadow:idx_lag_1h', \n",
    "    'is_in_shadow:idx_lag_forward_1h', \n",
    "    'clear_sky_energy_1h:J_lag_1h', \n",
    "    'clear_sky_energy_1h:J_lag_forward_1h', \n",
    "    'effective_cloud_cover:p_lag_1h', \n",
    "    'effective_cloud_cover:p_lag_forward_1h', \n",
    "    'visibility:m_lag_1h', \n",
    "    'visibility:m_lag_forward_1h', \n",
    "    'total_cloud_cover:p_lag_1h', \n",
    "    'total_cloud_cover:p_lag_forward_1h', \n",
    "\n",
    "\n",
    "    # 'direct_rad:W_lag_2h', \n",
    "    # 'direct_rad:W_lag_forward_2h', \n",
    "    # 'clear_sky_rad:W_lag_2h', \n",
    "    # 'clear_sky_rad:W_lag_forward_2h', \n",
    "    # 'diffuse_rad:W_lag_2h', \n",
    "    # 'diffuse_rad:W_lag_forward_2h', \n",
    "    # 'direct_rad_1h:J_lag_2h', \n",
    "    # 'direct_rad_1h:J_lag_forward_2h', \n",
    "    # 'is_in_shadow:idx_lag_2h', \n",
    "    # 'is_in_shadow:idx_lag_forward_2h', \n",
    "    # 'clear_sky_energy_1h:J_lag_2h', \n",
    "    # 'clear_sky_energy_1h:J_lag_forward_2h', \n",
    "    # 'effective_cloud_cover:p_lag_2h', \n",
    "    # 'effective_cloud_cover:p_lag_forward_2h', \n",
    "    # 'visibility:m_lag_2h', \n",
    "    # 'visibility:m_lag_forward_2h', \n",
    "    # 'total_cloud_cover:p_lag_2h', \n",
    "    # 'total_cloud_cover:p_lag_forward_2h', \n",
    "\n",
    "    # 'direct_rad:W_lag_3h', \n",
    "    # 'direct_rad:W_lag_forward_3h', \n",
    "    # 'clear_sky_rad:W_lag_3h', \n",
    "    # 'clear_sky_rad:W_lag_forward_3h', \n",
    "    # 'diffuse_rad:W_lag_3h', \n",
    "    # 'diffuse_rad:W_lag_forward_3h', \n",
    "    # 'direct_rad_1h:J_lag_3h', \n",
    "    # 'direct_rad_1h:J_lag_forward_3h', \n",
    "    # 'is_in_shadow:idx_lag_3h', \n",
    "    # 'is_in_shadow:idx_lag_forward_3h', \n",
    "    # 'clear_sky_energy_1h:J_lag_3h', \n",
    "    # 'clear_sky_energy_1h:J_lag_forward_3h', \n",
    "    # 'effective_cloud_cover:p_lag_3h', \n",
    "    # 'effective_cloud_cover:p_lag_forward_3h', \n",
    "    # 'visibility:m_lag_3h', \n",
    "    # 'visibility:m_lag_forward_3h', \n",
    "    # 'total_cloud_cover:p_lag_3h', \n",
    "    # 'total_cloud_cover:p_lag_forward_3h'\n",
    "]\n",
    "\n",
    "CUSTOM_COLUMNS_TO_KEEP = [\n",
    "    \"hour_cos\",\n",
    "    \"hour_sin\",\n",
    "    \"month_sin\",\n",
    "    \"month_cos\",\n",
    "    \"day-of-year\",\n",
    "]\n",
    "\n",
    "WEATHER_FEATURES = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "]\n",
    "\n",
    "\n",
    "TEST_COLUMNS_TO_KEEP = [\n",
    "    \"direct_rad:W\",\n",
    "    \"clear_sky_rad:W\",\n",
    "    \"diffuse_rad:W\",\n",
    "    \"direct_rad_1h:J\",\n",
    "    \"is_in_shadow:idx\",\n",
    "    \"clear_sky_energy_1h:J\",\n",
    "    \"diffuse_rad_1h:J\",\n",
    "    \"is_day:idx\",\n",
    "    \"sun_elevation:d\",\n",
    "    \"ceiling_height_agl:m\",\n",
    "    \"effective_cloud_cover:p\",\n",
    "    \"visibility:m\",\n",
    "    \"total_cloud_cover:p\",\n",
    "    \"air_density_2m:kgm3\",\n",
    "    \"wind_speed_v_10m:ms\",\n",
    "    \"dew_point_2m:K\",\n",
    "    \"wind_speed_u_10m:ms\",\n",
    "    \"t_1000hPa:K\",\n",
    "    \"absolute_humidity_2m:gm3\",\n",
    "    \"snow_water:kgm2\",\n",
    "    \"relative_humidity_1000hPa:p\",\n",
    "    \"fresh_snow_24h:cm\",\n",
    "    \"cloud_base_agl:m\",\n",
    "    \"fresh_snow_12h:cm\",\n",
    "    \"snow_depth:cm\",\n",
    "    \"dew_or_rime:idx\",\n",
    "    \"fresh_snow_6h:cm\",\n",
    "    \"super_cooled_liquid_water:kgm2\",\n",
    "    \"fresh_snow_3h:cm\",\n",
    "    \"rain_water:kgm2\",\n",
    "    \"precip_type_5min:idx\",\n",
    "    \"precip_5min:mm\",\n",
    "    \"fresh_snow_1h:cm\",\n",
    "    \"sun_azimuth:d\",\n",
    "    \"msl_pressure:hPa\",\n",
    "    \"pressure_100m:hPa\",\n",
    "    \"pressure_50m:hPa\",\n",
    "    \"sfc_pressure:hPa\",\n",
    "    \"prob_rime:p\",\n",
    "    \"wind_speed_10m:ms\",\n",
    "    # \"elevation:m\",\n",
    "    # \"snow_density:kgm3\",\n",
    "    # \"snow_drift:idx\",\n",
    "    \"snow_melt_10min:mm\",\n",
    "    \"wind_speed_w_1000hPa:ms\",\n",
    "    \"observed_or_estimated\"\n",
    "    # \"location_A\",\n",
    "    # \"location_B\",\n",
    "    # \"location_C\",\n",
    "    # \"date_calc\",\n",
    "] + CUSTOM_COLUMNS_TO_KEEP  +  LAGGED_COLUMNS_TO_KEEP\n",
    "\n",
    "COLUMNS_TO_KEEP = TEST_COLUMNS_TO_KEEP + [\"pv_measurement\"]\n",
    "\n",
    "\n",
    "\n",
    "def create_weather_lagged_features(df, weather_features):\n",
    "    # Choose the weather features for which you want to create lagged versions\n",
    "    for feature in weather_features:\n",
    "        # Assuming hourly data, adjust the lags for your specific dataset\n",
    "        # Creating lagged features for 1 hour, 1 day, and 1 week\n",
    "        df[f'{feature}_lag_1h'] = df[feature].shift(1)\n",
    "        # df[f'{feature}_lag_2h'] = df[feature].shift(2)\n",
    "        # df[f'{feature}_lag_3h'] = df[feature].shift(3)\n",
    "\n",
    "        df[f'{feature}_lag_forward_1h'] = df[feature].shift(-1)\n",
    "        # df[f'{feature}_lag_forward_2h'] = df[feature].shift(-2)\n",
    "        # df[f'{feature}_lag_forward_3h'] = df[feature].shift(-3)\n",
    "        # df[f'{feature}_lag_24h'] = df[feature].shift(24*4)\n",
    "        # df[f'{feature}_lag_168h'] = df[feature].shift(24 * 7 * 4 * 365)\n",
    "        # df[f'{feature}_front_lag_1h'] = df[feature].shift(-4)\n",
    "        # df[f'{feature}_front_lag_24h'] = df[feature].shift(-24*4)\n",
    "\n",
    "\n",
    "    # Handling edges by filling NaNs with appropriate values or dropping them\n",
    "    # You may choose to fill with zeroes or interpolate, based on what makes more sense for your data\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "    df.fillna(method='bfill', inplace=True)  # Backward fill\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_lagged_features(df, column_name='pv_measurement'):\n",
    "    # Assuming 'date_forecast' is the datetime column used for sorting\n",
    "\n",
    "    df[f'{column_name}_prev_month'] = df[column_name].shift(24*7) # previous week\n",
    "\n",
    "    # For yearly lag, you would need to calculate the number of observations per year\n",
    "    # If the data is not consistent (leap years, etc.), you may need a more complex method\n",
    "    # Here's a simple version assuming 365 days a year:\n",
    "    df[f'{column_name}_prev_year'] = df[column_name].shift(24*365) # previous year\n",
    "    df[f'{column_name}_2years_ago'] = df[column_name].shift(24*365*2) # next year\n",
    "\n",
    "    # Handling edges by filling NaNs with appropriate values or dropping them\n",
    "    df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "    df.fillna(method='bfill', inplace=True)  # Backward fill\n",
    "\n",
    "    return df\n",
    "\n",
    "B_SCALE_VALUE = 6.3\n",
    "C_SCALE_VALUE = 8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_custom_fields(df):\n",
    "     df['hour_sin'] = np.sin(2 * np.pi * df['date_forecast'].dt.hour / 24)\n",
    "     df['hour_cos'] = np.cos(2 * np.pi * df['date_forecast'].dt.hour / 24)\n",
    "\n",
    "     df['month_sin'] = np.sin(2 * np.pi * df['date_forecast'].dt.month / 12)\n",
    "     df['month_cos'] = np.cos(2 * np.pi * df['date_forecast'].dt.month / 12)\n",
    "     df['day-of-year'] = df['date_forecast'].dt.dayofyear\n",
    "     return df\n",
    "\n",
    "def remove_outliers(df):\n",
    "    # Use a mask to filter out the rows where rolling std is zero but keep the rows where the value itself is zero\n",
    "    mask = (df['pv_measurement'].rolling(5).std() == 0) & (df['pv_measurement'] != 0)\n",
    "    df = df[~mask]\n",
    "    return df\n",
    "\n",
    "def resample_add_data(df, is_test_data):\n",
    "    df = add_custom_fields(df)\n",
    "    df.set_index('date_forecast', inplace=True)\n",
    "    df = df.resample('1H').mean()\n",
    "    # Remove empty dates if test data\n",
    "    if is_test_data:\n",
    "        non_nan_threshold = len(df.columns) // 2  \n",
    "        df.dropna(thresh=non_nan_threshold, inplace=True)\n",
    "    df.interpolate(method=\"linear\", inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_location_feature(X, location):\n",
    "      # Treat location as a categorical feature by converting it to a category type\n",
    "    X['location'] = location\n",
    "    X['location'] = X['location'].astype(str)  # Convert to string if 'location' is not an int\n",
    "    X['dew_or_rime:idx'] = X['dew_or_rime:idx'].astype(str)\n",
    "    X['is_day:idx'] = X['is_day:idx'].astype(str)\n",
    "    X['is_in_shadow:idx'] = X['is_in_shadow:idx'].astype(str)\n",
    "    categorical_columns = ['location', 'dew_or_rime:idx', 'is_day:idx', 'is_in_shadow:idx']\n",
    "\n",
    "    # Before filling NaN values, add 'missing' as a category for each categorical column.\n",
    "    for column in categorical_columns:\n",
    "        X[column] = X[column].astype('category')  # Ensure the column is of type 'category'.\n",
    "        if 'missing' not in X[column].cat.categories:\n",
    "            X[column] = X[column].cat.add_categories(['missing'])  # Add 'missing' as a new category.\n",
    "        X[column] = X[column].fillna('missing')\n",
    "    X['location'] = X['location'].astype('category')\n",
    "    X['dew_or_rime:idx'] = X['dew_or_rime:idx'].astype('category')\n",
    "    X['is_day:idx'] = X['is_day:idx'].astype('category')\n",
    "    X['is_in_shadow:idx'] = X['is_in_shadow:idx'].astype('category')\n",
    "    \n",
    "    return X\n",
    "\n",
    "def add_scaling(X_test, X_training, location):\n",
    "    global scalers\n",
    "    continuous_columns = X_training.select_dtypes(include=['float32', 'int32']).columns\n",
    "    if location not in scalers:\n",
    "        scalers[location] = MinMaxScaler()\n",
    "    X_training[continuous_columns] = scalers[location].fit_transform(X_training[continuous_columns])\n",
    "    \n",
    "    X_test[continuous_columns] = scalers[location].transform(X_test[continuous_columns])\n",
    "\n",
    "    return X_test, X_training\n",
    "\n",
    "def make_observed_and_estimated_category(df_observed, df_estimated, df_test):\n",
    "     # Hot encode in wether observed or estimated\n",
    "    df_observed['observed_or_estimated'] = 'observed'\n",
    "    df_estimated['observed_or_estimated'] = 'estimated'\n",
    "    df_test['observed_or_estimated'] = 'estimated'\n",
    "    # Concatenate observed and estimated\n",
    "    df_training = pd.concat([df_observed, df_estimated], axis=0).sort_values(by=\"date_forecast\")\n",
    "    df_training['observed_or_estimated'] = df_training['observed_or_estimated'].astype('category')\n",
    "    df_test['observed_or_estimated'] = df_test['observed_or_estimated'].astype('category')\n",
    "\n",
    "    return df_training, df_test\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:162: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/620350683.py:163: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize a dictionary to hold the scalers for each location\n",
    "\n",
    "scalers = {}\n",
    "\n",
    "\n",
    "def prepare_data(location):\n",
    "    # Load data\n",
    "    scaling = False  # Set scaling to True to enable individual scaling for each location\n",
    "    global scalers\n",
    "    global scale_target \n",
    "    scale_target = False\n",
    "\n",
    "    # Load training data\n",
    "    df_observed = pd.read_parquet(f\"data/{location}/X_train_observed.parquet\")\n",
    "    df_estimated = pd.read_parquet(f\"data/{location}/X_train_estimated.parquet\")\n",
    "    df_target = pd.read_parquet(f\"data/{location}/train_targets.parquet\")\n",
    "\n",
    "   \n",
    "    # Load test data\n",
    "    df_test = pd.read_parquet(f\"data/{location}/X_test_estimated.parquet\")\n",
    "\n",
    "   \n",
    "    # Hot encode in wether observed or estimated\n",
    "\n",
    "    # Resample and add custom fields\n",
    "\n",
    "    df_observed = resample_add_data(df_observed, False)\n",
    "    df_estimated = resample_add_data(df_estimated, False)\n",
    "    df_test = resample_add_data(df_test, True)\n",
    "\n",
    "    df_training, df_test = make_observed_and_estimated_category(df_observed, df_estimated, df_test)\n",
    "\n",
    "    if scale_target:\n",
    "        if location == \"B\":\n",
    "            df_target[\"pv_measurement\"] = df_target[\"pv_measurement\"] * B_SCALE_VALUE\n",
    "        elif location == \"C\":\n",
    "            df_target[\"pv_measurement\"] = df_target[\"pv_measurement\"] * C_SCALE_VALUE\n",
    "\n",
    "    # Merge training with target data\n",
    "    df_training = pd.merge(df_training, df_target, left_on=\"date_forecast\", right_on=\"time\", how=\"inner\")\n",
    "    \n",
    "    # Create lagged features and remove outliers training\n",
    "    df_training = create_weather_lagged_features(df_training, WEATHER_FEATURES)\n",
    "    df_training = df_training[COLUMNS_TO_KEEP]\n",
    "    df_training = remove_outliers(df_training)\n",
    "\n",
    "    df_test = create_weather_lagged_features(df_test, WEATHER_FEATURES)\n",
    "    df_test = df_test[TEST_COLUMNS_TO_KEEP]\n",
    "\n",
    "\n",
    "    # Add categories\n",
    "    df_training = add_location_feature(df_training, location)\n",
    "    X_test = add_location_feature(df_test, location)\n",
    "    \n",
    "    # Add scaling\n",
    "    if scaling:\n",
    "        X_test, X_training = add_scaling(X_test, X_training, location)\n",
    "    df_test.reset_index(inplace=True)\n",
    "    df_test.drop(columns=[\"date_forecast\"], inplace=True)\n",
    "    # y_training = np.log1p(y_training)\n",
    "    return df_training, X_test\n",
    "\n",
    "\n",
    "\n",
    "# Use prepare_data function\n",
    "\n",
    "combined_df_train = []\n",
    "combined_df_test = []\n",
    "combined_df_validation = []\n",
    "\n",
    "for location in locations:\n",
    "    # Prepare the training data\n",
    "    X_training, X_test = prepare_data(location)\n",
    "\n",
    "    df_training, df_test = prepare_data(location)\n",
    "    X_training, X_validation = train_test_split(df_training, test_size=720, shuffle=False)\n",
    "    \n",
    "    combined_df_train.append(X_training)\n",
    "    combined_df_validation.append(X_validation)\n",
    "\n",
    "    combined_df_test.append(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models/test_modelA\"\n",
      "Presets specified: ['best_quality']\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"autogluon_models/test_modelA\"\n",
      "AutoGluon Version:  0.8.3b20231109\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Sat Jun 18 17:07:28 PDT 2022; root:xnu-8020.140.41~1/RELEASE_ARM64_T8110\n",
      "Disk Space Avail:   57.22 GB / 245.11 GB (23.3%)\n",
      "Train Data Rows:    33365\n",
      "Train Data Columns: 67\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 620.32562, 1155.01668)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    2269.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 9.11 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['is_in_shadow:idx', 'is_day:idx', 'dew_or_rime:idx', 'observed_or_estimated']\n",
      "\t\t('float', [])    : 62 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'clear_sky_energy_1h:J', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  3 | ['is_in_shadow:idx', 'is_day:idx', 'dew_or_rime:idx']\n",
      "\t\t('float', [])     : 62 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'clear_sky_energy_1h:J', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['observed_or_estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t66 features in original data used to generate 66 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 9.08 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.21s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN', 'FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 199.81s of the 299.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t-147.7112\t = Validation score   (-mean_absolute_error)\n",
      "\t33.54s\t = Training   runtime\n",
      "\t96.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 150.96s of the 250.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-155.4368\t = Validation score   (-mean_absolute_error)\n",
      "\t70.77s\t = Training   runtime\n",
      "\t90.73s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 75.32s of the 175.3s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 234 due to low memory. Expected memory usage reduced from 19.16% -> 15.0% of available memory...\n",
      "\t-175.9217\t = Validation score   (-mean_absolute_error)\n",
      "\t33.99s\t = Training   runtime\n",
      "\t0.62s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 40.43s of the 140.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-177.8236\t = Validation score   (-mean_absolute_error)\n",
      "\t32.83s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 5.74s of the 105.71s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 277 due to low memory. Expected memory usage reduced from 16.24% -> 15.0% of available memory...\n",
      "\tWarning: Reducing model 'n_estimators' from 277 -> 137 due to low time. Expected time usage reduced from 11.5s -> 5.7s...\n",
      "\t-176.2821\t = Validation score   (-mean_absolute_error)\n",
      "\t3.71s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1.5s of the 101.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-186.6401\t = Validation score   (-mean_absolute_error)\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.79s of the 97.97s of remaining time.\n",
      "\t-147.0722\t = Validation score   (-mean_absolute_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN', 'FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 97.69s of the 97.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-149.4367\t = Validation score   (-mean_absolute_error)\n",
      "\t3.16s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 93.0s of the 92.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-147.4585\t = Validation score   (-mean_absolute_error)\n",
      "\t2.24s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 88.97s of the 88.94s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 243 due to low memory. Expected memory usage reduced from 18.46% -> 15.0% of available memory...\n",
      "\t-146.5307\t = Validation score   (-mean_absolute_error)\n",
      "\t45.35s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 42.53s of the 42.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-147.6078\t = Validation score   (-mean_absolute_error)\n",
      "\t20.01s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 20.8s of the 20.79s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 252 due to low memory. Expected memory usage reduced from 17.81% -> 15.0% of available memory...\n",
      "\t-144.8503\t = Validation score   (-mean_absolute_error)\n",
      "\t7.56s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 12.25s of the 12.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t-146.4678\t = Validation score   (-mean_absolute_error)\n",
      "\t4.31s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 6.36s of the 6.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
      "\t-147.8394\t = Validation score   (-mean_absolute_error)\n",
      "\t6.14s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.79s of the -1.59s of remaining time.\n",
      "\t-144.1897\t = Validation score   (-mean_absolute_error)\n",
      "\t0.49s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 302.1s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon_models/test_modelA\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models/test_modelB\"\n",
      "Presets specified: ['best_quality']\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"autogluon_models/test_modelB\"\n",
      "AutoGluon Version:  0.8.3b20231109\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Sat Jun 18 17:07:28 PDT 2022; root:xnu-8020.140.41~1/RELEASE_ARM64_T8110\n",
      "Disk Space Avail:   55.52 GB / 245.11 GB (22.7%)\n",
      "Train Data Rows:    29017\n",
      "Train Data Columns: 67\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 91.51829, 200.09969)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    1829.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.92 MB (0.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['is_in_shadow:idx', 'is_day:idx', 'dew_or_rime:idx', 'observed_or_estimated']\n",
      "\t\t('float', [])    : 62 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'clear_sky_energy_1h:J', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  3 | ['is_in_shadow:idx', 'is_day:idx', 'dew_or_rime:idx']\n",
      "\t\t('float', [])     : 62 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'clear_sky_energy_1h:J', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['observed_or_estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t66 features in original data used to generate 66 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.89 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.22s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN', 'FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 199.8s of the 299.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-20.0052\t = Validation score   (-mean_absolute_error)\n",
      "\t60.47s\t = Training   runtime\n",
      "\t77.31s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 135.18s of the 235.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t-21.5433\t = Validation score   (-mean_absolute_error)\n",
      "\t71.92s\t = Training   runtime\n",
      "\t79.19s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 58.62s of the 158.59s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 270 due to low time. Expected time usage reduced from 65.1s -> 58.6s...\n",
      "\t-24.1433\t = Validation score   (-mean_absolute_error)\n",
      "\t41.18s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 16.61s of the 116.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t-26.3977\t = Validation score   (-mean_absolute_error)\n",
      "\t13.74s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1.21s of the 101.18s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 243 due to low memory. Expected memory usage reduced from 18.47% -> 15.0% of available memory...\n",
      "\tWarning: Model is expected to require 10.4s to train, which exceeds the maximum time limit of 1.2s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L1.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 0.78s of the 100.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.05%)\n",
      "\t-59.8891\t = Validation score   (-mean_absolute_error)\n",
      "\t1.45s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.78s of the 97.49s of remaining time.\n",
      "\t-19.942\t = Validation score   (-mean_absolute_error)\n",
      "\t0.27s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN', 'FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 97.21s of the 97.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-20.0712\t = Validation score   (-mean_absolute_error)\n",
      "\t5.08s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 90.1s of the 90.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t-19.7774\t = Validation score   (-mean_absolute_error)\n",
      "\t2.6s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 85.94s of the 85.93s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 279 due to low time. Expected time usage reduced from 92.2s -> 85.9s...\n",
      "\t-19.4316\t = Validation score   (-mean_absolute_error)\n",
      "\t48.26s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 36.85s of the 36.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-19.7713\t = Validation score   (-mean_absolute_error)\n",
      "\t29.6s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 5.46s of the 5.45s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 164 due to low time. Expected time usage reduced from 9.9s -> 5.5s...\n",
      "\t-19.2519\t = Validation score   (-mean_absolute_error)\n",
      "\t3.95s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 0.97s of the 0.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-32.0064\t = Validation score   (-mean_absolute_error)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.78s of the -1.63s of remaining time.\n",
      "\t-19.1623\t = Validation score   (-mean_absolute_error)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 302.24s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon_models/test_modelB\")\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"autogluon_models/test_modelC\"\n",
      "Presets specified: ['best_quality']\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=20\n",
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"autogluon_models/test_modelC\"\n",
      "AutoGluon Version:  0.8.3b20231109\n",
      "Python Version:     3.11.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 21.6.0: Sat Jun 18 17:07:28 PDT 2022; root:xnu-8020.140.41~1/RELEASE_ARM64_T8110\n",
      "Disk Space Avail:   54.83 GB / 245.11 GB (22.4%)\n",
      "Train Data Rows:    25523\n",
      "Train Data Columns: 67\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/core/utils/utils.py:564: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 75.75074, 164.77907)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/.venv/lib/python3.11/site-packages/autogluon/tabular/learner/default_learner.py:215: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context(\"mode.use_inf_as_na\", True):  # treat None, NaN, INF, NINF as NA\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3043.6 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.97 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  4 | ['is_in_shadow:idx', 'is_day:idx', 'dew_or_rime:idx', 'observed_or_estimated']\n",
      "\t\t('float', [])    : 62 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'clear_sky_energy_1h:J', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  3 | ['is_in_shadow:idx', 'is_day:idx', 'dew_or_rime:idx']\n",
      "\t\t('float', [])     : 62 | ['direct_rad:W', 'clear_sky_rad:W', 'diffuse_rad:W', 'direct_rad_1h:J', 'clear_sky_energy_1h:J', ...]\n",
      "\t\t('int', ['bool']) :  1 | ['observed_or_estimated']\n",
      "\t0.2s = Fit runtime\n",
      "\t66 features in original data used to generate 66 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.94 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.18s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN', 'FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 199.83s of the 299.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-16.4176\t = Validation score   (-mean_absolute_error)\n",
      "\t35.53s\t = Training   runtime\n",
      "\t73.78s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 151.94s of the 251.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t-17.5093\t = Validation score   (-mean_absolute_error)\n",
      "\t68.83s\t = Training   runtime\n",
      "\t78.86s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 78.26s of the 178.24s of remaining time.\n",
      "\t-19.4132\t = Validation score   (-mean_absolute_error)\n",
      "\t30.53s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 47.08s of the 147.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t-19.6016\t = Validation score   (-mean_absolute_error)\n",
      "\t38.31s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 7.06s of the 107.05s of remaining time.\n",
      "\t-19.4707\t = Validation score   (-mean_absolute_error)\n",
      "\t5.0s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1.35s of the 101.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-21.8112\t = Validation score   (-mean_absolute_error)\n",
      "\t1.69s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 299.82s of the 97.87s of remaining time.\n",
      "\t-16.3366\t = Validation score   (-mean_absolute_error)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Excluded models: ['KNN', 'FASTAI', 'NN_TORCH'] (Specified by `excluded_model_types`)\n",
      "Fitting 7 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 97.62s of the 97.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-16.6098\t = Validation score   (-mean_absolute_error)\n",
      "\t4.53s\t = Training   runtime\n",
      "\t0.85s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 91.38s of the 91.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.02%)\n",
      "\t-16.4559\t = Validation score   (-mean_absolute_error)\n",
      "\t2.36s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 87.4s of the 87.39s of remaining time.\n",
      "\t-16.0267\t = Validation score   (-mean_absolute_error)\n",
      "\t37.58s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 49.07s of the 49.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.03%)\n",
      "\t-16.6273\t = Validation score   (-mean_absolute_error)\n",
      "\t26.49s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 21.01s of the 21.0s of remaining time.\n",
      "\t-15.9851\t = Validation score   (-mean_absolute_error)\n",
      "\t5.57s\t = Training   runtime\n",
      "\t0.49s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 14.79s of the 14.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-16.2539\t = Validation score   (-mean_absolute_error)\n",
      "\t5.07s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 7.99s of the 7.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.04%)\n",
      "\t-16.3208\t = Validation score   (-mean_absolute_error)\n",
      "\t7.21s\t = Training   runtime\n",
      "\t1.01s\t = Validation runtime\n",
      "Completed 1/20 k-fold bagging repeats ...\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 299.82s of the -1.19s of remaining time.\n",
      "\t-15.8759\t = Validation score   (-mean_absolute_error)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 301.75s ... Best model: \"WeightedEnsemble_L3\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"autogluon_models/test_modelC\")\n"
     ]
    }
   ],
   "source": [
    "def train_model(dataset):\n",
    "    # Define the path where the AutoGluon models will be saved\n",
    "    #enumerate all the locations\n",
    "    for index, location in enumerate(locations):\n",
    "        save_path = f'autogluon_models/test_model{location}'\n",
    "        \n",
    "        # Initialize the TabularPredictor object\n",
    "        model = TabularPredictor(label='pv_measurement', path=save_path, eval_metric='mae')\n",
    "        model.fit(train_data=combined_df_train[index], presets='best_quality', time_limit=60*5, excluded_model_types=['KNN', 'NN_TORCH', 'FASTAI'])\n",
    "\n",
    "def evaluate_model(X_val, y_val, location, model=None):\n",
    "    if model is None:\n",
    "        # If no model is passed, we assume the model has been previously saved and needs to be loaded\n",
    "        save_path = f'autogluon_models_location_{location}'\n",
    "        # model = TabularPredictor.load(save_path)\n",
    "        model = autogluon.multimodal(save_path)\n",
    "\n",
    "    # Predictions are made on the non-transformed validation data\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # If y_val was transformed (e.g., log1p), then apply the inverse transformation\n",
    "    # y_val = np.expm1(y_val)\n",
    "    # y_pred = np.expm1(y_pred)\n",
    "    \n",
    "    # Calculate the MAE\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    print(f'Location {location}, Mean Absolute Error: {mae}')\n",
    "\n",
    "# Train the model using all available training data and the initial validation set for early stopping\n",
    "train_model(combined_df_train)\n",
    "\n",
    "# Evaluate the model using the same validation set\n",
    "# evaluate_model(combined_X_val, combined_Y_val, location, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.leaderboard(combined_df_validation, silent=True)\n",
    "# model.fit_summary(show_plot=True)\n",
    "# model.feature_importance(combined_df_validation, time_limit=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you have defined WEATHER_FEATURES, TEST_COLUMNS_TO_KEEP, and other functions previously\n",
    "\n",
    "def make_predictions(df_test_pred, location):\n",
    "    eval_model = TabularPredictor.load(f\"autogluon_models/test_model{location}\", require_version_match=False)\n",
    "    preds = eval_model.predict(df_test_pred)\n",
    "    return preds\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate locally\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb#X16sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb#X16sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mfor\u001b[39;00m loc \u001b[39min\u001b[39;00m locations:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb#X16sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     evaluate_model_locally(loc, scalers)\n",
      "\u001b[1;32m/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m target_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_parquet(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m/train_targets.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Make predictions\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# filter x_validate to only include values from location\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m pred_dataset \u001b[39m=\u001b[39m combined_df_validation[combined_df_validation[\u001b[39m\"\u001b[39;49m\u001b[39mlocation\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39m location]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pred_dataset\u001b[39m.\u001b[39mreset_index(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mathiasaas/NTNU/maskinlaring/project/TDT4173-project/autoML_Mathias.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m preds \u001b[39m=\u001b[39m make_predictions(pred_dataset\u001b[39m.\u001b[39mdrop(\u001b[39m\"\u001b[39m\u001b[39mpv_measurement\u001b[39m\u001b[39m\"\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), location)[\u001b[39m-\u001b[39m\u001b[39m720\u001b[39m:]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evaluate_model_locally(location, scalers):\n",
    "    # Load the test data\n",
    "    target_df = pd.read_parquet(f\"data/{location}/train_targets.parquet\")\n",
    "    \n",
    "    # Make predictions\n",
    "    # filter x_validate to only include values from location\n",
    "    pred_dataset = combined_df_validation[combined_df_validation[\"location\"] == location]\n",
    "    pred_dataset.reset_index(inplace=True)\n",
    "\n",
    "    preds = make_predictions(pred_dataset.drop(\"pv_measurement\", axis=1), location)[-720:]\n",
    "    target = target_df.tail(720)[\"pv_measurement\"].to_numpy()\n",
    "    \n",
    "    differences = preds - target\n",
    "    # Count predictions lower than the actual\n",
    "    lower_predictions = (differences < 0) & (target != 0)\n",
    "    # Count predictions higher than the actual\n",
    "    higher_predictions = (differences > 0) & (target != 0)\n",
    "\n",
    "    # Biggest misreads\n",
    "    absolute_differences = abs(differences)\n",
    "    max_diff_index = absolute_differences.argmax()  # Index of the biggest difference\n",
    "    # max_diff_value = absolute_differences[max_diff_index]  # Value of the biggest difference\n",
    "    print(f\"Number of predictions that are a lower value than the actual, given that the actual is not 0: {lower_predictions.sum()}\")\n",
    "    print(f\"Number of predictions that are larger than the target, given that the target is not 0: {higher_predictions.sum()}\")\n",
    "    # print(f\"The biggest misread is at index {max_diff_index} with a difference of {max_diff_value}\")\n",
    "    \n",
    "    index = target_df.index[-720:]\n",
    "    print(f'location: {location}')\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(60,6))\n",
    "    plt.plot(index, target, label=\"Target\")\n",
    "    plt.plot(index, preds, label=\"Predictions\")\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Target vs Predictions')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "    plt.show()\n",
    "\n",
    "for loc in locations:\n",
    "    evaluate_model_locally(loc, scalers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to csv 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    True\n",
      "1    True\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "Name: location, dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/1193821682.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_submission[\"prediction\"][720*index:720*(index+1)] = preds\n",
      "/var/folders/z2/g8xyn7s12bg5v9jx9vpx997h0000gn/T/ipykernel_69886/1193821682.py:15: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 5.52161485e-02  2.00569987e-01  7.02228427e-01  4.71671753e+01\n",
      "  2.96712463e+02  8.09475342e+02  1.71452612e+03  2.60205176e+03\n",
      "  2.87601831e+03  2.05451538e+03  2.15203271e+03  2.56653223e+03\n",
      "  2.03491968e+03  2.09325317e+03  1.87263574e+03  1.47256555e+03\n",
      "  1.38056567e+03  5.92302856e+02  2.31924347e+02  1.60165024e+01\n",
      "  1.33931264e-01  1.08747452e-01  8.71481514e+00  1.19258928e+01\n",
      "  6.23531222e-01  8.99468184e-01  8.51038170e+00  2.20669174e+02\n",
      "  6.34804932e+02  1.23053113e+03  1.92001318e+03  2.30932520e+03\n",
      "  3.23652344e+03  3.65726270e+03  3.61510498e+03  3.72989258e+03\n",
      "  3.79159521e+03  3.62995776e+03  3.26135034e+03  2.63699585e+03\n",
      "  1.63884888e+03  7.29511047e+02  3.85357391e+02  1.17136459e+02\n",
      "  1.04376230e+01  2.78153872e+00  6.80466175e-01 -1.90194279e-01\n",
      " -8.54404688e-01 -6.46235466e-01  2.46088104e+01  2.81938751e+02\n",
      "  7.01665894e+02  1.35399585e+03  2.35703760e+03  3.23363696e+03\n",
      "  3.88642822e+03  4.76079248e+03  4.80589697e+03  4.36802734e+03\n",
      "  4.45975781e+03  4.04329639e+03  2.68200195e+03  2.05988477e+03\n",
      "  1.31828821e+03  6.60399658e+02  3.24149658e+02  1.20532387e+02\n",
      "  1.57918781e-01 -1.87006772e+00 -1.28407562e+00  3.90896589e-01\n",
      "  2.58055162e+00  2.09185743e+00  1.81994896e+01  1.89309998e+02\n",
      "  5.70906494e+02  1.17670776e+03  2.62299707e+03  3.28380322e+03\n",
      "  3.19165845e+03  2.93779248e+03  2.62550171e+03  3.00355811e+03\n",
      "  3.12282983e+03  3.18569580e+03  3.05661011e+03  2.13080933e+03\n",
      "  1.49559033e+03  4.76487488e+02  3.02936371e+02  1.21127083e+02\n",
      "  3.31861591e+00  1.56088948e-01  1.95724517e-01 -7.86842406e-02\n",
      " -1.94913137e+00  5.57430983e-02  4.60887451e+01  2.44913879e+02\n",
      "  5.82998962e+02  1.51768250e+03  2.88723877e+03  3.34140137e+03\n",
      "  4.26267383e+03  4.67478662e+03  5.02183057e+03  5.04347803e+03\n",
      "  4.62887988e+03  4.33611670e+03  3.62070166e+03  2.90617139e+03\n",
      "  2.03362634e+03  9.76875244e+02  4.38195984e+02  1.99021973e+02\n",
      "  1.59450760e+01 -1.19275898e-01 -2.98087329e-01  2.12506652e-01\n",
      "  1.13785833e-01  1.86837745e+00  7.78686829e+01  2.44144165e+02\n",
      "  6.85769226e+02  1.61610400e+03  2.52027246e+03  3.52215454e+03\n",
      "  3.84217749e+03  3.61677124e+03  3.60235327e+03  2.59810303e+03\n",
      "  2.39943994e+03  2.51287939e+03  2.87786084e+03  2.07925488e+03\n",
      "  1.55233850e+03  8.56654846e+02  4.16235352e+02  1.81516953e+02\n",
      "  1.89761868e+01  1.64517665e+00  3.68328393e-02 -1.12001634e+00\n",
      " -7.52162933e-01  4.55950856e-01  8.07844238e+01  2.08052979e+02\n",
      "  6.54787964e+02  1.54667749e+03  2.53161719e+03  3.45922266e+03\n",
      "  4.00754712e+03  4.26903271e+03  4.26215576e+03  4.35221289e+03\n",
      "  4.03954883e+03  3.69585156e+03  3.29518628e+03  2.48893799e+03\n",
      "  1.71163184e+03  8.21149353e+02  3.98626770e+02  1.79224258e+02\n",
      "  1.56553183e+01  1.38055682e+00  3.89733493e-01  4.63385940e-01\n",
      "  8.91750604e-02  7.48670846e-02  8.49784851e+00  8.39776154e+01\n",
      "  1.80774261e+02  2.52287903e+02  2.42097855e+02  3.66026917e+02\n",
      "  4.91909210e+02  6.43502869e+02  7.80767883e+02  1.57235278e+03\n",
      "  1.98851050e+03  1.62358508e+03  1.89877905e+03  1.43612671e+03\n",
      "  9.08545898e+02  4.84706909e+02  3.25967743e+02  1.29031342e+02\n",
      "  1.83856125e+01 -1.06485558e+00 -9.82286930e-01 -7.31633604e-02\n",
      "  2.45686913e+00  9.82895136e-01  4.85361786e+01  2.17503693e+02\n",
      "  3.98370850e+02  1.21370874e+03  1.55261389e+03  1.96815247e+03\n",
      "  1.72780920e+03  2.06080786e+03  2.39294995e+03  1.94909448e+03\n",
      "  2.82203564e+03  2.41183789e+03  1.83137268e+03  1.02382275e+03\n",
      "  8.76875000e+02  5.52220032e+02  2.63242126e+02  6.64154434e+01\n",
      "  1.16470747e+01  1.88423479e+00  8.84259582e-01  1.22238982e+00\n",
      "  4.74571824e-01  3.87322283e+00  3.72145424e+01  1.37418259e+02\n",
      "  2.42872177e+02  3.56192749e+02  8.16653320e+02  1.43791223e+03\n",
      "  1.74058911e+03  1.72125439e+03  1.46703845e+03  1.28788354e+03\n",
      "  1.14050586e+03  8.86302002e+02  7.47079102e+02  5.73934937e+02\n",
      "  4.12654236e+02  3.07138580e+02  1.94587967e+02  6.40593491e+01\n",
      "  1.50897751e+01  1.40996361e+00 -2.42096275e-01  5.85247576e-02\n",
      "  3.27251256e-01  1.84030354e+00  2.62332535e+01  1.27239677e+02\n",
      "  3.51724243e+02  1.22127209e+03  1.53750391e+03  1.97989453e+03\n",
      "  1.89931946e+03  1.47011353e+03  2.15468042e+03  1.87993127e+03\n",
      "  2.07879639e+03  2.38639185e+03  2.34664648e+03  2.29206934e+03\n",
      "  1.59526538e+03  9.97341858e+02  4.80091217e+02  2.17307816e+02\n",
      "  5.11222763e+01  1.52720320e+00  1.63686097e-01  6.07581288e-02\n",
      "  2.68691123e-01  5.09759426e+00  8.37299271e+01  2.25396515e+02\n",
      "  4.89906769e+02  6.29941040e+02  8.38358276e+02  7.47742798e+02\n",
      "  8.04719788e+02  8.05539551e+02  1.06858716e+03  8.59094116e+02\n",
      "  5.98172241e+02  4.27113129e+02  4.37763489e+02  4.66455383e+02\n",
      "  5.02289276e+02  3.43949554e+02  1.62806335e+02  5.85967064e+01\n",
      "  1.08690147e+01 -5.52648187e-01  6.56537652e-01  2.79397559e+00\n",
      "  1.11488867e+00  4.38177729e+00  7.93445053e+01  1.88393875e+02\n",
      "  3.89682434e+02  1.16075598e+03  1.08028882e+03  1.28626685e+03\n",
      "  1.45631799e+03  1.88468481e+03  1.99148401e+03  1.82852502e+03\n",
      "  1.49835364e+03  1.85579419e+03  1.48721167e+03  1.29707703e+03\n",
      "  1.33350122e+03  9.07686340e+02  3.67231262e+02  1.98981064e+02\n",
      "  4.09781532e+01  7.61127234e-01 -5.00536442e-01  1.30380177e+00\n",
      "  2.13318944e+00  6.00545835e+00  7.60968170e+01  3.14422424e+02\n",
      "  4.68457092e+02  7.29103271e+02  1.02311169e+03  1.65898962e+03\n",
      "  1.91374097e+03  2.01722522e+03  1.97586768e+03  1.85648267e+03\n",
      "  1.59200293e+03  1.47128821e+03  1.13451184e+03  8.25949341e+02\n",
      "  6.35723145e+02  3.44391388e+02  1.82328369e+02  1.07688446e+02\n",
      "  1.94457798e+01  6.74472690e-01  9.88141596e-02  1.66555941e-01\n",
      "  3.20243865e-01  2.77630162e+00  3.13331795e+01  1.47848251e+02\n",
      "  2.78100800e+02  4.90697388e+02  6.92485474e+02  9.29864258e+02\n",
      "  1.15084570e+03  1.25887427e+03  1.12357031e+03  1.25497900e+03\n",
      "  1.31956348e+03  1.27941626e+03  1.23359900e+03  1.13317603e+03\n",
      "  7.92236328e+02  3.63181396e+02  2.01732666e+02  1.11979942e+02\n",
      "  3.59031601e+01  1.84719956e+00  9.34110761e-01  9.28566813e-01\n",
      "  1.06258607e+00  5.65986061e+00  5.56335258e+01  2.15441849e+02\n",
      "  3.14739685e+02  5.98325378e+02  9.11445618e+02  8.70404541e+02\n",
      "  1.32023218e+03  1.22567065e+03  1.14142249e+03  1.40812219e+03\n",
      "  1.31380347e+03  9.74436218e+02  1.02904810e+03  9.27334351e+02\n",
      "  9.47933472e+02  5.73973267e+02  2.47748657e+02  9.96198425e+01\n",
      "  1.51645279e+01  7.38896370e-01  1.42534330e-01 -8.18245709e-02\n",
      "  2.26008564e-01  3.10746789e+00  5.27842102e+01  1.67973099e+02\n",
      "  3.33200531e+02  4.11640747e+02  4.65748230e+02  6.44535156e+02\n",
      "  9.05792969e+02  1.15937402e+03  1.14130408e+03  1.12921582e+03\n",
      "  1.41062134e+03  1.22142285e+03  1.04445715e+03  1.14795813e+03\n",
      "  1.12766406e+03  9.12385254e+02  3.97986786e+02  2.09531464e+02\n",
      "  5.94510345e+01  2.22290444e+00 -7.68818259e-01 -8.30841541e-01\n",
      "  6.18904161e+00  2.35115166e+01  1.70610870e+02  3.46276306e+02\n",
      "  7.25642395e+02  1.93091333e+03  3.27348779e+03  4.10970557e+03\n",
      "  4.89834717e+03  5.08622168e+03  4.98119873e+03  4.89095557e+03\n",
      "  4.76376562e+03  4.38041895e+03  3.76759180e+03  3.15903052e+03\n",
      "  2.23254370e+03  1.19362866e+03  5.62098083e+02  3.24379578e+02\n",
      "  1.14669800e+02  2.17530417e+00 -7.92508721e-01 -9.09361541e-02\n",
      "  1.34787798e+00  1.52771721e+01  1.35905060e+02  3.48288025e+02\n",
      "  7.17276245e+02  1.46450562e+03  2.19087158e+03  3.09225391e+03\n",
      "  4.20695410e+03  4.20307666e+03  3.01692700e+03  1.75529614e+03\n",
      "  8.73777100e+02  5.20825745e+02  8.63129578e+02  8.21209900e+02\n",
      "  7.26753723e+02  4.42661438e+02  2.32309280e+02  1.58718170e+02\n",
      "  5.61320076e+01  5.41693115e+00  1.35367334e-01 -1.01827234e-01\n",
      "  4.21784401e-01  7.26577568e+00  7.06710663e+01  2.43516022e+02\n",
      "  4.40522095e+02  9.73925171e+02  1.91637292e+03  3.00904688e+03\n",
      "  4.12858447e+03  4.33767969e+03  4.16469580e+03  3.75427490e+03\n",
      "  3.31825293e+03  3.27476318e+03  3.03026367e+03  2.80235693e+03\n",
      "  2.10662549e+03  1.20508142e+03  6.06043945e+02  3.23437897e+02\n",
      "  1.21385483e+02  7.73815823e+00  6.24174774e-02  2.33327582e-01\n",
      " -2.77788937e-02  1.96801662e+01  1.18755966e+02  3.02026337e+02\n",
      "  6.95436951e+02  1.55871985e+03  2.48545679e+03  3.10956836e+03\n",
      "  3.77097046e+03  4.52209619e+03  4.63807080e+03  4.74110449e+03\n",
      "  4.48230225e+03  4.21502197e+03  3.59630566e+03  3.00622974e+03\n",
      "  2.14509521e+03  1.19740588e+03  6.09688782e+02  3.32263062e+02\n",
      "  1.25805862e+02  7.22765541e+00 -2.36263663e-01  1.69754219e+00\n",
      "  1.52232850e+00  1.02925854e+01  1.16851685e+02  3.51845123e+02\n",
      "  6.96505981e+02  1.30440564e+03  2.38504688e+03  3.24050024e+03\n",
      "  4.33060547e+03  4.77531445e+03  4.63342676e+03  3.53239038e+03\n",
      "  3.41942407e+03  2.75230762e+03  2.57663013e+03  1.76635168e+03\n",
      "  1.23379712e+03  6.57072754e+02  3.75262817e+02  2.02233780e+02\n",
      "  6.28439636e+01  6.88955486e-01 -1.05315340e+00 -6.58022642e-01\n",
      " -2.65896749e+00  4.29654408e+00  5.22866631e+01  1.37845932e+02\n",
      "  3.23603516e+02  5.40098572e+02  8.86160583e+02  8.64277344e+02\n",
      "  8.88456970e+02  9.24495728e+02  2.00561084e+03  3.49509741e+03\n",
      "  3.87893262e+03  3.73352612e+03  3.09390454e+03  2.56455371e+03\n",
      "  1.75245801e+03  1.09913403e+03  4.20781311e+02  2.76417206e+02\n",
      "  7.96914520e+01  3.01539278e+00 -2.08230996e+00 -2.52071881e+00\n",
      "  4.26364326e+00  1.06733150e+01  5.29470520e+01  1.43251205e+02\n",
      "  1.41438293e+02  2.13894714e+02  3.93265289e+02  8.61016418e+02\n",
      "  8.65343750e+02  1.29510376e+03  1.40659033e+03  1.52652966e+03\n",
      "  1.47412891e+03  2.09252271e+03  1.85965137e+03  2.35574878e+03\n",
      "  1.52644409e+03  9.62915039e+02  3.94399841e+02  1.44170868e+02\n",
      "  5.48083076e+01  1.95460010e+00 -6.86131477e-01  7.82458186e-02\n",
      " -1.59599888e+00  1.45141516e+01  1.10416428e+02  2.35551956e+02\n",
      "  6.48588135e+02  1.64747180e+03  2.74551758e+03  3.85179419e+03\n",
      "  4.24843359e+03  3.95795850e+03  4.30105029e+03  4.05748413e+03\n",
      "  3.49738232e+03  2.78079736e+03  2.48661353e+03  1.87785254e+03\n",
      "  1.13683875e+03  7.20179932e+02  2.67278320e+02  1.43678650e+02\n",
      "  5.63300247e+01  1.04125059e+00 -4.10483742e+00 -4.66626692e+00\n",
      " -2.01630783e+00  7.12996864e+00  9.83502426e+01  2.27104996e+02\n",
      "  5.88779480e+02  1.22066174e+03  1.85722327e+03  2.65943701e+03\n",
      "  3.81592529e+03  4.28452441e+03  4.51865332e+03  4.83648193e+03\n",
      "  4.49955811e+03  3.94781250e+03  2.60544775e+03  1.77237891e+03\n",
      "  1.21418640e+03  7.56304138e+02  4.98459045e+02  2.83242432e+02\n",
      "  1.01687271e+02  4.66367912e+00 -8.05741549e-02 -5.46793044e-02\n",
      "  8.94922614e-01  9.57074356e+00  1.19566383e+02  3.15126984e+02\n",
      "  3.74077545e+02  4.88181122e+02  5.90250244e+02  6.09673218e+02\n",
      "  9.04761169e+02  1.28187671e+03  9.22738892e+02  9.72432312e+02\n",
      "  1.32272021e+03  7.26693726e+02  8.33736694e+02  7.05194214e+02\n",
      "  4.79578217e+02  1.85185791e+02  1.28698456e+02  6.40851974e+01\n",
      "  1.63521328e+01  6.78282499e-01  3.03006977e-01  2.20883906e-01\n",
      "  4.14551526e-01  8.66639018e-01  3.49506493e+01  9.06208420e+01\n",
      "  1.21706131e+02  2.40125107e+02  3.43508484e+02  6.96320435e+02\n",
      "  6.75358521e+02  7.62854980e+02  7.10327759e+02  5.50905151e+02\n",
      "  8.40790649e+02  9.32526917e+02  7.40772644e+02  7.53057617e+02\n",
      "  5.85382019e+02  3.71289185e+02  2.41785400e+02  1.11319366e+02\n",
      "  2.78629532e+01  2.56972265e+00  1.07999384e-01  1.97762895e+00\n",
      " -2.11176920e+00  7.73498726e+00  9.97642670e+01  2.05304581e+02\n",
      "  4.48972961e+02  1.00989288e+03  2.36166016e+03  2.97466504e+03\n",
      "  3.47182422e+03  3.64253003e+03  3.86026147e+03  3.79694019e+03\n",
      "  3.60147119e+03  2.35958301e+03  2.32801929e+03  1.65327881e+03\n",
      "  1.17464990e+03  5.66273010e+02  3.06325592e+02  2.06703888e+02\n",
      "  6.85614471e+01  2.75904179e+00 -1.54230380e+00 -1.50834894e+00\n",
      " -1.18640411e+00  6.70721531e+00  6.92494736e+01  2.23727951e+02\n",
      "  2.91016785e+02  3.38296265e+02  3.75465881e+02  4.11125977e+02\n",
      "  1.67488965e+03  1.82976660e+03  2.52196680e+03  3.54212402e+03\n",
      "  3.39775439e+03  2.16029053e+03  1.42508691e+03  1.10536719e+03\n",
      "  7.55344788e+02  4.72863617e+02  3.20693848e+02  2.32089539e+02\n",
      "  7.18185883e+01  2.72041583e+00  3.40114951e-01  5.39130986e-01]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df_submission[\"prediction\"][720*index:720*(index+1)] = preds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: location, dtype: bool\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: location, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df_submission = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "for index, location in enumerate(locations): \n",
    "    preds = make_predictions(combined_df_test[index], location)\n",
    "\n",
    "    # Assign the predictions to df_submission for the current location\n",
    "    mask = df_submission[\"location\"] == location\n",
    "    print(mask.head())\n",
    "    # Add a check to make sure the lengths match\n",
    "    if len(preds) != mask.sum():\n",
    "        print(f\"Length of predictions: {len(preds)}\")\n",
    "        print(f\"Length of submission entries: {mask.sum()}\")\n",
    "        raise ValueError(f\"Mismatch in length of predictions and submission entries for location {location}.\")\n",
    "\n",
    "    df_submission[\"prediction\"][720*index:720*(index+1)] = preds\n",
    "\n",
    "\n",
    "# Save the results to a new submission file\n",
    "df_submission[[\"id\", \"prediction\"]].to_csv(\"predictions/autogluon-split.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
